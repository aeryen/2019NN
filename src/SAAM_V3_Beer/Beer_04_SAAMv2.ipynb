{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_DEVICE_ORDER'] = \"PCI_BUS_ID\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "from fastai.text import *\n",
    "from datahelper.Data import *\n",
    "from fastai.text.transform import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params = {\n",
    "    \"max_sequence_length\": 20*70,\n",
    "    \"batch_size\": 64,\n",
    "    \"num_epochs1\": 12,\n",
    "    \"num_epochs2\": 15,\n",
    "    \"num_aspect\": 5,\n",
    "    \"num_rating\": 5,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load LM Databunch and LM Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/disk2/yifan/code/SAAM/src/SAAM_V3_Hotel\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yifan/anaconda3/envs/saam/lib/python3.7/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cls_db = load_data(\"./data/hotel_balance_LengthFix1_3000per\", \"hotel_clas_databunch_2020.TraValTes\")\n",
    "cls_db = load_data(\"../../data/\", \"beer_clas_databunch_rint.TraVal\")\n",
    "cls_db.batch_size=hyper_params[\"batch_size\"]\n",
    "cls_db.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31600"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len( cls_db.vocab.itos )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Feature Combo Pooling (1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_emb(output, start, end):\n",
    "    avg_pool = output[start:end, :].mean(dim=0)\n",
    "    return avg_pool\n",
    "\n",
    "def sentence_avgpool(output, mask, p_index):\n",
    "#     output = outputs[-1]\n",
    "    doc_start = mask.int().sum(dim=1)\n",
    "    \n",
    "    batch = []\n",
    "    for doci in range(0,output.shape[0]):\n",
    "        pi = p_index[doci,:].nonzero(as_tuple=True)[0].int()\n",
    "        doc = []\n",
    "        for senti in range( len(pi) ):\n",
    "            if senti==0:\n",
    "                # from start of doc to end of first sent\n",
    "                doc.append( average_emb(output[doci,:,:], doc_start[doci], pi[senti]) )\n",
    "            else:\n",
    "                # from previous period to next\n",
    "                doc.append( average_emb(output[doci,:,:], pi[senti-1]+1, pi[senti]) )\n",
    "            \n",
    "        batch.append( torch.stack(doc, 0) )\n",
    "\n",
    "    return batch\n",
    "\n",
    "def sentence_finalpool(output, mask, p_index):\n",
    "#     output = outputs[-1]\n",
    "    \n",
    "    batch = []\n",
    "    for doci in range(0,output.shape[0]):\n",
    "        doc = output[doci,p_index[doci,:],:]\n",
    "        batch.append( doc )\n",
    "\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEFINE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceEncoder(Module):\n",
    "    \"Create an encoder over `module` that can process a full sentence.\"\n",
    "    def __init__(self, bptt:int, max_len:int, module:nn.Module, vocab, pad_idx:int=1):\n",
    "        print(\"Encoder init\")\n",
    "        self.max_len,self.bptt,self.module,self.pad_idx = max_len,bptt,module,pad_idx\n",
    "        self.vocab = vocab\n",
    "        self.period_index = self.vocab.stoi[\"xxperiod\"]\n",
    "\n",
    "    def concat(self, arrs:Collection[Tensor])->Tensor:\n",
    "        \"Concatenate the `arrs` along the batch dimension.\"\n",
    "        return [torch.cat([l[si] for l in arrs], dim=1) for si in range_of(arrs[0])]\n",
    "\n",
    "    def reset(self):\n",
    "        if hasattr(self.module, 'reset'): self.module.reset()\n",
    "\n",
    "    def forward(self, input:LongTensor)->Tuple[Tensor,Tensor]:\n",
    "        bs,sl = input.size()\n",
    "        self.reset()\n",
    "        raw_outputs,outputs,masks = [],[],[]\n",
    "        p_index = []\n",
    "        for i in range(0, sl, self.bptt):\n",
    "            r, o = self.module(input[:,i: min(i+self.bptt, sl)])\n",
    "            if i>(sl-self.max_len):\n",
    "                masks.append(input[:,i: min(i+self.bptt, sl)] == self.pad_idx)\n",
    "                raw_outputs.append(r)\n",
    "                outputs.append(o)\n",
    "                p_index.append( input[:,i: min(i+self.bptt, sl)] == self.period_index )\n",
    "\n",
    "                \n",
    "        # print(\"number of sentences in docs:\")\n",
    "#         n_sent = torch.sum( x==self.vocab.stoi[\"xxperiod\"] , dim=1)\n",
    "        # print(n_sent)\n",
    "        \n",
    "        # print(\"locating period marks\")\n",
    "        period_index = torch.cat(p_index,dim=1)\n",
    "        \n",
    "        return self.concat(raw_outputs),self.concat(outputs), \\\n",
    "               torch.cat(masks,dim=1),period_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLS 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment.add_tag(\"CLAS02\")\n",
    "# experiment.add_tag(\"2020AVG\")\n",
    "\n",
    "# ATTENTIONAL AVERAGING, COMPLETELY INDEPENDENT SENTI OUT\n",
    "\n",
    "class Cls02ATT400(Module):\n",
    "    \"Create a linear classifier with pooling.\"\n",
    "    def __init__(self, n_asp:int, n_rat:int, layers:Collection[int], drops:Collection[float]):\n",
    "        print(\"CLS init\")\n",
    "        print(\"Num Aspect: \"+str(n_asp) )\n",
    "        print(\"Num Rating: \"+str(n_rat) )\n",
    "        self.n_asp = n_asp\n",
    "        self.n_rat = n_rat\n",
    "        \n",
    "        self.proj_dim = 128\n",
    "        \n",
    "        self.aspect_projector = nn.Sequential(* ( bn_drop_lin( 400, self.proj_dim, p=0.5, actn=nn.GELU() ) ) )\n",
    "        self.senti_projector = nn.Sequential(* ( bn_drop_lin( 400, self.proj_dim, p=0.5, actn=nn.GELU() ) ) )\n",
    "        \n",
    "        self.hid_size = 64\n",
    "        # aspect projector, with additional 1 aspect for throw out\n",
    "        mod_layers = []\n",
    "#         mod_layers += bn_drop_lin( self.proj_dim, self.hid_size, p=0.35, actn=nn.GELU() )\n",
    "#         mod_layers += bn_drop_lin( self.hid_size, self.n_asp + 1, p=0.2, actn=torch.nn.Softmax(dim=1) )\n",
    "        mod_layers += bn_drop_lin( self.proj_dim, self.n_asp + 1, p=0.35, actn=torch.nn.Softmax(dim=1) )\n",
    "        self.aspect = nn.Sequential(*mod_layers)\n",
    "        \n",
    "#         self.s0 = nn.Sequential(* ( bn_drop_lin( self.proj_dim, self.n_rat, p=0.35, actn=None ) ) )  # from 256 to 5\n",
    "#         self.s1 = nn.Sequential(* ( bn_drop_lin( self.proj_dim, self.n_rat, p=0.35, actn=None ) ) )\n",
    "#         self.s2 = nn.Sequential(* ( bn_drop_lin( self.proj_dim, self.n_rat, p=0.35, actn=None ) ) )\n",
    "#         self.s3 = nn.Sequential(* ( bn_drop_lin( self.proj_dim, self.n_rat, p=0.35, actn=None ) ) )\n",
    "#         self.s4 = nn.Sequential(* ( bn_drop_lin( self.proj_dim, self.n_rat, p=0.35, actn=None ) ) )\n",
    "#         self.s5 = nn.Sequential(* ( bn_drop_lin( self.proj_dim, self.n_rat, p=0.35, actn=None ) ) )\n",
    "\n",
    "        self.sentiments = nn.Sequential(* ( bn_drop_lin( self.proj_dim, self.n_rat, p=0.35, actn=None ) ) )\n",
    "#         self.sentiments.append( self.s0 )\n",
    "#         self.sentiments.append( self.s1 )\n",
    "#         self.sentiments.append( self.s2 )\n",
    "#         self.sentiments.append( self.s3 )\n",
    "#         self.sentiments.append( self.s4 )\n",
    "#         self.sentiments.append( self.s5 )\n",
    "\n",
    "\n",
    "    def forward(self, input:Tuple[Tensor,Tensor,Tensor,Tensor])->Tuple[Tensor,Tensor,Tensor]:\n",
    "        raw_outputs,outputs,mask,p_index = input\n",
    "        batch_size = outputs[-1].shape[0]\n",
    "        \n",
    "        sentence_emb = outputs[-1].view(-1, 400)\n",
    "        \n",
    "        aspect_projection = self.aspect_projector( sentence_emb )  # [n_token, 256]\n",
    "        senti_projection = self.senti_projector( sentence_emb )  # [n_token, 256]\n",
    "        \n",
    "        aspect_projection = aspect_projection.view(batch_size, -1, self.proj_dim)  # [batch, doc_len, 256]\n",
    "        senti_projection = senti_projection.view(batch_size, -1, self.proj_dim)\n",
    "        \n",
    "        aspect_batch = sentence_avgpool(aspect_projection, mask, p_index)\n",
    "        senti_batch = sentence_avgpool(senti_projection, mask, p_index)\n",
    "        \n",
    "        allsent_aspect_proj = torch.cat(aspect_batch, dim=0)        # [n_sentence, 256]\n",
    "        allsent_senti_proj = torch.cat(senti_batch, dim=0)          # [n_sentence, 256]\n",
    "        \n",
    "        aspect_dist = self.aspect(allsent_aspect_proj)         # [n_sentence, aspect6]\n",
    "\n",
    "        sent_bmm = torch.bmm(aspect_dist[:,0:self.n_asp].unsqueeze(2), allsent_senti_proj.unsqueeze(1))  # [319, 6, 256]\n",
    "        \n",
    "        all_doc_emb = []\n",
    "        aspect_doc = []\n",
    "        sentim_doc = []\n",
    "        cur = 0\n",
    "        for doci in range(0, len(aspect_batch)):\n",
    "            sn = aspect_batch[doci].shape[0]\n",
    "            doc_emb_avg = torch.sum(sent_bmm[cur:(cur+sn), :, : ], dim=0, keepdim=True) # [1, 6, 400]\n",
    "            asp_w_sum = torch.sum(aspect_dist[cur:(cur+sn),0:self.n_asp], dim=0, keepdim=True)     # [1, 6]\n",
    "            doc_emb_avg = doc_emb_avg / asp_w_sum[:,:,None]                             # [1, 6, 400]\n",
    "            all_doc_emb.append( doc_emb_avg )\n",
    "            aspect_doc.append( aspect_dist[cur:(cur+sn), :] )\n",
    "            \n",
    "            cur = cur + sn\n",
    "\n",
    "        all_doc_emb = torch.cat( all_doc_emb, dim=0 )          # [batch, asp, 400]\n",
    "        \n",
    "        result_senti = [ self.sentiments( all_doc_emb[:,aspi,:] ) for aspi in range(0,self.n_asp)] # [batch, ra]\n",
    "        \n",
    "        result = torch.stack(result_senti, dim=1)  # [batch, asp, sentiment5]\n",
    "        \n",
    "        return result,raw_outputs,outputs,aspect_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_classifier(arch:Callable, vocab_sz:int, vocab, n_class:int, bptt:int=70, max_len:int=20*70, config:dict=None,\n",
    "                        drop_mult:float=1., lin_ftrs:Collection[int]=None, ps:Collection[float]=None,\n",
    "                        pad_idx:int=1) -> nn.Module:\n",
    "    \"Create a text classifier from `arch` and its `config`, maybe `pretrained`.\"\n",
    "    print(\"CUSTOM DEFINED CLASSIFIER\")\n",
    "    meta = text.learner._model_meta[arch]\n",
    "    config = ifnone(config, meta['config_clas']).copy()\n",
    "    for k in config.keys():\n",
    "        if k.endswith('_p'): config[k] *= drop_mult\n",
    "    if lin_ftrs is None: lin_ftrs = [50]\n",
    "    if ps is None:  ps = [0.1]*len(lin_ftrs)\n",
    "    layers = [config[meta['hid_name']] * 3] + lin_ftrs + [n_class]\n",
    "    ps = [config.pop('output_p')] + ps\n",
    "    init = config.pop('init') if 'init' in config else None\n",
    "    encoder = SentenceEncoder(bptt, max_len, arch(vocab_sz, **config), vocab, pad_idx=pad_idx)\n",
    "    cls_layer = Cls02ATT400(n_asp=hyper_params[\"num_aspect\"], n_rat=hyper_params[\"num_rating\"], layers=layers, drops=ps)\n",
    "    model = SequentialRNN(encoder, cls_layer)\n",
    "    return model if init is None else model.apply(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_classifier_learner(data:DataBunch, arch:Callable, bptt:int=70, max_len:int=20*70, config:dict=None,\n",
    "                            pretrained:bool=True, drop_mult:float=1., lin_ftrs:Collection[int]=None,\n",
    "                            ps:Collection[float]=None, **learn_kwargs) -> 'TextClassifierLearner':\n",
    "    \"Create a `Learner` with a text classifier from `data` and `arch`.\"\n",
    "    model = get_text_classifier(arch, len(data.vocab.itos), data.vocab, data.c, bptt=bptt, max_len=max_len,\n",
    "                                config=config, drop_mult=drop_mult, lin_ftrs=lin_ftrs, ps=ps)\n",
    "    meta = text.learner._model_meta[arch]\n",
    "    learn = RNNLearner(data, model, split_func=meta['split_clas'], **learn_kwargs)\n",
    "    if pretrained:\n",
    "        if 'url' not in meta:\n",
    "            warn(\"There are no pretrained weights for that architecture yet!\")\n",
    "            return learn\n",
    "        model_path = untar_data(meta['url'], data=False)\n",
    "        fnames = [list(model_path.glob(f'*.{ext}'))[0] for ext in ['pth', 'pkl']]\n",
    "        learn = learn.load_pretrained(*fnames, strict=False)\n",
    "        learn.freeze()\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification loss and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLabelCEL(nn.CrossEntropyLoss):\n",
    "    def forward(self, input, target, nasp=5):\n",
    "        target = target.long()\n",
    "        loss = 0\n",
    "        for i in range(nasp):\n",
    "            loss = loss + super(MultiLabelCEL, self).forward(input[:,i,:], target[:,i])\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_acc(preds, targs, nasp=5, nrat=5):\n",
    "    preds = preds[:,0:nasp,:]\n",
    "    preds = preds.contiguous().view(-1, nrat)\n",
    "    preds = torch.max(preds, dim=1)[1]\n",
    "    targs = targs.contiguous().view(-1).long()\n",
    "    return (preds==targs).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_0(preds, targs):\n",
    "    preds = torch.max(preds, dim=2)[1]\n",
    "    targs = targs.contiguous().long()\n",
    "    return (preds[:,0]==targs[:,0]).float().mean()\n",
    "def acc_1(preds, targs):\n",
    "    preds = torch.max(preds, dim=2)[1]\n",
    "    targs = targs.contiguous().long()\n",
    "    return (preds[:,1]==targs[:,1]).float().mean()\n",
    "def acc_2(preds, targs):\n",
    "    preds = torch.max(preds, dim=2)[1]\n",
    "    targs = targs.contiguous().long()\n",
    "    return (preds[:,2]==targs[:,2]).float().mean()\n",
    "def acc_3(preds, targs):\n",
    "    preds = torch.max(preds, dim=2)[1]\n",
    "    targs = targs.contiguous().long()\n",
    "    return (preds[:,3]==targs[:,3]).float().mean()\n",
    "def acc_4(preds, targs):\n",
    "    preds = torch.max(preds, dim=2)[1]\n",
    "    targs = targs.contiguous().long()\n",
    "    return (preds[:,4]==targs[:,4]).float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create the objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUSTOM DEFINED CLASSIFIER\n",
      "Encoder init\n",
      "CLS init\n",
      "Num Aspect: 5\n",
      "Num Rating: 5\n",
      "FREEZING\n",
      "Sequential(\n",
      "  (0): Embedding(31600, 400, padding_idx=1)\n",
      "  (1): EmbeddingDropout(\n",
      "    (emb): Embedding(31600, 400, padding_idx=1)\n",
      "  )\n",
      ")\n",
      "FREEZING\n",
      "Sequential(\n",
      "  (0): WeightDropout(\n",
      "    (module): LSTM(400, 1152, batch_first=True)\n",
      "  )\n",
      "  (1): RNNDropout()\n",
      ")\n",
      "FREEZING\n",
      "Sequential(\n",
      "  (0): WeightDropout(\n",
      "    (module): LSTM(1152, 1152, batch_first=True)\n",
      "  )\n",
      "  (1): RNNDropout()\n",
      ")\n",
      "FREEZING\n",
      "Sequential(\n",
      "  (0): WeightDropout(\n",
      "    (module): LSTM(1152, 400, batch_first=True)\n",
      "  )\n",
      "  (1): RNNDropout()\n",
      ")\n",
      "UN-FREEZING\n",
      "Sequential(\n",
      "  (0): Cls02ATT400(\n",
      "    (aspect_projector): Sequential(\n",
      "      (0): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): Dropout(p=0.5, inplace=False)\n",
      "      (2): Linear(in_features=400, out_features=128, bias=True)\n",
      "      (3): GELU()\n",
      "    )\n",
      "    (senti_projector): Sequential(\n",
      "      (0): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): Dropout(p=0.5, inplace=False)\n",
      "      (2): Linear(in_features=400, out_features=128, bias=True)\n",
      "      (3): GELU()\n",
      "    )\n",
      "    (aspect): Sequential(\n",
      "      (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): Dropout(p=0.35, inplace=False)\n",
      "      (2): Linear(in_features=128, out_features=6, bias=True)\n",
      "      (3): Softmax(dim=1)\n",
      "    )\n",
      "    (sentiments): Sequential(\n",
      "      (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): Dropout(p=0.35, inplace=False)\n",
      "      (2): Linear(in_features=128, out_features=5, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "mloss = MultiLabelCEL()\n",
    "cls_learn = text_classifier_learner(cls_db, AWD_LSTM, \n",
    "                                    loss_func=mloss,\n",
    "                                    drop_mult=1.1,\n",
    "                                    metrics=[multi_acc,acc_0,acc_1,acc_2,acc_3,acc_4],\n",
    "                                    bptt=70,\n",
    "                                    max_len=hyper_params[\"max_sequence_length\"],\n",
    "#                                     clip=1.0\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FREEZING\n",
      "Sequential(\n",
      "  (0): Embedding(31600, 400, padding_idx=1)\n",
      "  (1): EmbeddingDropout(\n",
      "    (emb): Embedding(31600, 400, padding_idx=1)\n",
      "  )\n",
      ")\n",
      "FREEZING\n",
      "Sequential(\n",
      "  (0): WeightDropout(\n",
      "    (module): LSTM(400, 1152, batch_first=True)\n",
      "  )\n",
      "  (1): RNNDropout()\n",
      ")\n",
      "FREEZING\n",
      "Sequential(\n",
      "  (0): WeightDropout(\n",
      "    (module): LSTM(1152, 1152, batch_first=True)\n",
      "  )\n",
      "  (1): RNNDropout()\n",
      ")\n",
      "FREEZING\n",
      "Sequential(\n",
      "  (0): WeightDropout(\n",
      "    (module): LSTM(1152, 400, batch_first=True)\n",
      "  )\n",
      "  (1): RNNDropout()\n",
      ")\n",
      "UN-FREEZING\n",
      "Sequential(\n",
      "  (0): Cls02ATT400(\n",
      "    (aspect_projector): Sequential(\n",
      "      (0): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): Dropout(p=0.5, inplace=False)\n",
      "      (2): Linear(in_features=400, out_features=128, bias=True)\n",
      "      (3): GELU()\n",
      "    )\n",
      "    (senti_projector): Sequential(\n",
      "      (0): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): Dropout(p=0.5, inplace=False)\n",
      "      (2): Linear(in_features=400, out_features=128, bias=True)\n",
      "      (3): GELU()\n",
      "    )\n",
      "    (aspect): Sequential(\n",
      "      (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): Dropout(p=0.35, inplace=False)\n",
      "      (2): Linear(in_features=128, out_features=6, bias=True)\n",
      "      (3): Softmax(dim=1)\n",
      "    )\n",
      "    (sentiments): Sequential(\n",
      "      (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): Dropout(p=0.35, inplace=False)\n",
      "      (2): Linear(in_features=128, out_features=5, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "_=cls_learn.load_encoder('lm_enc_beer.1115')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLAS 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>multi_acc</th>\n",
       "      <th>acc_0</th>\n",
       "      <th>acc_1</th>\n",
       "      <th>acc_2</th>\n",
       "      <th>acc_3</th>\n",
       "      <th>acc_4</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.898546</td>\n",
       "      <td>4.593500</td>\n",
       "      <td>0.564130</td>\n",
       "      <td>0.571813</td>\n",
       "      <td>0.556663</td>\n",
       "      <td>0.584432</td>\n",
       "      <td>0.566227</td>\n",
       "      <td>0.541513</td>\n",
       "      <td>11:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.902886</td>\n",
       "      <td>4.802731</td>\n",
       "      <td>0.536738</td>\n",
       "      <td>0.524313</td>\n",
       "      <td>0.543763</td>\n",
       "      <td>0.529095</td>\n",
       "      <td>0.551680</td>\n",
       "      <td>0.534842</td>\n",
       "      <td>11:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.840013</td>\n",
       "      <td>4.460827</td>\n",
       "      <td>0.591818</td>\n",
       "      <td>0.579047</td>\n",
       "      <td>0.581779</td>\n",
       "      <td>0.628757</td>\n",
       "      <td>0.583347</td>\n",
       "      <td>0.586160</td>\n",
       "      <td>11:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.800778</td>\n",
       "      <td>4.393319</td>\n",
       "      <td>0.596520</td>\n",
       "      <td>0.581699</td>\n",
       "      <td>0.578605</td>\n",
       "      <td>0.634826</td>\n",
       "      <td>0.587365</td>\n",
       "      <td>0.600105</td>\n",
       "      <td>10:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.700907</td>\n",
       "      <td>4.350946</td>\n",
       "      <td>0.601157</td>\n",
       "      <td>0.590138</td>\n",
       "      <td>0.589736</td>\n",
       "      <td>0.637076</td>\n",
       "      <td>0.591344</td>\n",
       "      <td>0.597492</td>\n",
       "      <td>09:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>4.714949</td>\n",
       "      <td>4.529812</td>\n",
       "      <td>0.592140</td>\n",
       "      <td>0.582061</td>\n",
       "      <td>0.590620</td>\n",
       "      <td>0.620800</td>\n",
       "      <td>0.578122</td>\n",
       "      <td>0.589093</td>\n",
       "      <td>10:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yifan/anaconda3/envs/saam/lib/python3.7/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/home/yifan/anaconda3/envs/saam/lib/python3.7/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/home/yifan/anaconda3/envs/saam/lib/python3.7/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/home/yifan/anaconda3/envs/saam/lib/python3.7/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/home/yifan/anaconda3/envs/saam/lib/python3.7/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    }
   ],
   "source": [
    "# 2020 AVG + TOKEN PROJECTOR\n",
    "cls_learn.fit_one_cycle( 6 , max_lr=slice(2e-3,2e-2), wd=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = cls_learn.recorder.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_learn.save('hotel.clas.saamv2.learner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNLearner(data=TextClasDataBunch;\n",
       "\n",
       "Train: LabelList (75113 items)\n",
       "x: TextList\n",
       "xxbos a lot of foam xxperiod xxmaj but a lot xxperiod xxmaj in the smell some banana , and then lactic and tart xxperiod xxmaj not a good start xxperiod xxmaj quite dark orange in color , with a lively carbonation ( now visible , under the foam ) xxperiod xxmaj again tending to lactic sourness xxperiod xxmaj same for the taste xxperiod xxmaj with some yeast and banana xxperiod,xxbos xxmaj dark red color , light beige foam , average xxperiod xxmaj in the smell malt and caramel , not really light xxperiod xxmaj again malt and caramel in the taste , not bad in the end xxperiod xxmaj maybe a note of honey in teh back , and a light fruitiness xxperiod xxmaj average body xxperiod xxmaj in the aftertaste a light bitterness , with the malt and red fruit xxperiod xxmaj nothing exceptional , but not bad , drinkable beer xxperiod,xxbos xxmaj almost totally black xxperiod xxmaj beige foam , quite compact , not bad xxperiod xxmaj light smell , just a bit of roast , and some hop xxperiod a bit too light xxperiod xxmaj the taste is light oo , and drinkable , with some malt , roast , hints of coffee xxperiod xxmaj nothing exceptional , but after all drinkable and pleasant xxperiod xxmaj light to average body xxperiod xxmaj in the aftertaste some dust , xxunk roast , hint of caramel , and a bit of bitterness xxperiod xxmaj no defect , drinkable , not bad xxperiod,xxbos xxmaj golden yellow color xxperiod xxmaj white , compact foam , quite creamy xxperiod xxmaj good appearance xxperiod xxmaj fresh smell , with good hop xxperiod xxmaj quite dry , with a good grassy note xxperiod xxmaj hay xxperiod xxmaj fresh and pleasant xxperiod xxmaj more sweet in the mouth , with honey xxperiod xxmaj the hop comes back in the end , and in the aftertaste xxperiod xxmaj not bad , but a bit too sweet for a pils xxperiod xxmaj in the end some vanilla and camomile note xxperiod xxmaj in the aftertaste , too xxperiod xxmaj though the hop , a bit too sweet xxperiod xxmaj honest xxperiod,xxbos 22 oz bottle from \" xxmaj lifesource \" xxmaj salem xxperiod $ 3 xxperiod 95 xxmaj nice golden clear beer body with a nice sized frothy / creamy white head xxperiod xxmaj ok aromas xxperiod mainlly a bit of ginger xxunk and some bready malt xxperiod simple nice xxmaj taste very nice indeed xxperiod nice spicy ginger backed with slightly caramel maltiness xxperiod simple again but i like xxperiod xxmaj liked the mouthfeel of this one xxperiod very forward carbonation which helps the ginger effect and a lingering ginger in the after taste xxperiod xxmaj overall a simple ginger brew xxperiod i liked it xxperiod\n",
       "y: MultiCategoryList\n",
       "4,,,,\n",
       "Path: ../../data;\n",
       "\n",
       "Valid: LabelList (24884 items)\n",
       "x: TextList\n",
       "xxbos xxmaj according to the website , the style for the xxmaj caldera xxmaj cauldron changes every year xxunk xxperiod xxmaj the current release is a xxup dipa , which frankly is the only cauldron i 'm familiar with ( it was an xxup ipa / xxup dipa the last time i ordered a cauldron at the xxunk several years back ) xxunk xxperiod xxmaj in any event xxunk xxperiod at the xxmaj horse xxmaj brass yesterday xxunk xxperiod xxmaj the beer pours an orange copper color with good head retention and lacing xxunk xxperiod xxmaj the nose is all hoppy xxup ipa goodness , showcasing a huge aroma of dry citrus , pine and xxunk xxunk xxperiod xxmaj the flavor profile replicates the nose pretty closely in this xxmaj west xxmaj coast all the way xxup dipa xxunk xxperiod xxmaj this xxup dipa is not for the faint of heart and is a bit much even for a hophead like xxunk xxunk xxperiod xxmaj the finish is quite dry and hoppy , and there 's barely enough sweet malt to balance and hold up the avalanche of hoppy bitterness in this beer xxunk xxperiod xxmaj mouthfeel is actually fairly light , with a long , xxunk bitter finish xxunk xxperiod xxmaj drinkability is good , with the alcohol barely noticeable in this well crafted beer xxunk xxperiod xxmaj still , this beer is so hugely hoppy / bitter , it 's really hard for me to imagine ordering more than a single glass xxunk xxperiod xxmaj regardless , this is a very impressive beer from the folks at xxmaj caldera xxunk xxperiod,xxbos xxmaj poured from the bottle into a xxmaj chimay goblet xxunk xxperiod xxmaj appearance : xxmaj pours a slightly cloudy yellow / orange color with a half finger of fluffy white head xxunk xxperiod xxmaj the head fades to a small layer on top of the pour xxunk xxperiod xxmaj smell : xxmaj very light and crisp xxunk xxperiod i 'm definitely picking up the ginger , but it 's not overly powerful xxunk xxperiod xxmaj there is a slight sweetness from the malt as well xxunk xxperiod xxmaj taste : xxmaj very light and refreshing xxunk xxperiod xxmaj the ginger shows up right away and then fades towards the finish of the sip xxunk xxperiod xxmaj the finish is malty and bread like xxunk xxperiod xxmaj mouthfeel : xxmaj the body is on the thin side with smooth carbonation and a very dry finish xxunk xxperiod xxmaj overall : xxmaj this is a light and refreshing beer , but nothing spectacular xxunk xxperiod xxmaj the amount of ginger is nice , but i would have liked to have more going on xxunk xxperiod,xxbos xxmaj notes from 6 / 24 xxunk xxperiod a : xxmaj bright golden glowing beer in a moment of clarity with a lively white head of feathery fluff xxunk xxperiod s : xxmaj the ginger is definitely there , or am i smelling my xxmaj indian dinner ? xxmaj almost cake - like in its malt aroma , sharply bready with a slight edge of sweetness xxunk xxperiod t : xxmaj nice clear malty throat taste , reminds me of strands of complex sugars and grains , ginger is more subtle than i expected , more of an undertone than a backbone xxunk xxperiod m : a refreshing light beer feel , like a pilsner or summer ale xxunk xxperiod d : xxmaj if this was a sixer instead of a double - deuce , i could see this being a fine picnic pounder xxunk xxperiod xxmaj overall , pretty impressed for the particular style xxunk xxperiod,xxbos 22 oz xxunk xxperiod bomber , xxunk xxperiod a : xxmaj pours a clear yellow with a mild white head , good retention xxunk xxperiod s : xxmaj great nose of ginger , honey , perfume xxunk xxperiod t : xxmaj rather light upfront , it reminds me of xxmaj lawnmower , with a hint of ale fruitiness / xxmaj kolsch - like almost xxunk xxperiod xxmaj good ginger honey notes on the back end , not taking over the beer in any way xxunk xxperiod xxmaj the ginger flavour is clear , but i wanted it to come out a little more in the end xxunk xxperiod m : xxmaj very light - bodied , watery , light base beer for sure xxunk xxperiod d : xxmaj an easy drinking spiced beer , this will offend no one , but there 's not a complexity to this brew at all xxunk xxperiod,xxbos xxmaj brown in color , somewhere between a porter and a brown ale xxunk xxperiod xxmaj lacking in aroma , but no off stuff xxunk xxperiod xxmaj same with the taste , lacking flavor , complexity , just went with smoothness xxunk xxperiod xxmaj no off flavors though , so i ca n't say this is bad , just xxunk , especially for xxmaj caldera , whom i think is generally underrated xxunk xxperiod xxmaj you really have to search to pull anything out of this in terms of the usual chocolate / coffee flavors , really , the only thing i can tell is that the oats did their job , because this is smooth and unoffensive xxunk xxperiod xxmaj other than that , extremely pedestrian xxunk xxperiod\n",
       "y: MultiCategoryList\n",
       ",,,,\n",
       "Path: ../../data;\n",
       "\n",
       "Test: None, model=SequentialRNN(\n",
       "  (0): SentenceEncoder(\n",
       "    (module): AWD_LSTM(\n",
       "      (encoder): Embedding(31600, 400, padding_idx=1)\n",
       "      (encoder_dp): EmbeddingDropout(\n",
       "        (emb): Embedding(31600, 400, padding_idx=1)\n",
       "      )\n",
       "      (rnns): ModuleList(\n",
       "        (0): WeightDropout(\n",
       "          (module): LSTM(400, 1152, batch_first=True)\n",
       "        )\n",
       "        (1): WeightDropout(\n",
       "          (module): LSTM(1152, 1152, batch_first=True)\n",
       "        )\n",
       "        (2): WeightDropout(\n",
       "          (module): LSTM(1152, 400, batch_first=True)\n",
       "        )\n",
       "      )\n",
       "      (input_dp): RNNDropout()\n",
       "      (hidden_dps): ModuleList(\n",
       "        (0): RNNDropout()\n",
       "        (1): RNNDropout()\n",
       "        (2): RNNDropout()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): Cls02ATT400(\n",
       "    (aspect_projector): Sequential(\n",
       "      (0): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.5, inplace=False)\n",
       "      (2): Linear(in_features=400, out_features=128, bias=True)\n",
       "      (3): GELU()\n",
       "    )\n",
       "    (senti_projector): Sequential(\n",
       "      (0): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.5, inplace=False)\n",
       "      (2): Linear(in_features=400, out_features=128, bias=True)\n",
       "      (3): GELU()\n",
       "    )\n",
       "    (aspect): Sequential(\n",
       "      (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.35, inplace=False)\n",
       "      (2): Linear(in_features=128, out_features=6, bias=True)\n",
       "      (3): Softmax(dim=1)\n",
       "    )\n",
       "    (sentiments): Sequential(\n",
       "      (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.35, inplace=False)\n",
       "      (2): Linear(in_features=128, out_features=5, bias=True)\n",
       "    )\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=MultiLabelCEL(), metrics=[<function multi_acc at 0x7f98307cbc20>, <function acc_0 at 0x7f98307cb950>, <function acc_1 at 0x7f98307cbef0>, <function acc_2 at 0x7f981fdb8050>, <function acc_3 at 0x7f981fdb8170>, <function acc_4 at 0x7f981fdb8290>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('../../data'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
       "learn: ...\n",
       "alpha: 2.0\n",
       "beta: 1.0], layer_groups=[Sequential(\n",
       "  (0): Embedding(31600, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(31600, 400, padding_idx=1)\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): Cls02ATT400(\n",
       "    (aspect_projector): Sequential(\n",
       "      (0): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.5, inplace=False)\n",
       "      (2): Linear(in_features=400, out_features=128, bias=True)\n",
       "      (3): GELU()\n",
       "    )\n",
       "    (senti_projector): Sequential(\n",
       "      (0): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.5, inplace=False)\n",
       "      (2): Linear(in_features=400, out_features=128, bias=True)\n",
       "      (3): GELU()\n",
       "    )\n",
       "    (aspect): Sequential(\n",
       "      (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.35, inplace=False)\n",
       "      (2): Linear(in_features=128, out_features=6, bias=True)\n",
       "      (3): Softmax(dim=1)\n",
       "    )\n",
       "    (sentiments): Sequential(\n",
       "      (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.35, inplace=False)\n",
       "      (2): Linear(in_features=128, out_features=5, bias=True)\n",
       "    )\n",
       "  )\n",
       ")], add_time=True, silent=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_learn.load('hotel.clas.saamv2.learner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UN-FREEZING\n",
      "Sequential(\n",
      "  (0): Embedding(31600, 400, padding_idx=1)\n",
      "  (1): EmbeddingDropout(\n",
      "    (emb): Embedding(31600, 400, padding_idx=1)\n",
      "  )\n",
      ")\n",
      "UN-FREEZING\n",
      "Sequential(\n",
      "  (0): WeightDropout(\n",
      "    (module): LSTM(400, 1152, batch_first=True)\n",
      "  )\n",
      "  (1): RNNDropout()\n",
      ")\n",
      "UN-FREEZING\n",
      "Sequential(\n",
      "  (0): WeightDropout(\n",
      "    (module): LSTM(1152, 1152, batch_first=True)\n",
      "  )\n",
      "  (1): RNNDropout()\n",
      ")\n",
      "UN-FREEZING\n",
      "Sequential(\n",
      "  (0): WeightDropout(\n",
      "    (module): LSTM(1152, 400, batch_first=True)\n",
      "  )\n",
      "  (1): RNNDropout()\n",
      ")\n",
      "UN-FREEZING\n",
      "Sequential(\n",
      "  (0): Cls02ATT400(\n",
      "    (aspect_projector): Sequential(\n",
      "      (0): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): Dropout(p=0.5, inplace=False)\n",
      "      (2): Linear(in_features=400, out_features=128, bias=True)\n",
      "      (3): GELU()\n",
      "    )\n",
      "    (senti_projector): Sequential(\n",
      "      (0): BatchNorm1d(400, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): Dropout(p=0.5, inplace=False)\n",
      "      (2): Linear(in_features=400, out_features=128, bias=True)\n",
      "      (3): GELU()\n",
      "    )\n",
      "    (aspect): Sequential(\n",
      "      (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): Dropout(p=0.35, inplace=False)\n",
      "      (2): Linear(in_features=128, out_features=6, bias=True)\n",
      "      (3): Softmax(dim=1)\n",
      "    )\n",
      "    (sentiments): Sequential(\n",
      "      (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): Dropout(p=0.35, inplace=False)\n",
      "      (2): Linear(in_features=128, out_features=5, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cls_learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>multi_acc</th>\n",
       "      <th>acc_0</th>\n",
       "      <th>acc_1</th>\n",
       "      <th>acc_2</th>\n",
       "      <th>acc_3</th>\n",
       "      <th>acc_4</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.668399</td>\n",
       "      <td>4.313121</td>\n",
       "      <td>0.601632</td>\n",
       "      <td>0.589535</td>\n",
       "      <td>0.587767</td>\n",
       "      <td>0.635187</td>\n",
       "      <td>0.597452</td>\n",
       "      <td>0.598216</td>\n",
       "      <td>12:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.574408</td>\n",
       "      <td>4.301300</td>\n",
       "      <td>0.604107</td>\n",
       "      <td>0.593032</td>\n",
       "      <td>0.595242</td>\n",
       "      <td>0.627793</td>\n",
       "      <td>0.599904</td>\n",
       "      <td>0.604565</td>\n",
       "      <td>11:55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.507301</td>\n",
       "      <td>4.271932</td>\n",
       "      <td>0.605883</td>\n",
       "      <td>0.599582</td>\n",
       "      <td>0.597090</td>\n",
       "      <td>0.644430</td>\n",
       "      <td>0.587245</td>\n",
       "      <td>0.601069</td>\n",
       "      <td>11:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.485294</td>\n",
       "      <td>4.329984</td>\n",
       "      <td>0.602668</td>\n",
       "      <td>0.598376</td>\n",
       "      <td>0.592349</td>\n",
       "      <td>0.639809</td>\n",
       "      <td>0.581418</td>\n",
       "      <td>0.601390</td>\n",
       "      <td>12:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.393159</td>\n",
       "      <td>4.194492</td>\n",
       "      <td>0.615214</td>\n",
       "      <td>0.608986</td>\n",
       "      <td>0.597131</td>\n",
       "      <td>0.649293</td>\n",
       "      <td>0.602194</td>\n",
       "      <td>0.618470</td>\n",
       "      <td>12:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>4.395024</td>\n",
       "      <td>4.136134</td>\n",
       "      <td>0.620479</td>\n",
       "      <td>0.609026</td>\n",
       "      <td>0.606092</td>\n",
       "      <td>0.651503</td>\n",
       "      <td>0.613045</td>\n",
       "      <td>0.622729</td>\n",
       "      <td>12:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>4.373187</td>\n",
       "      <td>4.133709</td>\n",
       "      <td>0.621219</td>\n",
       "      <td>0.609749</td>\n",
       "      <td>0.602998</td>\n",
       "      <td>0.653512</td>\n",
       "      <td>0.615657</td>\n",
       "      <td>0.624176</td>\n",
       "      <td>12:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>4.352146</td>\n",
       "      <td>4.144817</td>\n",
       "      <td>0.619249</td>\n",
       "      <td>0.612361</td>\n",
       "      <td>0.598497</td>\n",
       "      <td>0.659219</td>\n",
       "      <td>0.606936</td>\n",
       "      <td>0.619233</td>\n",
       "      <td>12:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>4.380236</td>\n",
       "      <td>4.159314</td>\n",
       "      <td>0.619418</td>\n",
       "      <td>0.611718</td>\n",
       "      <td>0.601471</td>\n",
       "      <td>0.655883</td>\n",
       "      <td>0.608182</td>\n",
       "      <td>0.619836</td>\n",
       "      <td>12:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>4.333897</td>\n",
       "      <td>4.116521</td>\n",
       "      <td>0.621934</td>\n",
       "      <td>0.612562</td>\n",
       "      <td>0.600948</td>\n",
       "      <td>0.658174</td>\n",
       "      <td>0.613286</td>\n",
       "      <td>0.624699</td>\n",
       "      <td>12:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yifan/anaconda3/envs/saam/lib/python3.7/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/home/yifan/anaconda3/envs/saam/lib/python3.7/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/home/yifan/anaconda3/envs/saam/lib/python3.7/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/home/yifan/anaconda3/envs/saam/lib/python3.7/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/home/yifan/anaconda3/envs/saam/lib/python3.7/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/home/yifan/anaconda3/envs/saam/lib/python3.7/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/home/yifan/anaconda3/envs/saam/lib/python3.7/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/home/yifan/anaconda3/envs/saam/lib/python3.7/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/home/yifan/anaconda3/envs/saam/lib/python3.7/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/home/yifan/anaconda3/envs/saam/lib/python3.7/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    }
   ],
   "source": [
    "# 2020 AVG + TokenProj\n",
    "cls_learn.fit_one_cycle(10, wd=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2020 AVG\n",
    "fig = cls_learn.recorder.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_learn.save('hotel.clas.saamv2.2.learner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_num_file = [\"aspect_0.count\", \"test_aspect_0.count\"]\n",
    "rating_file = [\"aspect_0.rating\", \"test_aspect_0.rating\"]\n",
    "content_file = [\"aspect_0.txt\", \"test_aspect_0.txt\"]\n",
    "\n",
    "dataset_dir = \"./data/hotel_balance_LengthFix1_3000per/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_to_doc(sent_list, sent_count):\n",
    "    start_index = 0\n",
    "    docs = []\n",
    "    for s in sent_count:\n",
    "#         doc = \" xxPERIOD \".join(sent_list[start_index:start_index + s])\n",
    "#         doc = doc + \" xxPERIOD \"\n",
    "        docs.append(sent_list[start_index:start_index + s])\n",
    "        start_index = start_index + s\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA = 0\n",
    "TEST_DATA = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 30, 25, 33, 29]\n",
      "   0  1  2  3  4  5\n",
      "0  1  0  0  3  1  1\n",
      "1  2  2  1  2  3  3\n",
      "2  4  4  4  3  4  4\n",
      "3  3  2  3  3  3  4\n",
      "4  3  4  3  4  4  4\n"
     ]
    }
   ],
   "source": [
    "# Load Count\n",
    "sent_count_test = list(open(dataset_dir + sent_num_file[TEST_DATA], \"r\").readlines())\n",
    "sent_count_test = [int(s) for s in sent_count_test if (len(s) > 0 and s != \"\\n\")]\n",
    "print( sent_count_test[0:5] )\n",
    "\n",
    "# Load Ratings\n",
    "aspect_rating_test = list(open(dataset_dir + rating_file[TEST_DATA], \"r\").readlines())\n",
    "aspect_rating_test = [s for s in aspect_rating_test if (len(s) > 0 and s != \"\\n\")]\n",
    "\n",
    "aspect_rating_test = [s.split(\" \") for s in aspect_rating_test]\n",
    "aspect_rating_test = np.array(aspect_rating_test)[:, 0:-1]\n",
    "aspect_rating_test = aspect_rating_test.astype(np.int) - 1\n",
    "aspect_rating_test = pd.DataFrame(aspect_rating_test)\n",
    "print( aspect_rating_test.head() )\n",
    "\n",
    "# Load Sents\n",
    "sents_test = list(open(dataset_dir + content_file[TEST_DATA], \"r\").readlines())\n",
    "sents_test = [s.strip() for s in sents_test]\n",
    "\n",
    "# Sents to Doc\n",
    "docs_test = concat_to_doc(sents_test, sent_count_test)\n",
    "\n",
    "docs_test = pd.DataFrame({doc:docs_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[definitely not a 5 star resort i 'm dumbfound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>[facilities need work, we visited excellence f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[excellence was exactly that, my family and i ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>[great service , nice hotel , mediocre food, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>[very relaxing experience just returned from m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4  5                                                  6\n",
       "0  1  0  0  3  1  1  [definitely not a 5 star resort i 'm dumbfound...\n",
       "1  2  2  1  2  3  3  [facilities need work, we visited excellence f...\n",
       "2  4  4  4  3  4  4  [excellence was exactly that, my family and i ...\n",
       "3  3  2  3  3  3  4  [great service , nice hotel , mediocre food, m...\n",
       "4  3  4  3  4  4  4  [very relaxing experience just returned from m..."
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.concat( [aspect_rating_test, docs_test], axis=1, ignore_index=True )\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clas_acc(asp_index):\n",
    "    def asp_acc(preds, targs):\n",
    "        preds = torch.max(preds, dim=2)[1]\n",
    "        targs = targs.contiguous().long()\n",
    "        return (preds[:,asp_index]==targs[:,asp_index]).float().mean()\n",
    "    return asp_acc\n",
    "def get_clas_mse(asp_index):\n",
    "    def asp_mse(preds, targs):\n",
    "        preds = torch.max(preds, dim=2)[1].float()[:,asp_index]\n",
    "        targs = targs.contiguous().float()[:,asp_index]\n",
    "        return torch.nn.functional.mse_loss(preds, targs)\n",
    "    return asp_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds(self,\n",
    "              ds_type:DatasetType,\n",
    "              activ:nn.Module=None,\n",
    "              with_loss:bool=False,\n",
    "              n_batch:Optional[int]=None,\n",
    "              pbar:Optional[PBar]=None,\n",
    "              ordered:bool=False) -> List[Tensor]:\n",
    "    \"Return predictions and targets on the valid, train, or test set, depending on `ds_type`.\"\n",
    "    self.model.reset()\n",
    "    if ordered: np.random.seed(42)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outs = []\n",
    "        asps = []\n",
    "        for xb,yb in progress_bar(cls_learn.dl(ds_type)):\n",
    "            out,raw_enc,enc,asp = cls_learn.model(xb)\n",
    "            outs.append(out)\n",
    "            for doc in asp:\n",
    "                asps.append( to_float(doc.cpu()))\n",
    "\n",
    "    outs = to_float(torch.cat(outs).cpu())\n",
    "    \n",
    "    if ordered and hasattr(self.dl(ds_type), 'sampler'):\n",
    "        np.random.seed(42)\n",
    "        sampler = [i for i in self.dl(ds_type).sampler]\n",
    "        reverse_sampler = np.argsort(sampler)\n",
    "        \n",
    "        outs = outs[reverse_sampler]\n",
    "        asps = [asps[i] for i in reverse_sampler]\n",
    "    return (outs,asps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='117' class='' max='117' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [117/117 00:23<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "outs,asps = get_preds(self=cls_learn, ds_type=DatasetType.Valid, ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0, 3, 1, 1],\n",
       "        [2, 2, 1, 2, 3, 3],\n",
       "        [4, 4, 4, 3, 4, 4],\n",
       "        ...,\n",
       "        [0, 0, 0, 3, 0, 2],\n",
       "        [0, 0, 0, 2, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 1]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = torch.tensor( aspect_rating_test.values )\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASP0</th>\n",
       "      <th>ASP1</th>\n",
       "      <th>ASP2</th>\n",
       "      <th>ASP3</th>\n",
       "      <th>ASP4</th>\n",
       "      <th>ASP5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.677721</td>\n",
       "      <td>0.60444</td>\n",
       "      <td>0.555764</td>\n",
       "      <td>0.485691</td>\n",
       "      <td>0.549077</td>\n",
       "      <td>0.57395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ASP0     ASP1      ASP2      ASP3      ASP4     ASP5\n",
       "0  0.677721  0.60444  0.555764  0.485691  0.549077  0.57395"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict( {\"ASP\"+str(ai):[get_clas_acc(ai)(outs, target).item()] for ai in range(6)} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASP0</th>\n",
       "      <th>ASP1</th>\n",
       "      <th>ASP2</th>\n",
       "      <th>ASP3</th>\n",
       "      <th>ASP4</th>\n",
       "      <th>ASP5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.401444</td>\n",
       "      <td>0.576625</td>\n",
       "      <td>0.675582</td>\n",
       "      <td>0.999465</td>\n",
       "      <td>0.750201</td>\n",
       "      <td>0.878042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ASP0      ASP1      ASP2      ASP3      ASP4      ASP5\n",
       "0  0.401444  0.576625  0.675582  0.999465  0.750201  0.878042"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict( {\"ASP\"+str(ai):[get_clas_mse(ai)(outs, target).item()] for ai in range(6)} )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize classification output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truth:\n",
      "[1, 0, 0, 3, 1, 1]\n",
      "prediction:\n",
      "tensor([1, 0, 0, 2, 0, 0])\n",
      "doc:\n",
      "definitely not a 5 star resort i 'm dumbfounded that this hotel gets good reviews and is so highly rated\n",
      "          +++ overall +++ value +++ [0.276 0.168 0.095 0.054 0.067 0.142]\n",
      "it 's decidedly a 3 star property , not 5 stars as indicated\n",
      "          +++ overall +++ room +++ [0.219 0.146 0.165 0.075 0.078 0.12 ]\n",
      "the rooms are very dated and run down , old crappy beds and pillows , an old tv and overall poorly maintained\n",
      "          +++ room +++ room +++ [0.078 0.067 0.608 0.022 0.199 0.025]\n",
      "the whole property is pretty run down and old - looking\n",
      "          +++ room +++ room +++ [0.143 0.113 0.34  0.095 0.238 0.056]\n",
      "the food is subpar , not one meal i had would be called great\n",
      "          +++ overall +++ service +++ [0.222 0.149 0.052 0.082 0.075 0.178]\n",
      "the service is uneven and the staff is poorly trained and uninformed\n",
      "          +++ service +++ service +++ [0.024 0.018 0.002 0.004 0.008 0.943]\n",
      "many do not comprehend english\n",
      "          +++ service +++ service +++ [0.101 0.059 0.021 0.027 0.035 0.708]\n",
      "the beach is great , it 's the only redeeming factor\n",
      "          +++ location +++ location +++ [0.011 0.008 0.003 0.293 0.003 0.009]\n",
      "however the resort is a 1- hour taxi trip from the airport\n",
      "          +++ location +++ location +++ [0.114 0.095 0.045 0.405 0.02  0.063]\n",
      "===========\n",
      "truth:\n",
      "[2, 2, 1, 2, 3, 3]\n",
      "prediction:\n",
      "tensor([3, 3, 1, 3, 3, 2])\n",
      "doc:\n",
      "facilities need work\n",
      "          +++ overall +++ service +++ [0.144 0.085 0.094 0.046 0.061 0.132]\n",
      "we visited excellence for 5 nights in december\n",
      "          +++ overall +++ value +++ [0.304 0.144 0.083 0.059 0.073 0.132]\n",
      "our first room , #1112, had a safe that did not work and so - so air conditioning\n",
      "          +++ room +++ room +++ [0.13  0.083 0.446 0.07  0.115 0.08 ]\n",
      "when we went to the front desk to complain , we were told to go to the room and someone would be there within 15 minutes\n",
      "          +++ service +++ service +++ [0.061 0.038 0.059 0.042 0.021 0.104]\n",
      "45 minutes later , the safe guy showed up , but nobody for the a/c\n",
      "          +++ service +++ service +++ [0.049 0.035 0.044 0.033 0.014 0.092]\n",
      "the safe guy could not fix it\n",
      "          +++ service +++ service +++ [0.08  0.051 0.109 0.041 0.032 0.127]\n",
      "when he left , the electricity went out\n",
      "          +++ service +++ service +++ [0.066 0.043 0.073 0.03  0.021 0.107]\n",
      "it went out a second time before we finally went to the front desk to change rooms\n",
      "          +++ service +++ service +++ [0.058 0.041 0.046 0.043 0.015 0.083]\n",
      "we had dinner that night in the lobster house\n",
      "          +++ overall +++ service +++ [0.115 0.072 0.083 0.059 0.038 0.097]\n",
      "do not waste your time on this one\n",
      "          +++ overall +++ service +++ [0.131 0.082 0.068 0.071 0.045 0.128]\n",
      "the lobster tails had about 2 bites of food included\n",
      "          +++ overall +++ value +++ [0.143 0.084 0.065 0.045 0.039 0.077]\n",
      "while we were in there , the electricity went out again\n",
      "          +++ service +++ service +++ [0.111 0.071 0.089 0.044 0.039 0.115]\n",
      "room 3002 served us pretty well , until night #3 when my partner got up to go to the bathroom and stepped into an inch of water\n",
      "          +++ service +++ service +++ [0.102 0.066 0.114 0.048 0.051 0.144]\n",
      "a hose had broken on the back of the toilet and flooded our room\n",
      "          +++ room +++ room +++ [0.161 0.112 0.363 0.052 0.134 0.114]\n",
      "it would 've been ok , but when we went to the front desk we were told that we needed to wait until noon to see if perhaps they could move us to another room\n",
      "          +++ room +++ room +++ [0.1   0.062 0.137 0.065 0.059 0.134]\n",
      "the front desk clerks were not empowered to just move us\n",
      "          +++ service +++ service +++ [0.109 0.065 0.063 0.056 0.035 0.325]\n",
      "my partner was infuriated that they wanted us to wait 4 hours for a new room\n",
      "          +++ service +++ service +++ [0.063 0.04  0.067 0.035 0.019 0.094]\n",
      "finally , matias at the front desk finally arranged to have us moved to another upgraded room - 3109\n",
      "          +++ service +++ service +++ [0.068 0.04  0.078 0.045 0.025 0.106]\n",
      "we walked in and saw the leak coming from the ceiling and nearly flipped\n",
      "          +++ room +++ room +++ [0.135 0.091 0.264 0.064 0.084 0.107]\n",
      "we finally got into #3110, which was a gorgeous suite with a beautiful view\n",
      "          +++ room +++ room +++ [0.087 0.056 0.285 0.081 0.068 0.068]\n",
      "on the positive side , the food at the other restaurants was very good\n",
      "          +++ service +++ service +++ [0.176 0.104 0.102 0.102 0.083 0.197]\n",
      "i particularly liked the french restaurant , while my partner liked the asian restaurant\n",
      "          +++ overall +++ service +++ [0.192 0.094 0.105 0.086 0.088 0.182]\n",
      "the breakfast buffet was like nothing i 'd ever seen before - lots of choices\n",
      "          +++ service +++ service +++ [0.157 0.09  0.035 0.078 0.044 0.175]\n",
      "the ocean was way too rough to enjoy , particularly if you 're not a strong swimmer\n",
      "          +++ location +++ location +++ [0.04  0.026 0.017 0.537 0.01  0.013]\n",
      "much of the beach was black flagged the entire time we were there , so if you 're a big ocean fan , i do not recommend this resort\n",
      "          +++ location +++ location +++ [0.058 0.04  0.024 0.403 0.018 0.024]\n",
      "my favorite part , by far , though , were the beds next to the pools and ocean\n",
      "          +++ location +++ location +++ [0.133 0.082 0.118 0.215 0.081 0.109]\n",
      "they were amazing\n",
      "          +++ room +++ room +++ [0.059 0.031 0.082 0.052 0.048 0.04 ]\n",
      "i guess you could particularly say so since the beds in the rooms were hard as rocks\n",
      "          +++ room +++ room +++ [0.138 0.073 0.3   0.073 0.11  0.088]\n",
      "all in all , a good trip - highly recommend the zip line tour\n",
      "          +++ overall +++ value +++ [0.303 0.203 0.115 0.127 0.061 0.14 ]\n",
      "it was worth every penny\n",
      "          +++ location +++ location +++ [0.121 0.092 0.037 0.137 0.022 0.055]\n",
      "===========\n",
      "truth:\n",
      "[4, 4, 4, 3, 4, 4]\n",
      "prediction:\n",
      "tensor([4, 4, 4, 4, 4, 4])\n",
      "doc:\n",
      "excellence was exactly that\n",
      "          +++ overall +++ service +++ [0.303 0.143 0.062 0.062 0.061 0.292]\n",
      "my family and i stayed at the excellence punta cana from december 22 to december 29 of this year\n",
      "          +++ overall +++ service +++ [0.335 0.152 0.076 0.068 0.071 0.243]\n",
      "it was an amazing time had by all that attended\n",
      "          +++ overall +++ service +++ [0.296 0.146 0.06  0.082 0.061 0.252]\n",
      "we arrived at the resort around 4 am because of a delay at the airport in vancouver , but even at 4 am , the service of the bellhops and the front desk was up to par\n",
      "          +++ service +++ service +++ [0.143 0.088 0.08  0.088 0.057 0.27 ]\n",
      "our bags were unloaded and immediately tagged and set to one side of the lobby while we were handed cold scented towels to cool off with\n",
      "          +++ service +++ service +++ [0.096 0.07  0.103 0.043 0.074 0.286]\n",
      "check in was fairly expedient and we were in our rooms within twenty minutes\n",
      "          +++ service +++ service +++ [0.071 0.045 0.091 0.044 0.033 0.107]\n",
      "i had never been to an all inclusive resort before , and wasted no time enjoying the pleasures of the mini bar in the room , as well as the ample storage space for our things\n",
      "          +++ service +++ service +++ [0.16  0.115 0.19  0.071 0.12  0.232]\n",
      "room service even at 4 am was great , the girl on the phone said it would be about 40 minutes for the food , which seemed a little long , but i think they only say that to cover there butts , because it took about 25 minutes at most\n",
      "          +++ service +++ service +++ [0.127 0.082 0.084 0.057 0.096 0.422]\n",
      "the activities during the day were well thought out , though , there was some delays and cancellations due to weather conditions ( beach volleyball cancelled to due strong winds\n",
      "          +++ overall +++ location +++ [0.146 0.091 0.057 0.129 0.05  0.085]\n",
      "the entertainment staff was amazing and extremely friendly , a special thanks to all my friends , ines ( my fiance , ) altagracia ( who lovingly reffered to me as flaco loco , which translates into crazy skinny guy , ) eliza and johanna ( my disco dance partners , ) sexy cesar ( who taught me all the sexy dance moves i\n",
      "          +++ service +++ service +++ [0.16  0.077 0.065 0.059 0.072 0.366]\n",
      "now know , ) julio cesar ( the mc for the games and parties\n",
      "          +++ service +++ service +++ [0.181 0.088 0.108 0.061 0.085 0.276]\n",
      "the restaurants i ca not offer too much help with , i did not eat at all of them , but of the few i did eat at , i recommend toscana for the huge buffet everyday , breakfast here is well prepared and quite delicious ( although i do not recommend the scrambled eggs\n",
      "          +++ service +++ service +++ [0.199 0.102 0.07  0.083 0.081 0.224]\n",
      "the omlettes are delicious and you have to try one\n",
      "          +++ overall +++ service +++ [0.149 0.075 0.039 0.052 0.047 0.139]\n",
      "for lunch , you have to check out the grill on the beach , different food everyday , always good , and makes the beach smell amazing\n",
      "          +++ overall +++ service +++ [0.186 0.099 0.058 0.08  0.078 0.159]\n",
      "for dinner , i liked spice ( asian cuisine , ) agave ( mexican , but do not eat the calimari from here , very rubbery , ) the pizza that is delivered to the pool and the beach is awesome , make sure you try that\n",
      "          +++ overall +++ service +++ [0.209 0.1   0.075 0.094 0.083 0.173]\n",
      "the bars were awesome , you get accustomed to speaking the language when ordering drinks , instead of drinking your usual bacardi and coke , try the brugal extra anejo , they call it the dominican babymaker , and it 's obvious why once you try it\n",
      "          +++ service +++ service +++ [0.139 0.076 0.062 0.05  0.065 0.21 ]\n",
      "the stuff tastes amazing and it does magic for someone trying to loosen up on the dance floor\n",
      "          +++ service +++ service +++ [0.119 0.061 0.051 0.044 0.043 0.136]\n",
      "the disco is great too , although sometimes a little empty , but still worth checking out\n",
      "          +++ overall +++ service +++ [0.105 0.06  0.047 0.056 0.038 0.08 ]\n",
      "the worst part of my trip was the vendors , they do not let up , and i am a very well mannered person , which makes it hard to shut them down over and over again , make sure you do not tell them you like anything until you know you 're going to buy it , otherwise you 'll have to beat\n",
      "          +++ service +++ service +++ [0.08  0.044 0.031 0.041 0.027 0.114]\n",
      "them off with a stick to get away\n",
      "          +++ overall +++ service +++ [0.05  0.033 0.027 0.024 0.014 0.047]\n",
      "try to make it to the theatre for the shows at 10pm every night , they are worth it\n",
      "          +++ overall +++ service +++ [0.11  0.068 0.05  0.062 0.038 0.082]\n",
      "the ice breaker shows are fun too , it gets people into the swing of things\n",
      "          +++ overall +++ service +++ [0.074 0.041 0.034 0.04  0.023 0.051]\n",
      "all in all , i would highly recommend this resort for anyone going on a honeymoon or a romantic time with the better half , there is not a very big single crowd , so parents beware taking your single sons and daughters to this resort if they 're looking to party with other singles\n",
      "          +++ overall +++ value +++ [0.339 0.193 0.107 0.113 0.061 0.117]\n",
      "hope this helps you\n",
      "          +++ overall +++ service +++ [0.117 0.05  0.065 0.047 0.034 0.084]\n",
      "adios amigos and amigas\n",
      "          +++ service +++ service +++ [0.251 0.101 0.105 0.078 0.075 0.255]\n",
      "===========\n",
      "truth:\n",
      "[3, 2, 3, 3, 3, 4]\n",
      "prediction:\n",
      "tensor([3, 3, 3, 3, 4, 4])\n",
      "doc:\n",
      "great service , nice hotel , mediocre food\n",
      "          +++ service +++ service +++ [0.17  0.118 0.072 0.053 0.069 0.434]\n",
      "my husband and i stayed at excellence for five nights mid - november\n",
      "          +++ overall +++ value +++ [0.348 0.173 0.087 0.08  0.067 0.172]\n",
      "we booked our trip at the very last minute so we were not able to do a ton of research on the dominican but the hotel receives high ratings thorughout the web\n",
      "          +++ overall +++ value +++ [0.116 0.08  0.049 0.057 0.027 0.052]\n",
      "after the one hour ride from the airport we arrived at the hotel and were greeted by everyone we met\n",
      "          +++ service +++ service +++ [0.109 0.071 0.064 0.097 0.038 0.155]\n",
      "i have to say that the staff at the hotel were very nice and made every effort to learn our names and greet us by name each time they saw us\n",
      "          +++ service +++ service +++ [0.083 0.05  0.034 0.028 0.052 0.723]\n",
      "we opted to upgrade to the excellence club and we are still trying to decide if we think it was worth it or not\n",
      "          +++ service +++ service +++ [0.169 0.101 0.121 0.075 0.073 0.197]\n",
      "as part of the excellence club , you are ushered to the club 's private lobby for check - in but , really , it almost just creates an unneccesary step in the check - in process and adds another person or two you feel like you should tip\n",
      "          +++ service +++ service +++ [0.14  0.092 0.083 0.06  0.054 0.327]\n",
      "the biggest benefits of the excellence club for us were the unlimited internet access , beach towels in the room ( they were hard to get otherwise ) , and the beach bag in our room\n",
      "          +++ service +++ service +++ [0.117 0.095 0.145 0.06  0.093 0.277]\n",
      "we did eat breakfast each morning in the excellence club which was nice because it was a small buffet and you did not have to deal with a crowd\n",
      "          +++ overall +++ service +++ [0.146 0.089 0.094 0.072 0.064 0.137]\n",
      "the hotel itself was clean , the staff was very friendly , and nothing ever felt crowded\n",
      "          +++ service +++ service +++ [0.082 0.058 0.046 0.027 0.101 0.681]\n",
      "however , the food was not great\n",
      "          +++ service +++ service +++ [0.205 0.119 0.081 0.077 0.105 0.252]\n",
      "it was not bad - but it was not great\n",
      "          +++ overall +++ service +++ [0.198 0.109 0.032 0.089 0.052 0.168]\n",
      "i 'm not a big eater but i was prepared to indulge on my vacation and there just was not anything i was crazy about\n",
      "          +++ overall +++ service +++ [0.228 0.123 0.043 0.081 0.057 0.16 ]\n",
      "the presentation of the food was nice but it was just bland\n",
      "          +++ overall +++ service +++ [0.203 0.115 0.056 0.078 0.063 0.173]\n",
      "i think that is the best way to describe it\n",
      "          +++ overall +++ service +++ [0.162 0.093 0.031 0.069 0.044 0.149]\n",
      "the pizzas that were delivered to the pool area were good but it was unpredictable because you never knew when they would arrive\n",
      "          +++ service +++ service +++ [0.168 0.092 0.044 0.076 0.068 0.194]\n",
      "we went on two excursions - swimming with the sting - rays/sharks and the zip - line tour\n",
      "          +++ overall +++ location +++ [0.053 0.036 0.024 0.04  0.009 0.022]\n",
      "we loved the zip - line excursion\n",
      "          +++ location +++ location +++ [0.06  0.044 0.044 0.066 0.013 0.029]\n",
      "the staff was great and our bus driver and tour guide were great\n",
      "          +++ service +++ service +++ [0.087 0.047 0.055 0.048 0.037 0.246]\n",
      "it was interesting to visit the sting - rays and swim with the sharks but the reef where we snorkeled was disappointing\n",
      "          +++ location +++ location +++ [0.037 0.022 0.015 0.041 0.008 0.019]\n",
      "the fish were very small and there was not much to see\n",
      "          +++ location +++ location +++ [0.033 0.02  0.009 0.038 0.007 0.015]\n",
      "the electricity went out in our room a handful of times , especially when i used the hairdryer\n",
      "          +++ overall +++ room +++ [0.109 0.071 0.104 0.048 0.037 0.069]\n",
      "also , our ac was terrible\n",
      "          +++ room +++ room +++ [0.137 0.085 0.31  0.056 0.084 0.094]\n",
      "they tried to repair it but it just never got cool\n",
      "          +++ room +++ room +++ [0.103 0.068 0.209 0.028 0.044 0.092]\n",
      "our room was big , though , and clean\n",
      "          +++ room +++ room +++ [0.065 0.044 0.693 0.032 0.116 0.031]\n",
      "we always got housekeeping service twice a day and they refilled our mini - bar daily\n",
      "          +++ service +++ service +++ [0.066 0.072 0.137 0.029 0.325 0.365]\n",
      "in many of the reviews , people said they got sick\n",
      "          +++ service +++ service +++ [0.128 0.081 0.105 0.051 0.192 0.39 ]\n",
      "our representative at the hotel ( through aaa ) warned us that many people think they get sick from the water or the food but they do not realize that having too many drinks with coconut in them will also do it\n",
      "          +++ overall +++ service +++ [0.134 0.068 0.059 0.052 0.056 0.131]\n",
      "coconut is a natural laxative so you need to limit your consumption\n",
      "          +++ overall +++ location +++ [0.041 0.025 0.009 0.026 0.007 0.016]\n",
      "i would still pack the immodium just to be sure\n",
      "          +++ overall +++ value +++ [0.145 0.085 0.046 0.06  0.042 0.083]\n",
      "i could not decide if i wanted to give this hotel a 3/5 or a 4/5 but i decided to go up because of the friendly staff and the cleanliness of our room\n",
      "          +++ overall +++ service +++ [0.258 0.179 0.095 0.089 0.111 0.24 ]\n",
      "i do not think i would go back because of the food but we had a nice time while we were there\n",
      "          +++ overall +++ service +++ [0.275 0.161 0.095 0.099 0.115 0.244]\n",
      "we met a lot of great people at the swim up bar\n",
      "          +++ overall +++ service +++ [0.231 0.106 0.044 0.084 0.051 0.203]\n",
      "===========\n",
      "truth:\n",
      "[3, 4, 3, 4, 4, 4]\n",
      "prediction:\n",
      "tensor([3, 3, 4, 3, 4, 4])\n",
      "doc:\n",
      "very relaxing experience just returned from my 40th birthday romantic getaway with my husband\n",
      "          +++ overall +++ value +++ [0.295 0.163 0.074 0.087 0.046 0.113]\n",
      "this was our first time in the dominican republic , and we have literally been to every single island in the caribbean\n",
      "          +++ overall +++ service +++ [0.266 0.139 0.068 0.114 0.061 0.144]\n",
      "so i can assure you that my review will be short , sweet , and comprehensive\n",
      "          +++ overall +++ service +++ [0.142 0.069 0.045 0.063 0.031 0.099]\n",
      "in general , we liked the dr , and the excellence was very nice\n",
      "          +++ overall +++ service +++ [0.288 0.169 0.106 0.092 0.095 0.175]\n",
      "the top reasons why we liked excellence were : 1) no kids ( ie\n",
      "          +++ overall +++ service +++ [0.163 0.09  0.106 0.083 0.061 0.14 ]\n",
      ", if i want to get away from my own kids , i definitely do not want to vacation with other peoples ' kids )\n",
      "          +++ overall +++ service +++ [0.239 0.124 0.11  0.11  0.066 0.147]\n",
      "it was so quiet\n",
      "          +++ overall +++ service +++ [0.128 0.076 0.079 0.087 0.043 0.091]\n",
      "2) the staff and the people in the dr in general\n",
      "          +++ service +++ service +++ [0.14  0.083 0.055 0.042 0.088 0.571]\n",
      "so genuinely friendly , helpful , and wonderful\n",
      "          +++ service +++ service +++ [0.023 0.013 0.006 0.007 0.017 0.931]\n",
      "believe me , this is not true in most other areas of the caribbean\n",
      "          +++ service +++ service +++ [0.155 0.08  0.079 0.07  0.073 0.258]\n",
      "the all - inclusive feature\n",
      "          +++ overall +++ service +++ [0.074 0.048 0.04  0.054 0.023 0.061]\n",
      "loved being served , served , served\n",
      "          +++ service +++ service +++ [0.142 0.08  0.038 0.049 0.053 0.162]\n",
      "i wanted to sit on my [ - - ] all day and just be a gluttonous pig\n",
      "          +++ overall +++ service +++ [0.164 0.09  0.095 0.06  0.053 0.116]\n",
      "and this is the perfect place to do it\n",
      "          +++ overall +++ service +++ [0.187 0.099 0.096 0.088 0.061 0.124]\n",
      "4) the best selection of beach and pool lounge chairs , beds , and hammocks i 've ever seen\n",
      "          +++ service +++ service +++ [0.096 0.056 0.05  0.061 0.054 0.119]\n",
      "there were palapas everywhere , so there was no shortage of shade\n",
      "          +++ overall +++ location +++ [0.105 0.065 0.069 0.087 0.065 0.075]\n",
      "there were so many beds , you did not have to worry about not getting one\n",
      "          +++ overall +++ room +++ [0.114 0.064 0.102 0.077 0.064 0.067]\n",
      "i 'd never had the chance to sleep on a beach bed , because usually hotels have only a few , so you end up looking longingly at the lucky few who get them\n",
      "          +++ room +++ room +++ [0.144 0.082 0.169 0.069 0.069 0.078]\n",
      "ok , so here 's what i did not love about excellence :1) beach is not swimmable\n",
      "          +++ overall +++ service +++ [0.109 0.068 0.084 0.104 0.069 0.104]\n",
      "way too rough most of the time\n",
      "          +++ location +++ location +++ [0.01  0.008 0.003 0.716 0.002 0.004]\n",
      "for this reason alone , i 'd not return here\n",
      "          +++ location +++ location +++ [0.244 0.161 0.052 0.326 0.055 0.087]\n",
      "i 'm a beach fan , and love to swim in the warm caribbean sea\n",
      "          +++ location +++ location +++ [0.055 0.041 0.012 0.347 0.011 0.02 ]\n",
      "i 'm no food snob , but some of the food was downright bad\n",
      "          +++ overall +++ location +++ [0.105 0.063 0.017 0.098 0.022 0.059]\n",
      "and you end up eating in the same spot for breakfast and lunch\n",
      "          +++ overall +++ service +++ [0.155 0.097 0.032 0.058 0.049 0.137]\n",
      "even though they have like 7 restaurants - the majority of them are only open for dinner\n",
      "          +++ overall +++ value +++ [0.177 0.105 0.03  0.071 0.041 0.105]\n",
      "we only stayed 4 nights , and we were definitely getting very tired of the breakfast/lunch selection by the 3rd day\n",
      "          +++ overall +++ service +++ [0.241 0.157 0.074 0.07  0.086 0.177]\n",
      "overall , if you just want to relax by the pool and you do not care about not going in the beach , this is a very beautiful resort\n",
      "          +++ overall +++ value +++ [0.241 0.149 0.088 0.145 0.074 0.113]\n",
      "the staff is wonderful\n",
      "          +++ service +++ service +++ [0.076 0.042 0.015 0.027 0.033 0.794]\n",
      "if you are looking for a place to party and be loud and crazy , this is not your place\n",
      "          +++ overall +++ service +++ [0.246 0.132 0.103 0.099 0.069 0.232]\n",
      "===========\n",
      "truth:\n",
      "[1, 0, 2, 3, 1, 0]\n",
      "prediction:\n",
      "tensor([1, 1, 2, 3, 1, 0])\n",
      "doc:\n",
      "5- star views\n",
      "          +++ overall +++ value +++ [0.145 0.103 0.073 0.042 0.032 0.069]\n",
      "2- star service i do not know where to start\n",
      "          +++ service +++ service +++ [0.201 0.128 0.096 0.058 0.067 0.282]\n",
      "the roaches in the room , the rude waiters , bartenders , front desk , the dead flies that stayed on our friends ' mirror the entire stay , the average at best food ( only one morning in the bathroom for longer than you would want ) , the 6,7,8 times i had to trip the breakers so my wife could use the\n",
      "          +++ service +++ service +++ [0.117 0.098 0.131 0.029 0.195 0.428]\n",
      "hair dryer without our power going out , or the waste of money the excellence club turned out to be\n",
      "          +++ room +++ room +++ [0.193 0.144 0.249 0.054 0.111 0.141]\n",
      "i guess i 'll start with the good\n",
      "          +++ overall +++ value +++ [0.139 0.098 0.062 0.049 0.032 0.091]\n",
      "the beach was fabulous\n",
      "          +++ location +++ location +++ [0.055 0.039 0.022 0.124 0.023 0.047]\n",
      "the resort itself , d?cor , pool , beach access was great\n",
      "          +++ room +++ room +++ [0.132 0.105 0.168 0.157 0.15  0.142]\n",
      "ok now for the rest of the trip\n",
      "          +++ overall +++ service +++ [0.213 0.14  0.093 0.102 0.078 0.161]\n",
      "we booked the excellence after changing from another resort we booked\n",
      "          +++ overall +++ value +++ [0.262 0.148 0.124 0.092 0.076 0.083]\n",
      "we booked the other one a little quickly and then read some really bad reviews\n",
      "          +++ overall +++ value +++ [0.07  0.038 0.036 0.03  0.02  0.036]\n",
      "so we were able to get out of that one and do a little more homework\n",
      "          +++ overall +++ service +++ [0.058 0.037 0.04  0.037 0.02  0.044]\n",
      "we read about the excellence from trip advisor and were really excited to go\n",
      "          +++ overall +++ service +++ [0.11  0.052 0.048 0.039 0.035 0.09 ]\n",
      "now , we 've been to the caribbean plenty and are low maintenance travelers\n",
      "          +++ overall +++ service +++ [0.105 0.055 0.049 0.048 0.036 0.081]\n",
      "we 'll check in and the hotel usually does not hear from us until we leave\n",
      "          +++ room +++ room +++ [0.14  0.075 0.159 0.061 0.079 0.14 ]\n",
      "one thing we usually like to do is get to the front desk and see about upgrading rooms\n",
      "          +++ service +++ service +++ [0.083 0.048 0.085 0.073 0.046 0.136]\n",
      "we were originally booked in a garden view room\n",
      "          +++ room +++ room +++ [0.073 0.043 0.187 0.05  0.039 0.044]\n",
      "our first question at the front desk was , ??o you have any ocean view rooms available\n",
      "          +++ room +++ room +++ [0.058 0.036 0.068 0.064 0.023 0.067]\n",
      "he said , ??es , let me tell you about the excellence club\n",
      "          +++ room +++ room +++ [0.058 0.038 0.066 0.042 0.022 0.058]\n",
      "the excellence club rooms are identical to every other room in the resort ( but with a plasma tv ) and you have access to what?? basically another room where you can eat ( the same food that?? served everywhere else ) , have premium drinks , and check out dvds\n",
      "          +++ room +++ room +++ [0.129 0.085 0.258 0.069 0.09  0.121]\n",
      "he showed us where we would be staying\n",
      "          +++ service +++ service +++ [0.064 0.038 0.058 0.031 0.026 0.073]\n",
      "it was perfect , right in front of the pool over looking the ocean\n",
      "          +++ room +++ room +++ [0.093 0.056 0.151 0.102 0.055 0.096]\n",
      "much to our dismay , we show up and still have a garden view\n",
      "          +++ room +++ room +++ [0.11  0.069 0.154 0.079 0.064 0.083]\n",
      "we call the front desk and ask where the ocean view room is and he commences to telling us how wonderful the excellence club is\n",
      "          +++ room +++ room +++ [0.058 0.035 0.088 0.056 0.027 0.071]\n",
      "so great , the hustle is on\n",
      "          +++ location +++ location +++ [0.046 0.032 0.046 0.056 0.014 0.051]\n",
      "after spending much of the first night arguing back and forth while he?? ??ooking into it?\n",
      "          +++ service +++ service +++ [0.123 0.076 0.098 0.078 0.051 0.164]\n",
      "we finally gave up and waited until the morning\n",
      "          +++ service +++ service +++ [0.065 0.041 0.059 0.032 0.027 0.07 ]\n",
      "they finally moved us to a pool front room but i still don?? why we had to pay $400 extra per couple for a plasma tv and movies\n",
      "          +++ room +++ room +++ [0.109 0.075 0.181 0.058 0.056 0.083]\n",
      "the movies ended up being ok since one morning i stayed in bed with an upset stomach and my wife did the same thing a couple of nights\n",
      "          +++ room +++ room +++ [0.134 0.085 0.166 0.078 0.051 0.073]\n",
      "the resort was pretty much empty so we were a little confused why there were no ocean front rooms available\n",
      "          +++ location +++ location +++ [0.106 0.076 0.105 0.124 0.054 0.055]\n",
      "the restaurants were empty , the bars were empty\n",
      "          +++ overall +++ location +++ [0.154 0.091 0.072 0.118 0.075 0.085]\n",
      "i guess enjoying their ocean front rooms\n",
      "          +++ location +++ location +++ [0.09  0.059 0.061 0.123 0.038 0.066]\n",
      "another strange phenomenon was with it being so empty , why were the waits so long\n",
      "          +++ location +++ location +++ [0.106 0.067 0.084 0.113 0.045 0.079]\n",
      "waiting for service , waiting for a table , waiting for a drink , waiting at the front desk\n",
      "          +++ service +++ service +++ [0.144 0.091 0.058 0.057 0.074 0.49 ]\n",
      "the place was empty\n",
      "          +++ service +++ service +++ [0.16  0.112 0.118 0.1   0.107 0.214]\n",
      "there were a few nice waiters but most of them were rude , acted as if we were bothering them and sometimes just stood there and looked at us like we were stupid or something\n",
      "          +++ service +++ service +++ [0.054 0.037 0.012 0.016 0.026 0.85 ]\n",
      "i was amazed\n",
      "          +++ service +++ service +++ [0.083 0.052 0.033 0.029 0.032 0.273]\n",
      "i would recommend bringing an electrician with you as well because you??l need to get the power turned on if you want to dry your hair and run the air conditioner at the same time\n",
      "          +++ room +++ room +++ [0.096 0.06  0.111 0.054 0.043 0.103]\n",
      "watch your step walking underneath the vent as well so you won?? slip in the leaking water from the vent\n",
      "          +++ room +++ room +++ [0.116 0.069 0.235 0.062 0.052 0.064]\n",
      "we had roaches in our bar , the couple that went with us noticed dead flies stuck to their mirror in clear sight and they stayed there the whole time we were there\n",
      "          +++ clean +++ clean +++ [0.14  0.093 0.239 0.071 0.247 0.178]\n",
      "average at best\n",
      "          +++ room +++ room +++ [0.158 0.114 0.245 0.066 0.134 0.116]\n",
      "the quality wasn?? very good\n",
      "          +++ room +++ room +++ [0.121 0.078 0.231 0.088 0.13  0.13 ]\n",
      "we spent the whole trip scared of it after we were in the bathroom the next morning\n",
      "          +++ overall +++ room +++ [0.215 0.138 0.202 0.123 0.152 0.109]\n",
      "we called room service one night and they were out of pepperonis for the pizza\n",
      "          +++ service +++ service +++ [0.108 0.077 0.085 0.061 0.082 0.38 ]\n",
      "( that was more funny than annoying ) and our friends went to the italian restaurant and ate dinner\n",
      "          +++ service +++ service +++ [0.131 0.083 0.069 0.057 0.076 0.327]\n",
      "after , they ordered dessert : ??e??e out of tiramisu\n",
      "          +++ service +++ service +++ [0.139 0.078 0.064 0.054 0.054 0.186]\n",
      "??e have one cheesecake?\n",
      "          +++ overall +++ service +++ [0.109 0.061 0.042 0.05  0.035 0.108]\n",
      "ok , what kind\n",
      "          +++ service +++ service +++ [0.088 0.053 0.037 0.041 0.027 0.09 ]\n",
      "??o , we have one piece of cheesecake left\n",
      "          +++ overall +++ service +++ [0.088 0.052 0.032 0.05  0.027 0.077]\n",
      "ran out of dessert\n",
      "          +++ service +++ service +++ [0.056 0.042 0.022 0.021 0.015 0.061]\n",
      "like i said before , we??e low maintenance travelers\n",
      "          +++ service +++ service +++ [0.154 0.089 0.082 0.051 0.076 0.209]\n",
      "we go to a cheaper place and have to wait or deal with annoyances , we don?? mind\n",
      "          +++ service +++ service +++ [0.17  0.113 0.095 0.069 0.075 0.17 ]\n",
      "you get what you pay for\n",
      "          +++ service +++ service +++ [0.106 0.087 0.05  0.046 0.039 0.197]\n",
      "but this is supposed to be a 4-5 star establishment and it seemed as though they didn?? know what the heck they were doing\n",
      "          +++ service +++ service +++ [0.132 0.105 0.068 0.055 0.051 0.244]\n",
      "it was just a comedy of issues from the time we showed up to the time we left\n",
      "          +++ service +++ service +++ [0.176 0.132 0.082 0.065 0.065 0.217]\n",
      "the whole trip was ruined and that?? a few thousand dollars we wish we had back\n",
      "          +++ overall +++ value +++ [0.277 0.191 0.073 0.1   0.059 0.129]\n",
      "there are so many other options available down there , look elsewhere\n",
      "          +++ overall +++ value +++ [0.207 0.143 0.036 0.073 0.028 0.066]\n",
      "i know we??l never return\n",
      "          +++ overall +++ value +++ [0.36  0.196 0.074 0.084 0.061 0.16 ]\n",
      "===========\n",
      "truth:\n",
      "[3, 3, 3, 4, 3, 4]\n",
      "prediction:\n",
      "tensor([4, 4, 4, 4, 4, 4])\n",
      "doc:\n",
      "we just got back yesterday from a one week stay at the excellence resort in punta cana\n",
      "          +++ overall +++ value +++ [0.282 0.152 0.084 0.083 0.057 0.102]\n",
      "i had done my research online and found that with the exception of the food , there were almost 100% positive things that people had to say about this resort\n",
      "          +++ overall +++ service +++ [0.231 0.123 0.047 0.065 0.054 0.173]\n",
      "it all lived up to be true\n",
      "          +++ overall +++ value +++ [0.271 0.149 0.088 0.076 0.07  0.139]\n",
      "the resort was magical\n",
      "          +++ overall +++ service +++ [0.188 0.123 0.142 0.076 0.12  0.149]\n",
      "my wife and i went with 2 friends of ours and were blown away\n",
      "          +++ overall +++ service +++ [0.171 0.085 0.09  0.071 0.051 0.091]\n",
      "the pool and beach were spectacular\n",
      "          +++ location +++ location +++ [0.07  0.043 0.037 0.081 0.041 0.05 ]\n",
      "as tropical beach rooms go , the rooms were nicely appointed with an open feel\n",
      "          +++ room +++ room +++ [0.125 0.089 0.311 0.093 0.138 0.085]\n",
      "bathtub in the room , shower in the bathroom , was a nice tough\n",
      "          +++ room +++ room +++ [0.093 0.066 0.599 0.041 0.124 0.059]\n",
      "the only negative thing i can say about this experience was the food\n",
      "          +++ location +++ location +++ [0.055 0.03  0.062 0.088 0.031 0.067]\n",
      "even though at all the restaurants you ordered from menus , the food was prepared banquet style\n",
      "          +++ service +++ service +++ [0.234 0.13  0.056 0.078 0.085 0.269]\n",
      "what i mean by this is that it was not as hot and fresh as food would typically be that is prepared for you\n",
      "          +++ overall +++ service +++ [0.213 0.121 0.065 0.052 0.066 0.194]\n",
      "if you are a person that typically eats in nice restaurants in cities like new york , san francisco , etc\n",
      "          +++ overall +++ service +++ [0.211 0.106 0.069 0.1   0.067 0.187]\n",
      "you will probably rate this food around a c+ or b -\n",
      "          +++ overall +++ service +++ [0.273 0.158 0.098 0.085 0.075 0.188]\n",
      "though i am not typically a buffet type person , i would highly recommend you go to their buffet for both breakfast and lunch\n",
      "          +++ overall +++ service +++ [0.224 0.128 0.052 0.081 0.065 0.213]\n",
      "you will not be disappointed as they will prepare eggs , meats , pastas individually for you\n",
      "          +++ service +++ service +++ [0.169 0.097 0.037 0.057 0.051 0.188]\n",
      "lastly on the food , steer clear of the lobster house\n",
      "          +++ overall +++ service +++ [0.19  0.115 0.056 0.09  0.069 0.161]\n",
      "it was the only restaurant that highly disappointed us\n",
      "          +++ overall +++ service +++ [0.155 0.083 0.03  0.075 0.038 0.1  ]\n",
      "every place else ( the mexican , french , italian , etc\n",
      "          +++ overall +++ service +++ [0.246 0.138 0.092 0.14  0.094 0.161]\n",
      ") provided the ambiance , a decent meal , wine , etc\n",
      "          +++ overall +++ service +++ [0.196 0.12  0.07  0.085 0.071 0.193]\n",
      "for a very nice evening\n",
      "          +++ overall +++ value +++ [0.256 0.183 0.085 0.079 0.075 0.135]\n",
      "outside of the food , the resort and its people were truly amazing\n",
      "          +++ service +++ service +++ [0.201 0.111 0.056 0.1   0.089 0.277]\n",
      "we will definitely go back\n",
      "          +++ service +++ service +++ [0.264 0.127 0.102 0.087 0.115 0.3  ]\n",
      "this review was written by an ad agency executive who travels almost half the year in mostly big cities like la , new york , las vegas and san francisco\n",
      "          +++ overall +++ service +++ [0.151 0.076 0.05  0.109 0.04  0.12 ]\n",
      "i am lucky enough to entertain clients in very fine restaurants and would probably be considered a food snob\n",
      "          +++ overall +++ service +++ [0.182 0.099 0.059 0.084 0.052 0.138]\n",
      "===========\n",
      "truth:\n",
      "[4, 4, 4, 4, 4, 4]\n",
      "prediction:\n",
      "tensor([4, 4, 4, 4, 4, 4])\n",
      "doc:\n",
      "life does not get better than this\n",
      "          +++ overall +++ service +++ [0.152 0.085 0.051 0.047 0.029 0.094]\n",
      "my husband and i stayed at excellence punta cana from 10th nov - 24th nov\n",
      "          +++ overall +++ service +++ [0.35  0.162 0.068 0.067 0.054 0.169]\n",
      "this was our first holiday in 2 years , so we were looking for somewhere where we can just relax on a beautiful beach or by the pool\n",
      "          +++ overall +++ value +++ [0.198 0.119 0.077 0.098 0.045 0.083]\n",
      "we did not expect much with regards to the food after having read poor reviews and to be honest some of them had us a little worried\n",
      "          +++ overall +++ service +++ [0.182 0.107 0.04  0.08  0.046 0.149]\n",
      "i am pleased to say that excellence punta cana exceeded our expectations by a mile\n",
      "          +++ overall +++ service +++ [0.289 0.161 0.083 0.088 0.076 0.188]\n",
      "for the first couple of day , i just walked around with my mouth open\n",
      "          +++ overall +++ service +++ [0.209 0.131 0.077 0.085 0.067 0.136]\n",
      "the place is absolutely breathtaking\n",
      "          +++ overall +++ room +++ [0.107 0.065 0.105 0.077 0.079 0.073]\n",
      "we loved our room (3101) , clean , spacious and quiet\n",
      "          +++ room +++ room +++ [0.092 0.069 0.449 0.054 0.184 0.095]\n",
      "the beach is beautiful , the sea is so much fun to swim in ( we both like the waves\n",
      "          +++ location +++ location +++ [0.055 0.035 0.033 0.174 0.026 0.028]\n",
      ") , the pool is huge and sparkling clean with plenty of beds/loungers\n",
      "          +++ clean +++ clean +++ [0.1   0.07  0.083 0.081 0.105 0.085]\n",
      "as i said we did not expect much and we 're not sure why people are complaining so much ( bearing in mind that we are very fussy eaters )\n",
      "          +++ overall +++ room +++ [0.166 0.092 0.155 0.074 0.095 0.144]\n",
      "for a start it is an all - inclusive resort not a michelin - star restaurant\n",
      "          +++ overall +++ value +++ [0.254 0.169 0.108 0.108 0.068 0.109]\n",
      "the choices were plentiful and the food was fresh , well presented and well cooked\n",
      "          +++ service +++ service +++ [0.191 0.13  0.064 0.068 0.103 0.29 ]\n",
      "we were there for 2 weeks and could have probably stayed another 2 weeks without getting bored of the food\n",
      "          +++ overall +++ value +++ [0.274 0.166 0.103 0.082 0.103 0.161]\n",
      "the entertainment team do a great job , the bar staff are fun , beach  pool servers always around , the waiting staff friendly and attentive , the housekeeping ladies kept our room spotlessly clean and tidy\n",
      "          +++ service +++ service +++ [0.086 0.067 0.056 0.033 0.155 0.584]\n",
      "i 'm not going to single out any staff in particular because i think every single one played a big part in having made our stay so enjoyable , and in particular those behind the scenes who works so hard but do not get the tips or the credit they derserve\n",
      "          +++ service +++ service +++ [0.09  0.057 0.05  0.034 0.107 0.65 ]\n",
      "we 've had a wonderful time and although we usually prefer not to return to the same place ( so as not to spoil it ) , excellence punta cana is one of those places that we would certainly not hesitate going back to\n",
      "          +++ overall +++ service +++ [0.309 0.176 0.097 0.084 0.096 0.23 ]\n",
      "in fact we would have quite liked to move in\n",
      "          +++ overall +++ service +++ [0.309 0.174 0.113 0.095 0.091 0.175]\n",
      "there are so much more to say , but i could go on forever\n",
      "          +++ overall +++ service +++ [0.248 0.135 0.071 0.104 0.055 0.136]\n",
      "this place is a taste of heaven , go with the right attitude and you will not be dissapointed\n",
      "          +++ overall +++ service +++ [0.213 0.119 0.097 0.086 0.058 0.159]\n",
      "everything that they offer must surely satisfy 90% of guests\n",
      "          +++ service +++ service +++ [0.205 0.105 0.079 0.056 0.064 0.387]\n",
      "as for the other 10% , there is no satisfaction no matter what you do\n",
      "          +++ overall +++ service +++ [0.156 0.101 0.074 0.079 0.048 0.155]\n",
      "they should probably rather stay at home and certainly not travel to a 3rd world country\n",
      "          +++ overall +++ service +++ [0.233 0.129 0.089 0.077 0.058 0.177]\n",
      "ps : 1\n",
      "          +++ overall +++ service +++ [0.139 0.08  0.078 0.088 0.046 0.106]\n",
      "enjoy the ride from the airport (50minutes ) , its an excursion on its own , saves having to pay to go on one in precious holiday time\n",
      "          +++ location +++ location +++ [0.095 0.066 0.039 0.151 0.022 0.05 ]\n",
      "find the soft serve machine by cafe kafe bar\n",
      "          +++ overall +++ service +++ [0.051 0.032 0.019 0.039 0.016 0.039]\n",
      "nancy 's shop is the best , she wo not rip you off\n",
      "          +++ service +++ service +++ [0.045 0.025 0.028 0.03  0.016 0.05 ]\n",
      "( with the other vendors everything always starts at $200, and you can get it down to $15, nancy gives a reasonable price from the start )4\n",
      "          +++ service +++ service +++ [0.05  0.034 0.028 0.03  0.015 0.053]\n",
      "go to the sports bar for ice cold water\n",
      "          +++ overall +++ service +++ [0.028 0.019 0.014 0.016 0.009 0.026]\n",
      "===========\n",
      "truth:\n",
      "[4, 4, 4, 4, 4, 4]\n",
      "prediction:\n",
      "tensor([4, 4, 4, 4, 4, 4])\n",
      "doc:\n",
      "everything is excellent at excellence punta cana we just got back from our honeymoon\n",
      "          +++ overall +++ service +++ [0.305 0.151 0.086 0.065 0.071 0.271]\n",
      "we had an amazing time at excellence punta cana\n",
      "          +++ overall +++ service +++ [0.32  0.166 0.081 0.075 0.07  0.243]\n",
      "we felt we were in paradise\n",
      "          +++ overall +++ service +++ [0.219 0.109 0.104 0.061 0.076 0.202]\n",
      "the hotel and service was excellent\n",
      "          +++ service +++ service +++ [0.139 0.085 0.064 0.043 0.098 0.549]\n",
      "the whole staff was very friendly and so polite\n",
      "          +++ service +++ service +++ [0.045 0.025 0.011 0.013 0.025 0.872]\n",
      "my husband and i did not want to leave the resort\n",
      "          +++ service +++ service +++ [0.172 0.089 0.109 0.065 0.079 0.252]\n",
      "they made us feel very special\n",
      "          +++ service +++ service +++ [0.117 0.06  0.054 0.032 0.058 0.507]\n",
      "we have never experience a trip like this one\n",
      "          +++ service +++ service +++ [0.249 0.123 0.071 0.057 0.082 0.386]\n",
      "we loved it so much we are gathering a group of couple to go again early next summer\n",
      "          +++ overall +++ service +++ [0.278 0.137 0.147 0.096 0.095 0.171]\n",
      "we never experience a problem while our stay\n",
      "          +++ overall +++ service +++ [0.281 0.14  0.095 0.077 0.079 0.234]\n",
      "all of our belongings we safe , nothing was missing\n",
      "          +++ service +++ service +++ [0.186 0.109 0.146 0.078 0.144 0.245]\n",
      "ca not wait to go back\n",
      "          +++ overall +++ service +++ [0.275 0.134 0.109 0.093 0.102 0.248]\n",
      "much love to maria isabel and carlos from excellence club concierge - - from mr\n",
      "          +++ service +++ service +++ [0.184 0.085 0.078 0.071 0.076 0.439]\n",
      "===========\n",
      "truth:\n",
      "[4, 4, 4, 4, 4, 4]\n",
      "prediction:\n",
      "tensor([4, 4, 4, 4, 4, 4])\n",
      "doc:\n",
      "the pool and beach were beautiful this hotel catered to every persons needs\n",
      "          +++ overall +++ service +++ [0.179 0.112 0.072 0.105 0.061 0.134]\n",
      "i love the fact that it is all inclusive food and alcohol\n",
      "          +++ overall +++ service +++ [0.14  0.093 0.074 0.08  0.044 0.096]\n",
      "just because the hotel says it is all inclusive does not mean you dont have to tip\n",
      "          +++ overall +++ service +++ [0.126 0.088 0.048 0.062 0.037 0.117]\n",
      "the people there work 12 days straight with 2 days off\n",
      "          +++ service +++ service +++ [0.163 0.093 0.058 0.045 0.056 0.394]\n",
      "they work up to 16 hours a day to make your experience there comfortable\n",
      "          +++ service +++ service +++ [0.147 0.089 0.062 0.043 0.07  0.456]\n",
      "so i made sure i tipped everyone who helped me\n",
      "          +++ service +++ service +++ [0.124 0.081 0.066 0.044 0.083 0.471]\n",
      "it is 35 pesos to one american dollar so you can do the math\n",
      "          +++ service +++ service +++ [0.066 0.047 0.04  0.034 0.021 0.127]\n",
      "the people that work in entertainment , cesar , mariel , ines , whinny were all very good\n",
      "          +++ service +++ service +++ [0.096 0.049 0.04  0.038 0.058 0.628]\n",
      "they taught me and my husband many things about there culture such as dancing\n",
      "          +++ service +++ service +++ [0.088 0.047 0.039 0.038 0.029 0.169]\n",
      "also there was a bartender named juan who made the best drinks there\n",
      "          +++ service +++ service +++ [0.096 0.05  0.035 0.041 0.031 0.132]\n",
      "===========\n"
     ]
    }
   ],
   "source": [
    "asp_inc_overall = True\n",
    "if not asp_inc_overall: \n",
    "    nasp_analysis = hyper_params[\"num_aspect\"] - 1\n",
    "else:\n",
    "    nasp_analysis = hyper_params[\"num_aspect\"]\n",
    "    \n",
    "np.set_printoptions(precision=3)\n",
    "asp_name = [\"overall\", \"value\", \"room\", \"location\", \"clean\", \"service\"]\n",
    "for i in range(10):\n",
    "    print(\"truth:\")\n",
    "    print(df_test.iloc[i,0:6].values.flatten().tolist() )\n",
    "    print(\"prediction:\")\n",
    "    print( torch.argmax(outs[i][0:6],dim=1) )\n",
    "    print(\"doc:\")\n",
    "    dasp = torch.argmax(asps[i][:,0:nasp_analysis],dim=1).numpy()\n",
    "    if asp_inc_overall: dasp_noall = torch.argmax(asps[i][:,1:6],dim=1).numpy()\n",
    "#     dasp_dist = torch.nn.functional.softmax(asps[i][:,0:nasp_analysis], dim=1).numpy()\n",
    "    dasp_dist = asps[i][:,0:nasp_analysis].numpy()\n",
    "    for senti,s in enumerate(df_test.iloc[i,6]):\n",
    "        print(s)\n",
    "        if asp_inc_overall:\n",
    "            print(\"          +++ \"+ asp_name[dasp[senti]] + \" +++ \" + asp_name[dasp_noall[senti]+1] + \" +++ \" + str(dasp_dist[senti]) )\n",
    "        else:\n",
    "            print(\"          +++ \"+ asp_name[dasp[senti]+1] + \" +++ \" + str(dasp_dist[senti]) )\n",
    "    print(\"===========\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize regression output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truth:\n",
      "[1, 0, 0, 3, 1, 1]\n",
      "prediction:\n",
      "tensor([[4.1020e-04, 9.9668e-01, 2.9009e-03, 3.9855e-06, 1.4823e-06],\n",
      "        [8.2763e-03, 9.6310e-01, 2.8592e-02, 1.9740e-05, 1.5135e-05],\n",
      "        [9.9990e-01, 1.0335e-04, 4.0020e-08, 2.1092e-08, 5.1732e-09],\n",
      "        [2.2873e-01, 1.3853e-01, 2.5908e-01, 3.5016e-01, 2.3494e-02],\n",
      "        [9.5705e-01, 4.2916e-02, 3.6786e-05, 1.6780e-07, 1.2092e-07],\n",
      "        [9.9998e-01, 1.9123e-05, 1.6604e-09, 5.1853e-12, 3.6041e-11]])\n",
      "doc:\n",
      "definitely not a 5 star resort i 'm dumbfounded that this hotel gets good reviews and is so highly rated\n",
      "          +++ value +++ [0.22 0.2  0.19 0.19 0.19]\n",
      "it 's decidedly a 3 star property , not 5 stars as indicated\n",
      "          +++ value +++ [0.22 0.2  0.2  0.19 0.19]\n",
      "the rooms are very dated and run down , old crappy beds and pillows , an old tv and overall poorly maintained\n",
      "          +++ location +++ [0.17 0.17 0.28 0.17 0.21]\n",
      "the whole property is pretty run down and old - looking\n",
      "          +++ location +++ [0.19 0.18 0.25 0.18 0.21]\n",
      "the food is subpar , not one meal i had would be called great\n",
      "          +++ value +++ [0.21 0.19 0.21 0.19 0.2 ]\n",
      "the service is uneven and the staff is poorly trained and uninformed\n",
      "          +++ value +++ [0.2 0.2 0.2 0.2 0.2]\n",
      "many do not comprehend english\n",
      "          +++ value +++ [0.21 0.2  0.2  0.2  0.2 ]\n",
      "the beach is great , it 's the only redeeming factor\n",
      "          +++ clean +++ [0.18 0.18 0.18 0.28 0.18]\n",
      "however the resort is a 1- hour taxi trip from the airport\n",
      "          +++ clean +++ [0.19 0.19 0.19 0.25 0.19]\n",
      "===========\n",
      "truth:\n",
      "[2, 2, 1, 2, 3, 3]\n",
      "prediction:\n",
      "tensor([[1.4483e-04, 9.8034e-01, 1.8719e-02, 7.9833e-04, 1.3543e-06],\n",
      "        [3.2097e-04, 8.8404e-01, 1.1110e-01, 4.4965e-03, 4.1651e-05],\n",
      "        [9.1542e-02, 4.8621e-01, 2.8853e-02, 3.6794e-01, 2.5458e-02],\n",
      "        [2.4023e-05, 1.3841e-03, 6.8200e-01, 3.0687e-01, 9.7190e-03],\n",
      "        [1.4971e-03, 2.3923e-02, 1.7517e-01, 7.2813e-01, 7.1284e-02],\n",
      "        [2.5925e-03, 6.4041e-01, 2.5299e-01, 1.0233e-01, 1.6784e-03]])\n",
      "doc:\n",
      "facilities need work\n",
      "          +++ value +++ [0.22 0.2  0.2  0.19 0.19]\n",
      "we visited excellence for 5 nights in december\n",
      "          +++ value +++ [0.22 0.2  0.2  0.19 0.19]\n",
      "our first room , #1112, had a safe that did not work and so - so air conditioning\n",
      "          +++ location +++ [0.2  0.19 0.22 0.19 0.19]\n",
      "when we went to the front desk to complain , we were told to go to the room and someone would be there within 15 minutes\n",
      "          +++ value +++ [0.21 0.2  0.2  0.2  0.19]\n",
      "45 minutes later , the safe guy showed up , but nobody for the a/c\n",
      "          +++ value +++ [0.21 0.2  0.2  0.2  0.19]\n",
      "the safe guy could not fix it\n",
      "          +++ value +++ [0.21 0.2  0.2  0.2  0.19]\n",
      "when he left , the electricity went out\n",
      "          +++ value +++ [0.21 0.2  0.2  0.2  0.19]\n",
      "it went out a second time before we finally went to the front desk to change rooms\n",
      "          +++ value +++ [0.21 0.2  0.2  0.2  0.19]\n",
      "we had dinner that night in the lobster house\n",
      "          +++ value +++ [0.21 0.2  0.2  0.2  0.19]\n",
      "do not waste your time on this one\n",
      "          +++ value +++ [0.22 0.2  0.19 0.19 0.19]\n",
      "the lobster tails had about 2 bites of food included\n",
      "          +++ value +++ [0.21 0.2  0.2  0.2  0.2 ]\n",
      "while we were in there , the electricity went out again\n",
      "          +++ value +++ [0.21 0.2  0.2  0.2  0.2 ]\n",
      "room 3002 served us pretty well , until night #3 when my partner got up to go to the bathroom and stepped into an inch of water\n",
      "          +++ location +++ [0.2  0.19 0.21 0.19 0.19]\n",
      "a hose had broken on the back of the toilet and flooded our room\n",
      "          +++ location +++ [0.19 0.19 0.24 0.19 0.19]\n",
      "it would 've been ok , but when we went to the front desk we were told that we needed to wait until noon to see if perhaps they could move us to another room\n",
      "          +++ value +++ [0.21 0.2  0.2  0.2  0.19]\n",
      "the front desk clerks were not empowered to just move us\n",
      "          +++ value +++ [0.21 0.2  0.2  0.2  0.19]\n",
      "my partner was infuriated that they wanted us to wait 4 hours for a new room\n",
      "          +++ value +++ [0.21 0.2  0.2  0.2  0.19]\n",
      "finally , matias at the front desk finally arranged to have us moved to another upgraded room - 3109\n",
      "          +++ value +++ [0.21 0.2  0.2  0.2  0.19]\n",
      "we walked in and saw the leak coming from the ceiling and nearly flipped\n",
      "          +++ location +++ [0.2  0.19 0.22 0.2  0.19]\n",
      "we finally got into #3110, which was a gorgeous suite with a beautiful view\n",
      "          +++ location +++ [0.19 0.19 0.24 0.19 0.19]\n",
      "on the positive side , the food at the other restaurants was very good\n",
      "          +++ value +++ [0.22 0.2  0.19 0.2  0.19]\n",
      "i particularly liked the french restaurant , while my partner liked the asian restaurant\n",
      "          +++ value +++ [0.22 0.2  0.19 0.2  0.19]\n",
      "the breakfast buffet was like nothing i 'd ever seen before - lots of choices\n",
      "          +++ value +++ [0.22 0.2  0.19 0.2  0.19]\n",
      "the ocean was way too rough to enjoy , particularly if you 're not a strong swimmer\n",
      "          +++ clean +++ [0.2  0.2  0.19 0.22 0.19]\n",
      "much of the beach was black flagged the entire time we were there , so if you 're a big ocean fan , i do not recommend this resort\n",
      "          +++ clean +++ [0.21 0.19 0.19 0.22 0.19]\n",
      "my favorite part , by far , though , were the beds next to the pools and ocean\n",
      "          +++ location +++ [0.2  0.19 0.22 0.19 0.19]\n",
      "they were amazing\n",
      "          +++ location +++ [0.2  0.19 0.21 0.2  0.2 ]\n",
      "i guess you could particularly say so since the beds in the rooms were hard as rocks\n",
      "          +++ location +++ [0.19 0.19 0.24 0.19 0.19]\n",
      "all in all , a good trip - highly recommend the zip line tour\n",
      "          +++ value +++ [0.21 0.2  0.19 0.21 0.19]\n",
      "it was worth every penny\n",
      "          +++ value +++ [0.22 0.2  0.19 0.2  0.19]\n",
      "===========\n",
      "truth:\n",
      "[4, 4, 4, 3, 4, 4]\n",
      "prediction:\n",
      "tensor([[1.8609e-07, 1.7810e-10, 5.0119e-11, 3.3600e-06, 1.0000e+00],\n",
      "        [1.1452e-06, 2.3374e-08, 2.8158e-09, 1.1409e-05, 9.9999e-01],\n",
      "        [5.4073e-07, 2.6483e-07, 5.1241e-07, 2.1868e-05, 9.9998e-01],\n",
      "        [1.2492e-07, 2.9025e-06, 8.7353e-06, 1.2448e-04, 9.9986e-01],\n",
      "        [2.3340e-05, 7.1462e-07, 3.3719e-06, 2.6458e-06, 9.9997e-01],\n",
      "        [1.5828e-06, 2.5712e-07, 6.6358e-07, 1.8245e-05, 9.9998e-01]])\n",
      "doc:\n",
      "excellence was exactly that\n",
      "          +++ value +++ [0.22 0.2  0.19 0.19 0.19]\n",
      "my family and i stayed at the excellence punta cana from december 22 to december 29 of this year\n",
      "          +++ value +++ [0.22 0.2  0.2  0.19 0.19]\n",
      "it was an amazing time had by all that attended\n",
      "          +++ value +++ [0.22 0.2  0.19 0.19 0.2 ]\n",
      "we arrived at the resort around 4 am because of a delay at the airport in vancouver , but even at 4 am , the service of the bellhops and the front desk was up to par\n",
      "          +++ value +++ [0.21 0.2  0.2  0.2  0.2 ]\n",
      "our bags were unloaded and immediately tagged and set to one side of the lobby while we were handed cold scented towels to cool off with\n",
      "          +++ service +++ [0.2  0.19 0.2  0.2  0.21]\n",
      "check in was fairly expedient and we were in our rooms within twenty minutes\n",
      "          +++ value +++ [0.21 0.2  0.2  0.2  0.19]\n",
      "i had never been to an all inclusive resort before , and wasted no time enjoying the pleasures of the mini bar in the room , as well as the ample storage space for our things\n",
      "          +++ location +++ [0.2  0.19 0.21 0.19 0.2 ]\n",
      "room service even at 4 am was great , the girl on the phone said it would be about 40 minutes for the food , which seemed a little long , but i think they only say that to cover there butts , because it took about 25 minutes at most\n",
      "          +++ value +++ [0.2 0.2 0.2 0.2 0.2]\n",
      "the activities during the day were well thought out , though , there was some delays and cancellations due to weather conditions ( beach volleyball cancelled to due strong winds\n",
      "          +++ clean +++ [0.2  0.2  0.2  0.21 0.2 ]\n",
      "the entertainment staff was amazing and extremely friendly , a special thanks to all my friends , ines ( my fiance , ) altagracia ( who lovingly reffered to me as flaco loco , which translates into crazy skinny guy , ) eliza and johanna ( my disco dance partners , ) sexy cesar ( who taught me all the sexy dance moves i\n",
      "          +++ value +++ [0.21 0.2  0.2  0.2  0.2 ]\n",
      "now know , ) julio cesar ( the mc for the games and parties\n",
      "          +++ value +++ [0.21 0.2  0.2  0.2  0.2 ]\n",
      "the restaurants i ca not offer too much help with , i did not eat at all of them , but of the few i did eat at , i recommend toscana for the huge buffet everyday , breakfast here is well prepared and quite delicious ( although i do not recommend the scrambled eggs\n",
      "          +++ value +++ [0.21 0.2  0.19 0.2  0.2 ]\n",
      "the omlettes are delicious and you have to try one\n",
      "          +++ value +++ [0.21 0.2  0.19 0.2  0.2 ]\n",
      "for lunch , you have to check out the grill on the beach , different food everyday , always good , and makes the beach smell amazing\n",
      "          +++ value +++ [0.21 0.2  0.19 0.21 0.2 ]\n",
      "for dinner , i liked spice ( asian cuisine , ) agave ( mexican , but do not eat the calimari from here , very rubbery , ) the pizza that is delivered to the pool and the beach is awesome , make sure you try that\n",
      "          +++ value +++ [0.21 0.2  0.19 0.2  0.2 ]\n",
      "the bars were awesome , you get accustomed to speaking the language when ordering drinks , instead of drinking your usual bacardi and coke , try the brugal extra anejo , they call it the dominican babymaker , and it 's obvious why once you try it\n",
      "          +++ value +++ [0.21 0.2  0.2  0.2  0.2 ]\n",
      "the stuff tastes amazing and it does magic for someone trying to loosen up on the dance floor\n",
      "          +++ value +++ [0.21 0.2  0.2  0.2  0.2 ]\n",
      "the disco is great too , although sometimes a little empty , but still worth checking out\n",
      "          +++ value +++ [0.21 0.2  0.2  0.2  0.2 ]\n",
      "the worst part of my trip was the vendors , they do not let up , and i am a very well mannered person , which makes it hard to shut them down over and over again , make sure you do not tell them you like anything until you know you 're going to buy it , otherwise you 'll have to beat\n",
      "          +++ value +++ [0.2 0.2 0.2 0.2 0.2]\n",
      "them off with a stick to get away\n",
      "          +++ value +++ [0.2 0.2 0.2 0.2 0.2]\n",
      "try to make it to the theatre for the shows at 10pm every night , they are worth it\n",
      "          +++ value +++ [0.21 0.2  0.2  0.2  0.2 ]\n",
      "the ice breaker shows are fun too , it gets people into the swing of things\n",
      "          +++ value +++ [0.21 0.2  0.2  0.2  0.2 ]\n",
      "all in all , i would highly recommend this resort for anyone going on a honeymoon or a romantic time with the better half , there is not a very big single crowd , so parents beware taking your single sons and daughters to this resort if they 're looking to party with other singles\n",
      "          +++ value +++ [0.23 0.2  0.19 0.19 0.19]\n",
      "hope this helps you\n",
      "          +++ value +++ [0.22 0.2  0.19 0.2  0.19]\n",
      "adios amigos and amigas\n",
      "          +++ value +++ [0.22 0.2  0.19 0.2  0.19]\n",
      "===========\n",
      "truth:\n",
      "[3, 2, 3, 3, 3, 4]\n",
      "prediction:\n",
      "tensor([[3.6580e-08, 7.1439e-08, 7.8256e-05, 9.9992e-01, 1.5043e-06],\n",
      "        [9.7199e-08, 4.7277e-07, 8.6615e-04, 9.9884e-01, 2.9803e-04],\n",
      "        [5.7395e-06, 2.4570e-04, 1.4986e-02, 9.8184e-01, 2.9182e-03],\n",
      "        [2.7667e-07, 3.0203e-06, 5.5198e-04, 2.7141e-01, 7.2803e-01],\n",
      "        [1.1826e-04, 3.1205e-05, 2.0831e-03, 4.8128e-01, 5.1648e-01],\n",
      "        [2.5054e-07, 5.7264e-07, 2.2535e-05, 8.4117e-03, 9.9156e-01]])\n",
      "doc:\n",
      "great service , nice hotel , mediocre food\n",
      "          +++ value +++ [0.22 0.2  0.19 0.2  0.19]\n",
      "my husband and i stayed at excellence for five nights mid - november\n",
      "          +++ value +++ [0.22 0.2  0.2  0.19 0.19]\n",
      "we booked our trip at the very last minute so we were not able to do a ton of research on the dominican but the hotel receives high ratings thorughout the web\n",
      "          +++ clean +++ [0.2  0.2  0.2  0.21 0.2 ]\n",
      "after the one hour ride from the airport we arrived at the hotel and were greeted by everyone we met\n",
      "          +++ value +++ [0.2 0.2 0.2 0.2 0.2]\n",
      "i have to say that the staff at the hotel were very nice and made every effort to learn our names and greet us by name each time they saw us\n",
      "          +++ service +++ [0.2  0.2  0.2  0.2  0.21]\n",
      "we opted to upgrade to the excellence club and we are still trying to decide if we think it was worth it or not\n",
      "          +++ value +++ [0.22 0.2  0.2  0.19 0.19]\n",
      "as part of the excellence club , you are ushered to the club 's private lobby for check - in but , really , it almost just creates an unneccesary step in the check - in process and adds another person or two you feel like you should tip\n",
      "          +++ value +++ [0.21 0.2  0.2  0.2  0.19]\n",
      "the biggest benefits of the excellence club for us were the unlimited internet access , beach towels in the room ( they were hard to get otherwise ) , and the beach bag in our room\n",
      "          +++ value +++ [0.2 0.2 0.2 0.2 0.2]\n",
      "we did eat breakfast each morning in the excellence club which was nice because it was a small buffet and you did not have to deal with a crowd\n",
      "          +++ value +++ [0.21 0.2  0.2  0.2  0.19]\n",
      "the hotel itself was clean , the staff was very friendly , and nothing ever felt crowded\n",
      "          +++ service +++ [0.2  0.2  0.19 0.2  0.21]\n",
      "however , the food was not great\n",
      "          +++ value +++ [0.22 0.2  0.19 0.2  0.19]\n",
      "it was not bad - but it was not great\n",
      "          +++ value +++ [0.23 0.2  0.19 0.19 0.19]\n",
      "i 'm not a big eater but i was prepared to indulge on my vacation and there just was not anything i was crazy about\n",
      "          +++ value +++ [0.23 0.2  0.19 0.2  0.19]\n",
      "the presentation of the food was nice but it was just bland\n",
      "          +++ value +++ [0.22 0.2  0.19 0.19 0.19]\n",
      "i think that is the best way to describe it\n",
      "          +++ value +++ [0.22 0.2  0.19 0.2  0.19]\n",
      "the pizzas that were delivered to the pool area were good but it was unpredictable because you never knew when they would arrive\n",
      "          +++ value +++ [0.21 0.2  0.19 0.2  0.19]\n",
      "we went on two excursions - swimming with the sting - rays/sharks and the zip - line tour\n",
      "          +++ value +++ [0.21 0.2  0.2  0.2  0.19]\n",
      "we loved the zip - line excursion\n",
      "          +++ value +++ [0.21 0.2  0.2  0.2  0.2 ]\n",
      "the staff was great and our bus driver and tour guide were great\n",
      "          +++ value +++ [0.2 0.2 0.2 0.2 0.2]\n",
      "it was interesting to visit the sting - rays and swim with the sharks but the reef where we snorkeled was disappointing\n",
      "          +++ clean +++ [0.2  0.2  0.2  0.21 0.2 ]\n",
      "the fish were very small and there was not much to see\n",
      "          +++ clean +++ [0.2  0.2  0.2  0.21 0.2 ]\n",
      "the electricity went out in our room a handful of times , especially when i used the hairdryer\n",
      "          +++ value +++ [0.21 0.2  0.2  0.2  0.2 ]\n",
      "also , our ac was terrible\n",
      "          +++ location +++ [0.2  0.19 0.23 0.19 0.19]\n",
      "they tried to repair it but it just never got cool\n",
      "          +++ location +++ [0.2  0.19 0.22 0.19 0.19]\n",
      "our room was big , though , and clean\n",
      "          +++ location +++ [0.18 0.17 0.29 0.17 0.19]\n",
      "we always got housekeeping service twice a day and they refilled our mini - bar daily\n",
      "          +++ service +++ [0.2  0.19 0.2  0.19 0.21]\n",
      "in many of the reviews , people said they got sick\n",
      "          +++ service +++ [0.2 0.2 0.2 0.2 0.2]\n",
      "our representative at the hotel ( through aaa ) warned us that many people think they get sick from the water or the food but they do not realize that having too many drinks with coconut in them will also do it\n",
      "          +++ value +++ [0.21 0.2  0.2  0.2  0.2 ]\n",
      "coconut is a natural laxative so you need to limit your consumption\n",
      "          +++ clean +++ [0.2  0.2  0.19 0.21 0.2 ]\n",
      "i would still pack the immodium just to be sure\n",
      "          +++ value +++ [0.21 0.2  0.19 0.2  0.2 ]\n",
      "i could not decide if i wanted to give this hotel a 3/5 or a 4/5 but i decided to go up because of the friendly staff and the cleanliness of our room\n",
      "          +++ service +++ [0.19 0.18 0.22 0.18 0.23]\n",
      "i do not think i would go back because of the food but we had a nice time while we were there\n",
      "          +++ value +++ [0.24 0.2  0.18 0.19 0.19]\n",
      "we met a lot of great people at the swim up bar\n",
      "          +++ value +++ [0.21 0.2  0.2  0.2  0.2 ]\n",
      "===========\n",
      "truth:\n",
      "[3, 4, 3, 4, 4, 4]\n",
      "prediction:\n",
      "tensor([[8.4084e-07, 6.6263e-06, 3.7345e-04, 9.9915e-01, 4.6555e-04],\n",
      "        [1.1268e-05, 1.6399e-05, 1.9504e-03, 9.2403e-01, 7.3995e-02],\n",
      "        [8.9798e-07, 2.3409e-06, 1.2049e-04, 3.6899e-01, 6.3089e-01],\n",
      "        [3.0712e-06, 1.4998e-05, 5.3127e-05, 1.4099e-02, 9.8583e-01],\n",
      "        [9.3287e-06, 5.6259e-08, 5.9345e-07, 8.7584e-05, 9.9990e-01],\n",
      "        [3.9845e-10, 8.1773e-11, 1.4880e-09, 4.4981e-06, 1.0000e+00]])\n",
      "doc:\n",
      "very relaxing experience just returned from my 40th birthday romantic getaway with my husband\n",
      "          +++ value +++ [0.21 0.2  0.19 0.21 0.19]\n",
      "this was our first time in the dominican republic , and we have literally been to every single island in the caribbean\n",
      "          +++ clean +++ [0.21 0.2  0.19 0.21 0.19]\n",
      "so i can assure you that my review will be short , sweet , and comprehensive\n",
      "          +++ value +++ [0.21 0.2  0.19 0.2  0.2 ]\n",
      "in general , we liked the dr , and the excellence was very nice\n",
      "          +++ value +++ [0.22 0.2  0.18 0.19 0.2 ]\n",
      "the top reasons why we liked excellence were : 1) no kids ( ie\n",
      "          +++ value +++ [0.2 0.2 0.2 0.2 0.2]\n",
      ", if i want to get away from my own kids , i definitely do not want to vacation with other peoples ' kids )\n",
      "          +++ value +++ [0.21 0.2  0.19 0.2  0.19]\n",
      "it was so quiet\n",
      "          +++ value +++ [0.21 0.2  0.2  0.2  0.19]\n",
      "2) the staff and the people in the dr in general\n",
      "          +++ service +++ [0.2 0.2 0.2 0.2 0.2]\n",
      "so genuinely friendly , helpful , and wonderful\n",
      "          +++ service +++ [0.2  0.2  0.2  0.2  0.21]\n",
      "believe me , this is not true in most other areas of the caribbean\n",
      "          +++ clean +++ [0.2  0.2  0.19 0.21 0.2 ]\n",
      "the all - inclusive feature\n",
      "          +++ value +++ [0.21 0.2  0.2  0.2  0.2 ]\n",
      "loved being served , served , served\n",
      "          +++ service +++ [0.2  0.2  0.2  0.2  0.21]\n",
      "i wanted to sit on my [ - - ] all day and just be a gluttonous pig\n",
      "          +++ value +++ [0.2  0.2  0.19 0.2  0.2 ]\n",
      "and this is the perfect place to do it\n",
      "          +++ value +++ [0.22 0.2  0.19 0.19 0.19]\n",
      "4) the best selection of beach and pool lounge chairs , beds , and hammocks i 've ever seen\n",
      "          +++ clean +++ [0.2  0.19 0.2  0.21 0.2 ]\n",
      "there were palapas everywhere , so there was no shortage of shade\n",
      "          +++ clean +++ [0.2  0.2  0.2  0.21 0.2 ]\n",
      "there were so many beds , you did not have to worry about not getting one\n",
      "          +++ location +++ [0.2 0.2 0.2 0.2 0.2]\n",
      "i 'd never had the chance to sleep on a beach bed , because usually hotels have only a few , so you end up looking longingly at the lucky few who get them\n",
      "          +++ location +++ [0.2 0.2 0.2 0.2 0.2]\n",
      "ok , so here 's what i did not love about excellence :1) beach is not swimmable\n",
      "          +++ clean +++ [0.19 0.19 0.19 0.24 0.19]\n",
      "way too rough most of the time\n",
      "          +++ clean +++ [0.19 0.19 0.19 0.24 0.19]\n",
      "for this reason alone , i 'd not return here\n",
      "          +++ value +++ [0.25 0.21 0.18 0.19 0.17]\n",
      "i 'm a beach fan , and love to swim in the warm caribbean sea\n",
      "          +++ clean +++ [0.19 0.19 0.19 0.24 0.19]\n",
      "i 'm no food snob , but some of the food was downright bad\n",
      "          +++ value +++ [0.21 0.2  0.19 0.21 0.19]\n",
      "and you end up eating in the same spot for breakfast and lunch\n",
      "          +++ value +++ [0.22 0.2  0.19 0.2  0.19]\n",
      "even though they have like 7 restaurants - the majority of them are only open for dinner\n",
      "          +++ value +++ [0.21 0.2  0.19 0.2  0.19]\n",
      "we only stayed 4 nights , and we were definitely getting very tired of the breakfast/lunch selection by the 3rd day\n",
      "          +++ value +++ [0.22 0.2  0.19 0.2  0.19]\n",
      "overall , if you just want to relax by the pool and you do not care about not going in the beach , this is a very beautiful resort\n",
      "          +++ value +++ [0.22 0.2  0.18 0.21 0.18]\n",
      "the staff is wonderful\n",
      "          +++ service +++ [0.2  0.2  0.2  0.2  0.21]\n",
      "if you are looking for a place to party and be loud and crazy , this is not your place\n",
      "          +++ clean +++ [0.22 0.2  0.19 0.22 0.18]\n",
      "===========\n",
      "truth:\n",
      "[1, 0, 2, 3, 1, 0]\n",
      "prediction:\n",
      "tensor([[4.2200e-02, 9.5585e-01, 1.7459e-03, 1.8237e-04, 1.9602e-05],\n",
      "        [9.2379e-02, 8.9690e-01, 1.0464e-02, 1.4482e-04, 1.0815e-04],\n",
      "        [6.7303e-01, 3.0013e-01, 1.5393e-02, 1.0660e-02, 7.9320e-04],\n",
      "        [2.1633e-04, 1.2704e-03, 9.9103e-02, 7.3378e-01, 1.6563e-01],\n",
      "        [4.5772e-01, 4.4981e-01, 8.1876e-02, 8.7199e-03, 1.8734e-03],\n",
      "        [9.0938e-01, 8.4787e-02, 4.9554e-03, 3.2411e-04, 5.5284e-04]])\n",
      "doc:\n",
      "5- star views\n",
      "          +++ clean +++ [0.21 0.2  0.19 0.22 0.18]\n",
      "2- star service i do not know where to start\n",
      "          +++ value +++ [0.22 0.2  0.19 0.2  0.19]\n",
      "the roaches in the room , the rude waiters , bartenders , front desk , the dead flies that stayed on our friends ' mirror the entire stay , the average at best food ( only one morning in the bathroom for longer than you would want ) , the 6,7,8 times i had to trip the breakers so my wife could use the\n",
      "          +++ location +++ [0.19 0.18 0.23 0.18 0.21]\n",
      "hair dryer without our power going out , or the waste of money the excellence club turned out to be\n",
      "          +++ location +++ [0.21 0.19 0.22 0.19 0.2 ]\n",
      "i guess i 'll start with the good\n",
      "          +++ value +++ [0.22 0.2  0.2  0.19 0.19]\n",
      "the beach was fabulous\n",
      "          +++ clean +++ [0.19 0.19 0.19 0.24 0.19]\n",
      "the resort itself , d?cor , pool , beach access was great\n",
      "          +++ location +++ [0.2  0.19 0.21 0.21 0.2 ]\n",
      "ok now for the rest of the trip\n",
      "          +++ value +++ [0.21 0.2  0.2  0.2  0.19]\n",
      "we booked the excellence after changing from another resort we booked\n",
      "          +++ value +++ [0.22 0.2  0.2  0.2  0.19]\n",
      "we booked the other one a little quickly and then read some really bad reviews\n",
      "          +++ value +++ [0.21 0.2  0.2  0.2  0.19]\n",
      "so we were able to get out of that one and do a little more homework\n",
      "          +++ value +++ [0.21 0.2  0.2  0.2  0.2 ]\n",
      "we read about the excellence from trip advisor and were really excited to go\n",
      "          +++ value +++ [0.22 0.2  0.2  0.19 0.19]\n",
      "now , we 've been to the caribbean plenty and are low maintenance travelers\n",
      "          +++ value +++ [0.21 0.2  0.2  0.2  0.2 ]\n",
      "we 'll check in and the hotel usually does not hear from us until we leave\n",
      "          +++ value +++ [0.21 0.2  0.2  0.2  0.19]\n",
      "one thing we usually like to do is get to the front desk and see about upgrading rooms\n",
      "          +++ value +++ [0.21 0.2  0.2  0.2  0.19]\n",
      "we were originally booked in a garden view room\n",
      "          +++ value +++ [0.2  0.2  0.2  0.2  0.19]\n",
      "our first question at the front desk was , ??o you have any ocean view rooms available\n",
      "          +++ value +++ [0.21 0.2  0.2  0.2  0.19]\n",
      "he said , ??es , let me tell you about the excellence club\n",
      "          +++ value +++ [0.21 0.2  0.2  0.2  0.19]\n",
      "the excellence club rooms are identical to every other room in the resort ( but with a plasma tv ) and you have access to what?? basically another room where you can eat ( the same food that?? served everywhere else ) , have premium drinks , and check out dvds\n",
      "          +++ value +++ [0.21 0.2  0.2  0.2  0.19]\n",
      "he showed us where we would be staying\n",
      "          +++ value +++ [0.21 0.2  0.2  0.2  0.19]\n",
      "it was perfect , right in front of the pool over looking the ocean\n",
      "          +++ location +++ [0.2  0.2  0.21 0.2  0.19]\n",
      "much to our dismay , we show up and still have a garden view\n",
      "          +++ value +++ [0.21 0.2  0.2  0.2  0.19]\n",
      "we call the front desk and ask where the ocean view room is and he commences to telling us how wonderful the excellence club is\n",
      "          +++ value +++ [0.21 0.2  0.2  0.2  0.19]\n",
      "so great , the hustle is on\n",
      "          +++ clean +++ [0.2  0.2  0.2  0.21 0.19]\n",
      "after spending much of the first night arguing back and forth while he?? ??ooking into it?\n",
      "          +++ value +++ [0.21 0.2  0.2  0.2  0.19]\n",
      "we finally gave up and waited until the morning\n",
      "          +++ value +++ [0.21 0.2  0.2  0.2  0.2 ]\n",
      "they finally moved us to a pool front room but i still don?? why we had to pay $400 extra per couple for a plasma tv and movies\n",
      "          +++ value +++ [0.21 0.2  0.2  0.2  0.19]\n",
      "the movies ended up being ok since one morning i stayed in bed with an upset stomach and my wife did the same thing a couple of nights\n",
      "          +++ location +++ [0.21 0.2  0.21 0.2  0.19]\n",
      "the resort was pretty much empty so we were a little confused why there were no ocean front rooms available\n",
      "          +++ location +++ [0.2  0.2  0.21 0.2  0.19]\n",
      "the restaurants were empty , the bars were empty\n",
      "          +++ value +++ [0.21 0.2  0.2  0.2  0.19]\n",
      "i guess enjoying their ocean front rooms\n",
      "          +++ value +++ [0.21 0.2  0.21 0.2  0.19]\n",
      "another strange phenomenon was with it being so empty , why were the waits so long\n",
      "          +++ value +++ [0.21 0.2  0.2  0.2  0.19]\n",
      "waiting for service , waiting for a table , waiting for a drink , waiting at the front desk\n",
      "          +++ value +++ [0.21 0.2  0.2  0.2  0.2 ]\n",
      "the place was empty\n",
      "          +++ value +++ [0.21 0.2  0.19 0.2  0.19]\n",
      "there were a few nice waiters but most of them were rude , acted as if we were bothering them and sometimes just stood there and looked at us like we were stupid or something\n",
      "          +++ value +++ [0.2 0.2 0.2 0.2 0.2]\n",
      "i was amazed\n",
      "          +++ value +++ [0.21 0.2  0.2  0.2  0.2 ]\n",
      "i would recommend bringing an electrician with you as well because you??l need to get the power turned on if you want to dry your hair and run the air conditioner at the same time\n",
      "          +++ location +++ [0.21 0.2  0.21 0.19 0.2 ]\n",
      "watch your step walking underneath the vent as well so you won?? slip in the leaking water from the vent\n",
      "          +++ location +++ [0.2  0.19 0.22 0.19 0.19]\n",
      "we had roaches in our bar , the couple that went with us noticed dead flies stuck to their mirror in clear sight and they stayed there the whole time we were there\n",
      "          +++ location +++ [0.19 0.18 0.23 0.18 0.21]\n",
      "average at best\n",
      "          +++ location +++ [0.19 0.18 0.25 0.18 0.2 ]\n",
      "the quality wasn?? very good\n",
      "          +++ location +++ [0.2  0.19 0.22 0.19 0.2 ]\n",
      "we spent the whole trip scared of it after we were in the bathroom the next morning\n",
      "          +++ location +++ [0.2  0.19 0.22 0.19 0.2 ]\n",
      "we called room service one night and they were out of pepperonis for the pizza\n",
      "          +++ value +++ [0.21 0.2  0.2  0.2  0.2 ]\n",
      "( that was more funny than annoying ) and our friends went to the italian restaurant and ate dinner\n",
      "          +++ value +++ [0.22 0.2  0.19 0.2  0.19]\n",
      "after , they ordered dessert : ??e??e out of tiramisu\n",
      "          +++ value +++ [0.21 0.2  0.19 0.2  0.2 ]\n",
      "??e have one cheesecake?\n",
      "          +++ value +++ [0.21 0.2  0.2  0.2  0.2 ]\n",
      "ok , what kind\n",
      "          +++ value +++ [0.21 0.2  0.19 0.2  0.19]\n",
      "??o , we have one piece of cheesecake left\n",
      "          +++ value +++ [0.21 0.2  0.2  0.2  0.2 ]\n",
      "ran out of dessert\n",
      "          +++ value +++ [0.21 0.2  0.2  0.2  0.2 ]\n",
      "like i said before , we??e low maintenance travelers\n",
      "          +++ value +++ [0.21 0.2  0.2  0.2  0.2 ]\n",
      "we go to a cheaper place and have to wait or deal with annoyances , we don?? mind\n",
      "          +++ value +++ [0.21 0.2  0.19 0.2  0.19]\n",
      "you get what you pay for\n",
      "          +++ value +++ [0.21 0.2  0.19 0.2  0.19]\n",
      "but this is supposed to be a 4-5 star establishment and it seemed as though they didn?? know what the heck they were doing\n",
      "          +++ value +++ [0.21 0.2  0.2  0.2  0.19]\n",
      "it was just a comedy of issues from the time we showed up to the time we left\n",
      "          +++ value +++ [0.22 0.2  0.19 0.2  0.19]\n",
      "the whole trip was ruined and that?? a few thousand dollars we wish we had back\n",
      "          +++ value +++ [0.23 0.2  0.19 0.19 0.19]\n",
      "there are so many other options available down there , look elsewhere\n",
      "          +++ value +++ [0.23 0.2  0.19 0.19 0.19]\n",
      "i know we??l never return\n",
      "          +++ value +++ [0.25 0.21 0.18 0.18 0.18]\n",
      "===========\n",
      "truth:\n",
      "[3, 3, 3, 4, 3, 4]\n",
      "prediction:\n",
      "tensor([[1.3337e-06, 2.8296e-08, 4.6831e-08, 1.3547e-03, 9.9864e-01],\n",
      "        [5.4394e-07, 1.9599e-07, 1.5283e-07, 2.3779e-04, 9.9976e-01],\n",
      "        [4.6940e-06, 3.3177e-08, 1.4304e-07, 1.3275e-03, 9.9867e-01],\n",
      "        [3.0501e-08, 5.4341e-07, 3.2844e-07, 1.8999e-05, 9.9998e-01],\n",
      "        [3.5019e-06, 5.1406e-08, 2.6429e-07, 1.9837e-06, 9.9999e-01],\n",
      "        [2.0109e-08, 4.3648e-08, 1.8418e-07, 5.4377e-05, 9.9995e-01]])\n",
      "doc:\n",
      "we just got back yesterday from a one week stay at the excellence resort in punta cana\n",
      "          +++ value +++ [0.21 0.2  0.19 0.2  0.2 ]\n",
      "i had done my research online and found that with the exception of the food , there were almost 100% positive things that people had to say about this resort\n",
      "          +++ value +++ [0.22 0.2  0.19 0.19 0.19]\n",
      "it all lived up to be true\n",
      "          +++ value +++ [0.22 0.2  0.19 0.19 0.19]\n",
      "the resort was magical\n",
      "          +++ value +++ [0.21 0.2  0.2  0.19 0.2 ]\n",
      "my wife and i went with 2 friends of ours and were blown away\n",
      "          +++ value +++ [0.22 0.2  0.19 0.2  0.19]\n",
      "the pool and beach were spectacular\n",
      "          +++ clean +++ [0.19 0.19 0.19 0.22 0.19]\n",
      "as tropical beach rooms go , the rooms were nicely appointed with an open feel\n",
      "          +++ location +++ [0.18 0.18 0.28 0.18 0.19]\n",
      "bathtub in the room , shower in the bathroom , was a nice tough\n",
      "          +++ location +++ [0.18 0.18 0.27 0.18 0.18]\n",
      "the only negative thing i can say about this experience was the food\n",
      "          +++ value +++ [0.23 0.2  0.19 0.19 0.19]\n",
      "even though at all the restaurants you ordered from menus , the food was prepared banquet style\n",
      "          +++ value +++ [0.22 0.2  0.2  0.2  0.19]\n",
      "what i mean by this is that it was not as hot and fresh as food would typically be that is prepared for you\n",
      "          +++ value +++ [0.22 0.2  0.19 0.19 0.19]\n",
      "if you are a person that typically eats in nice restaurants in cities like new york , san francisco , etc\n",
      "          +++ value +++ [0.21 0.2  0.19 0.2  0.19]\n",
      "you will probably rate this food around a c+ or b -\n",
      "          +++ value +++ [0.23 0.2  0.19 0.19 0.19]\n",
      "though i am not typically a buffet type person , i would highly recommend you go to their buffet for both breakfast and lunch\n",
      "          +++ value +++ [0.22 0.2  0.19 0.2  0.19]\n",
      "you will not be disappointed as they will prepare eggs , meats , pastas individually for you\n",
      "          +++ value +++ [0.22 0.2  0.19 0.2  0.2 ]\n",
      "lastly on the food , steer clear of the lobster house\n",
      "          +++ value +++ [0.21 0.2  0.19 0.2  0.19]\n",
      "it was the only restaurant that highly disappointed us\n",
      "          +++ value +++ [0.22 0.2  0.19 0.2  0.19]\n",
      "every place else ( the mexican , french , italian , etc\n",
      "          +++ value +++ [0.21 0.2  0.2  0.2  0.19]\n",
      ") provided the ambiance , a decent meal , wine , etc\n",
      "          +++ value +++ [0.21 0.2  0.2  0.2  0.2 ]\n",
      "for a very nice evening\n",
      "          +++ value +++ [0.21 0.2  0.19 0.2  0.19]\n",
      "outside of the food , the resort and its people were truly amazing\n",
      "          +++ service +++ [0.2  0.2  0.19 0.2  0.21]\n",
      "we will definitely go back\n",
      "          +++ value +++ [0.23 0.2  0.18 0.19 0.2 ]\n",
      "this review was written by an ad agency executive who travels almost half the year in mostly big cities like la , new york , las vegas and san francisco\n",
      "          +++ clean +++ [0.2  0.2  0.2  0.21 0.2 ]\n",
      "i am lucky enough to entertain clients in very fine restaurants and would probably be considered a food snob\n",
      "          +++ value +++ [0.22 0.2  0.19 0.2  0.19]\n",
      "===========\n",
      "truth:\n",
      "[4, 4, 4, 4, 4, 4]\n",
      "prediction:\n",
      "tensor([[6.3634e-09, 6.6011e-11, 1.1526e-11, 2.5008e-07, 1.0000e+00],\n",
      "        [2.9541e-08, 1.1291e-08, 5.9148e-10, 1.6055e-06, 1.0000e+00],\n",
      "        [1.1582e-07, 1.2325e-08, 1.7565e-08, 6.7471e-06, 9.9999e-01],\n",
      "        [3.5451e-08, 1.1549e-06, 7.6374e-07, 1.3465e-05, 9.9998e-01],\n",
      "        [1.9543e-06, 2.7467e-08, 1.3066e-07, 2.8922e-07, 1.0000e+00],\n",
      "        [1.2131e-08, 8.6012e-09, 2.5163e-08, 2.2591e-06, 1.0000e+00]])\n",
      "doc:\n",
      "life does not get better than this\n",
      "          +++ value +++ [0.23 0.21 0.18 0.2  0.18]\n",
      "my husband and i stayed at excellence punta cana from 10th nov - 24th nov\n",
      "          +++ value +++ [0.22 0.2  0.2  0.19 0.19]\n",
      "this was our first holiday in 2 years , so we were looking for somewhere where we can just relax on a beautiful beach or by the pool\n",
      "          +++ value +++ [0.21 0.2  0.19 0.21 0.19]\n",
      "we did not expect much with regards to the food after having read poor reviews and to be honest some of them had us a little worried\n",
      "          +++ value +++ [0.22 0.2  0.19 0.19 0.19]\n",
      "i am pleased to say that excellence punta cana exceeded our expectations by a mile\n",
      "          +++ value +++ [0.22 0.2  0.19 0.19 0.19]\n",
      "for the first couple of day , i just walked around with my mouth open\n",
      "          +++ clean +++ [0.2 0.2 0.2 0.2 0.2]\n",
      "the place is absolutely breathtaking\n",
      "          +++ clean +++ [0.19 0.19 0.2  0.22 0.2 ]\n",
      "we loved our room (3101) , clean , spacious and quiet\n",
      "          +++ location +++ [0.19 0.18 0.26 0.18 0.2 ]\n",
      "the beach is beautiful , the sea is so much fun to swim in ( we both like the waves\n",
      "          +++ clean +++ [0.2  0.2  0.2  0.21 0.2 ]\n",
      ") , the pool is huge and sparkling clean with plenty of beds/loungers\n",
      "          +++ clean +++ [0.2  0.2  0.2  0.21 0.2 ]\n",
      "as i said we did not expect much and we 're not sure why people are complaining so much ( bearing in mind that we are very fussy eaters )\n",
      "          +++ value +++ [0.21 0.19 0.2  0.2  0.19]\n",
      "for a start it is an all - inclusive resort not a michelin - star restaurant\n",
      "          +++ value +++ [0.23 0.2  0.19 0.19 0.19]\n",
      "the choices were plentiful and the food was fresh , well presented and well cooked\n",
      "          +++ value +++ [0.21 0.2  0.2  0.19 0.21]\n",
      "we were there for 2 weeks and could have probably stayed another 2 weeks without getting bored of the food\n",
      "          +++ value +++ [0.23 0.2  0.19 0.19 0.19]\n",
      "the entertainment team do a great job , the bar staff are fun , beach  pool servers always around , the waiting staff friendly and attentive , the housekeeping ladies kept our room spotlessly clean and tidy\n",
      "          +++ service +++ [0.19 0.18 0.2  0.19 0.24]\n",
      "i 'm not going to single out any staff in particular because i think every single one played a big part in having made our stay so enjoyable , and in particular those behind the scenes who works so hard but do not get the tips or the credit they derserve\n",
      "          +++ service +++ [0.2 0.2 0.2 0.2 0.2]\n",
      "we 've had a wonderful time and although we usually prefer not to return to the same place ( so as not to spoil it ) , excellence punta cana is one of those places that we would certainly not hesitate going back to\n",
      "          +++ value +++ [0.24 0.21 0.18 0.18 0.19]\n",
      "in fact we would have quite liked to move in\n",
      "          +++ value +++ [0.23 0.2  0.19 0.19 0.19]\n",
      "there are so much more to say , but i could go on forever\n",
      "          +++ value +++ [0.23 0.2  0.19 0.19 0.19]\n",
      "this place is a taste of heaven , go with the right attitude and you will not be dissapointed\n",
      "          +++ value +++ [0.22 0.2  0.19 0.19 0.2 ]\n",
      "everything that they offer must surely satisfy 90% of guests\n",
      "          +++ value +++ [0.21 0.2  0.19 0.2  0.2 ]\n",
      "as for the other 10% , there is no satisfaction no matter what you do\n",
      "          +++ value +++ [0.21 0.2  0.2  0.2  0.2 ]\n",
      "they should probably rather stay at home and certainly not travel to a 3rd world country\n",
      "          +++ value +++ [0.22 0.2  0.2  0.2  0.19]\n",
      "ps : 1\n",
      "          +++ clean +++ [0.2  0.2  0.2  0.21 0.2 ]\n",
      "enjoy the ride from the airport (50minutes ) , its an excursion on its own , saves having to pay to go on one in precious holiday time\n",
      "          +++ clean +++ [0.2  0.2  0.19 0.22 0.2 ]\n",
      "find the soft serve machine by cafe kafe bar\n",
      "          +++ clean +++ [0.2  0.2  0.2  0.21 0.2 ]\n",
      "nancy 's shop is the best , she wo not rip you off\n",
      "          +++ clean +++ [0.2  0.2  0.2  0.21 0.2 ]\n",
      "( with the other vendors everything always starts at $200, and you can get it down to $15, nancy gives a reasonable price from the start )4\n",
      "          +++ clean +++ [0.2 0.2 0.2 0.2 0.2]\n",
      "go to the sports bar for ice cold water\n",
      "          +++ value +++ [0.21 0.2  0.2  0.2  0.2 ]\n",
      "===========\n",
      "truth:\n",
      "[4, 4, 4, 4, 4, 4]\n",
      "prediction:\n",
      "tensor([[1.3482e-09, 5.5344e-15, 2.4204e-15, 3.8888e-11, 1.0000e+00],\n",
      "        [2.2262e-07, 2.2185e-10, 1.8590e-12, 3.9325e-09, 1.0000e+00],\n",
      "        [1.7217e-08, 2.9531e-09, 2.4548e-09, 2.3951e-09, 1.0000e+00],\n",
      "        [2.0244e-08, 9.9657e-07, 4.6473e-08, 2.5267e-08, 1.0000e+00],\n",
      "        [6.9858e-06, 2.6199e-08, 1.4574e-07, 5.6835e-09, 9.9999e-01],\n",
      "        [1.7755e-07, 9.0359e-10, 3.1757e-10, 1.1514e-08, 1.0000e+00]])\n",
      "doc:\n",
      "everything is excellent at excellence punta cana we just got back from our honeymoon\n",
      "          +++ value +++ [0.22 0.2  0.19 0.19 0.19]\n",
      "we had an amazing time at excellence punta cana\n",
      "          +++ value +++ [0.22 0.2  0.19 0.19 0.2 ]\n",
      "we felt we were in paradise\n",
      "          +++ value +++ [0.21 0.2  0.2  0.2  0.19]\n",
      "the hotel and service was excellent\n",
      "          +++ service +++ [0.2  0.2  0.2  0.2  0.21]\n",
      "the whole staff was very friendly and so polite\n",
      "          +++ service +++ [0.2  0.2  0.2  0.2  0.21]\n",
      "my husband and i did not want to leave the resort\n",
      "          +++ value +++ [0.21 0.2  0.2  0.2  0.2 ]\n",
      "they made us feel very special\n",
      "          +++ service +++ [0.2 0.2 0.2 0.2 0.2]\n",
      "we have never experience a trip like this one\n",
      "          +++ value +++ [0.22 0.2  0.19 0.19 0.19]\n",
      "we loved it so much we are gathering a group of couple to go again early next summer\n",
      "          +++ value +++ [0.22 0.2  0.19 0.19 0.19]\n",
      "we never experience a problem while our stay\n",
      "          +++ value +++ [0.21 0.2  0.2  0.19 0.19]\n",
      "all of our belongings we safe , nothing was missing\n",
      "          +++ value +++ [0.22 0.2  0.2  0.19 0.19]\n",
      "ca not wait to go back\n",
      "          +++ value +++ [0.23 0.21 0.19 0.19 0.19]\n",
      "much love to maria isabel and carlos from excellence club concierge - - from mr\n",
      "          +++ value +++ [0.21 0.2  0.2  0.2  0.19]\n",
      "===========\n",
      "truth:\n",
      "[4, 4, 4, 4, 4, 4]\n",
      "prediction:\n",
      "tensor([[1.4498e-09, 8.5083e-13, 4.1866e-13, 5.5214e-08, 1.0000e+00],\n",
      "        [2.2207e-08, 6.0916e-10, 9.8872e-11, 2.4354e-06, 1.0000e+00],\n",
      "        [1.1146e-08, 1.9252e-08, 2.9254e-08, 6.0871e-07, 1.0000e+00],\n",
      "        [4.5215e-09, 4.1306e-07, 8.1024e-07, 1.8986e-05, 9.9998e-01],\n",
      "        [1.8055e-06, 1.4050e-08, 1.3543e-07, 7.4386e-08, 1.0000e+00],\n",
      "        [2.4027e-08, 2.5745e-10, 9.9839e-10, 1.1573e-07, 1.0000e+00]])\n",
      "doc:\n",
      "the pool and beach were beautiful this hotel catered to every persons needs\n",
      "          +++ value +++ [0.21 0.2  0.2  0.19 0.2 ]\n",
      "i love the fact that it is all inclusive food and alcohol\n",
      "          +++ value +++ [0.21 0.2  0.2  0.2  0.2 ]\n",
      "just because the hotel says it is all inclusive does not mean you dont have to tip\n",
      "          +++ value +++ [0.21 0.2  0.19 0.2  0.2 ]\n",
      "the people there work 12 days straight with 2 days off\n",
      "          +++ value +++ [0.2 0.2 0.2 0.2 0.2]\n",
      "they work up to 16 hours a day to make your experience there comfortable\n",
      "          +++ value +++ [0.2 0.2 0.2 0.2 0.2]\n",
      "so i made sure i tipped everyone who helped me\n",
      "          +++ service +++ [0.2 0.2 0.2 0.2 0.2]\n",
      "it is 35 pesos to one american dollar so you can do the math\n",
      "          +++ clean +++ [0.2 0.2 0.2 0.2 0.2]\n",
      "the people that work in entertainment , cesar , mariel , ines , whinny were all very good\n",
      "          +++ value +++ [0.2 0.2 0.2 0.2 0.2]\n",
      "they taught me and my husband many things about there culture such as dancing\n",
      "          +++ value +++ [0.2 0.2 0.2 0.2 0.2]\n",
      "also there was a bartender named juan who made the best drinks there\n",
      "          +++ value +++ [0.2 0.2 0.2 0.2 0.2]\n",
      "===========\n"
     ]
    }
   ],
   "source": [
    "asp_inc_overall = False\n",
    "if not asp_inc_overall: \n",
    "    nasp_analysis = hyper_params[\"num_aspect\"] - 1\n",
    "else:\n",
    "    nasp_analysis = hyper_params[\"num_aspect\"]\n",
    "    \n",
    "np.set_printoptions(precision=3)\n",
    "asp_name = [\"overall\", \"value\", \"room\", \"location\", \"clean\", \"service\"]\n",
    "for i in range(10):\n",
    "    print(\"truth:\")\n",
    "    print( df_test.iloc[i,0:6].values.flatten().tolist() )\n",
    "    print(\"prediction:\")\n",
    "    print( outs[i][0:6] )\n",
    "    print(\"doc:\")\n",
    "    dasp = torch.argmax(asps[i][:,0:nasp_analysis],dim=1).numpy()\n",
    "    if asp_inc_overall: dasp_noall = torch.argmax(asps[i][:,1:6],dim=1).numpy()\n",
    "    dasp_dist = torch.nn.functional.softmax(asps[i][:,0:nasp_analysis], dim=1).numpy()\n",
    "#     dasp_dist = asps[i][:,0:nasp_analysis].numpy()\n",
    "    for senti,s in enumerate(df_test.iloc[i,6]):\n",
    "        print(s)\n",
    "        if asp_inc_overall:\n",
    "            print(\"          +++ \"+ asp_name[dasp[senti]] + \" +++ \" + asp_name[dasp_noall[senti]+1] + \" +++ \" + str(dasp_dist[senti]) )\n",
    "        else:\n",
    "            print(\"          +++ \"+ asp_name[dasp[senti]+1] + \" +++ \" + str( np.around(dasp_dist[senti], decimals=2) ) )\n",
    "    print(\"===========\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_hotel_asp(asp_pred, asp_true, asp_inc_overall):\n",
    "    asp_to_id = {\"value\":0, \"room\":1, \"location\":2, \"cleanliness\":3, \"service\":4, \"none\":-1}\n",
    "    asp_true = np.array( [asp_to_id[l] for l in asp_true] )\n",
    "    print(\"total true: \" + str(len(asp_true)) )\n",
    "    print(\"total not none: \" + str(sum(asp_true>0)) )\n",
    "    \n",
    "    asp_pred_index = []\n",
    "    if asp_inc_overall:\n",
    "        for i in range(1000):\n",
    "            asp_pred_index.append( asp_pred[i][:,1:6].numpy().argsort() )\n",
    "    else:\n",
    "        for i in range(1000):\n",
    "            asp_pred_index.append( asp_pred[i][:,0:5].numpy().argsort() )\n",
    "    asp_pred_index = np.concatenate( asp_pred_index , axis=0)\n",
    "    \n",
    "    result_index = []\n",
    "    for i,lbl in enumerate(asp_true):\n",
    "        if(lbl==-1):\n",
    "            result_index.append(-1)\n",
    "        else:\n",
    "            at = np.where(asp_pred_index[i,] == lbl)\n",
    "            result_index.append(at[0][0])\n",
    "    result_index = np.array(result_index)\n",
    "    \n",
    "    print(\"Top 1 ACC:\")\n",
    "    print( sum(result_index>=4) / sum(result_index>=0) )\n",
    "    print(\"Top 2 ACC:\")\n",
    "    print( sum(result_index>=3) / sum(result_index>=0) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "yifan_label = open(dataset_dir + \"test_aspect_0.yifanmarjan.aspect\", \"r\").readlines()\n",
    "yifan_label = [s.split()[0] for s in yifan_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total true: 1000\n",
      "total not none: 454\n",
      "Top 1 ACC:\n",
      "0.7321772639691715\n",
      "Top 2 ACC:\n",
      "0.8863198458574181\n"
     ]
    }
   ],
   "source": [
    "eval_hotel_asp(asps, yifan_label, asp_inc_overall=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "fan_label = open(dataset_dir + \"test_aspect_0.fan.aspect\", \"r\").readlines()\n",
    "fan_label = [s.split()[0] for s in fan_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total true: 621\n",
      "total not none: 288\n",
      "Top 1 ACC:\n",
      "0.7079646017699115\n",
      "Top 2 ACC:\n",
      "0.8849557522123894\n"
     ]
    }
   ],
   "source": [
    "eval_hotel_asp(asps, fan_label, asp_inc_overall=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
