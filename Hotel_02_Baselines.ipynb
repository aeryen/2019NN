{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import comet_ml\n",
    "experiment = comet_ml.Experiment(project_name=\"2019nn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "from fastai.text import *\n",
    "from data_helpers.Data import *\n",
    "from fastai.text.transform import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params = {\n",
    "    \"max_sequence_length\": 40*70,\n",
    "    \"batch_size\": 32,\n",
    "    \"num_epochs1\": 12,\n",
    "    \"num_epochs2\": 15,\n",
    "    \"num_aspect\": 6,\n",
    "    \"num_rating\": 5,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.log_parameters(hyper_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load LM Databunch and LM Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lm_db = load_data(\"./data/\", \"hotel_lm_databunch.1001\")\n",
    "# lm_learn = language_model_learner(lm_db, AWD_LSTM)\n",
    "# lm_learn = lm_learn.load(\"lang_model_hotel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lm_learn.save_encoder('lang_model_hotel_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_db = load_data(\"./data/\", \"hotel_clas_databunch.TraValTes\")\n",
    "cls_db.batch_size=hyper_params[\"batch_size\"]\n",
    "cls_db.batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Feature Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool_combo(output, start, end):\n",
    "    avg_pool = output[start:end, :].mean(dim=0)\n",
    "    max_pool = output[start:end, :].max(dim=0)[0]\n",
    "    x = torch.cat([output[-1,:], max_pool, avg_pool], 0)\n",
    "    return x\n",
    "\n",
    "def sentence_pool_1200(outputs, mask, p_index):\n",
    "    \"Pool MultiBatchEncoder outputs into one vector [last_hidden, max_pool, avg_pool].\"\n",
    "    output = outputs[-1]\n",
    "    seq_max = output.size(1)\n",
    "    doc_start = mask.int().sum(dim=1)\n",
    "    \n",
    "    batch = []\n",
    "    for doci in range(0,output.shape[0]):\n",
    "        pi = p_index[doci,:].nonzero(as_tuple=True)[0].int()\n",
    "        doc = []\n",
    "        for senti in range( len(pi) ):\n",
    "            if senti==0:\n",
    "                doc.append( pool_combo(output[doci,:,:], doc_start[doci], pi[senti]) )\n",
    "            else:\n",
    "                doc.append( pool_combo(output[doci,:,:], pi[senti-1]+1, pi[senti]) )\n",
    "            \n",
    "        batch.append( torch.stack(doc, 0) )\n",
    "\n",
    "    return batch\n",
    "\n",
    "def sentence_pool_400(outputs, mask, p_index):\n",
    "    output = outputs[-1]\n",
    "    \n",
    "    batch = []\n",
    "    for doci in range(0,output.shape[0]):\n",
    "        doc = output[doci,p_index[doci,:],:]\n",
    "        batch.append( doc )\n",
    "\n",
    "    return batch\n",
    "\n",
    "def masked_concat_pool(outputs, mask):\n",
    "    \"Pool MultiBatchEncoder outputs into one vector [last_hidden, max_pool, avg_pool].\"\n",
    "    output = outputs[-1]\n",
    "    avg_pool = output.masked_fill(mask[:, :, None], 0).mean(dim=1)\n",
    "    avg_pool *= output.size(1) / (output.size(1)-mask.type(avg_pool.dtype).sum(dim=1))[:,None]\n",
    "    max_pool = output.masked_fill(mask[:,:,None], -float('inf')).max(dim=1)[0]\n",
    "    x = torch.cat([output[:,-1], max_pool, avg_pool], 1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEFINE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceEncoder(Module):\n",
    "    \"Create an encoder over `module` that can process a full sentence.\"\n",
    "    def __init__(self, bptt:int, max_len:int, module:nn.Module, vocab, pad_idx:int=1):\n",
    "        print(\"Encoder init\")\n",
    "        self.max_len,self.bptt,self.module,self.pad_idx = max_len,bptt,module,pad_idx\n",
    "        self.vocab = vocab\n",
    "        self.period_index = self.vocab.stoi[\"xxperiod\"]\n",
    "\n",
    "    def concat(self, arrs:Collection[Tensor])->Tensor:\n",
    "        \"Concatenate the `arrs` along the batch dimension.\"\n",
    "        return [torch.cat([l[si] for l in arrs], dim=1) for si in range_of(arrs[0])]\n",
    "\n",
    "    def reset(self):\n",
    "        if hasattr(self.module, 'reset'): self.module.reset()\n",
    "\n",
    "    def forward(self, input:LongTensor)->Tuple[Tensor,Tensor]:\n",
    "        bs,sl = input.size()\n",
    "        self.reset()\n",
    "        raw_outputs,outputs,masks = [],[],[]\n",
    "        p_index = []\n",
    "        for i in range(0, sl, self.bptt):\n",
    "            r, o = self.module(input[:,i: min(i+self.bptt, sl)])\n",
    "            if i>(sl-self.max_len):\n",
    "                masks.append(input[:,i: min(i+self.bptt, sl)] == self.pad_idx)\n",
    "                raw_outputs.append(r)\n",
    "                outputs.append(o)\n",
    "                p_index.append( input[:,i: min(i+self.bptt, sl)] == self.period_index )\n",
    "                \n",
    "#         print(\"number of sentences in docs:\")\n",
    "#         n_sent = torch.sum( x==self.vocab.stoi[\"xxperiod\"] , dim=1)\n",
    "#         print(n_sent)\n",
    "        \n",
    "        period_index = torch.cat(p_index,dim=1)\n",
    "        \n",
    "        return self.concat(raw_outputs),self.concat(outputs), \\\n",
    "               torch.cat(masks,dim=1),period_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline 01: Fastai Default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.add_tag(\"base01\")\n",
    "\n",
    "class Base01Module(Module):\n",
    "    def __init__(self, n_asp:int, n_rat:int, layers:Collection[int], drops:Collection[float]):\n",
    "        print(\"base01 init\")\n",
    "        print(\"Num Aspect: \"+str(n_asp) )\n",
    "        print(\"Num Rating: \"+str(n_rat) )\n",
    "        self.n_asp = n_asp\n",
    "        self.n_rat = n_rat\n",
    "        \n",
    "        mod_layers = []\n",
    "        mod_layers += bn_drop_lin(1200, 50, p=0.5, actn=nn.ReLU(inplace=True))\n",
    "        mod_layers += bn_drop_lin(50, n_asp*n_rat, p=0.1, actn=None)\n",
    "        self.layers = nn.Sequential(*mod_layers)\n",
    "\n",
    "    def forward(self, input:Tuple[Tensor,Tensor,Tensor,Tensor])->Tuple[Tensor,Tensor,Tensor]:\n",
    "        raw_outputs,outputs,mask,p_index = input\n",
    "        \n",
    "        x = masked_concat_pool(outputs, mask)\n",
    "\n",
    "        sentiment_dist = self.layers(x)\n",
    "        sentiment_dist = sentiment_dist.view(-1, self.n_asp, self.n_rat)\n",
    "        \n",
    "        return sentiment_dist,raw_outputs,outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline 02: Sentence feature (400) extract then estimate distribution, sent. dist. sumed to doc output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.add_tag(\"base02\")\n",
    "\n",
    "class SimpleSentModule(Module):\n",
    "    \"Create a linear classifier with pooling.\"\n",
    "    def __init__(self, n_asp:int, n_rat:int, layers:Collection[int], drops:Collection[float]):\n",
    "        print(\"SimpleSentModule init\")\n",
    "        print(\"Num Aspect: \"+str(n_asp) )\n",
    "        print(\"Num Rating: \"+str(n_rat) )\n",
    "        self.n_asp = n_asp\n",
    "        self.n_rat = n_rat\n",
    "        \n",
    "        mod_layers = []\n",
    "#         mod_layers += bn_drop_lin(400, 60, p=0.4, actn=nn.ReLU(inplace=True))\n",
    "        mod_layers += bn_drop_lin(400, n_asp*n_rat, p=0, actn=None)\n",
    "        self.layers = nn.Sequential(*mod_layers)\n",
    "\n",
    "    def forward(self, input:Tuple[Tensor,Tensor,Tensor,Tensor])->Tuple[Tensor,Tensor,Tensor]:\n",
    "        raw_outputs,outputs,mask,p_index = input\n",
    "\n",
    "        # takes only last layer output\n",
    "        output = outputs[-1] # [batch, seq_len, emb_size]\n",
    "\n",
    "        result = []\n",
    "        for bati in range(0,output.shape[0]):\n",
    "            sent_output = output[bati, p_index[bati,:], :]\n",
    "            sentiment_dist = self.layers(sent_output)\n",
    "            sentiment_dist = torch.sum(sentiment_dist, dim=0, keepdim=True)\n",
    "            sentiment_dist = sentiment_dist.view(-1, self.n_asp, self.n_rat)\n",
    "            result.append(sentiment_dist)\n",
    "        \n",
    "        result = torch.cat( result, dim=0 )\n",
    "        \n",
    "        return result,raw_outputs,outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline 03: average sentence combo pool feature then do document BMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.add_tag(\"base03\")\n",
    "\n",
    "class ClsModule1200avg(Module):\n",
    "    \"Create a linear classifier with pooling.\"\n",
    "    def __init__(self, n_asp:int, n_rat:int, layers:Collection[int], drops:Collection[float]):\n",
    "        print(\"CLS init\")\n",
    "        print(\"Num Aspect: \"+str(n_asp) )\n",
    "        print(\"Num Rating: \"+str(n_rat) )\n",
    "        self.n_asp = n_asp\n",
    "        self.n_rat = n_rat\n",
    "        \n",
    "        mod_layers = []\n",
    "        mod_layers += bn_drop_lin( 1200, 50, p=0.5, actn=nn.ReLU(inplace=True) )\n",
    "        mod_layers += bn_drop_lin( 50, self.n_asp+1, p=0, actn=torch.nn.Softmax(dim=1) )\n",
    "#         mod_layers += bn_drop_lin( 1200, self.n_asp+1, p=0, actn=torch.nn.Softmax(dim=1) )\n",
    "        self.aspect = nn.Sequential(*mod_layers)\n",
    "        \n",
    "        mod_layers = []\n",
    "        mod_layers += bn_drop_lin( 1200, 50, p=0.5, actn=nn.ReLU(inplace=True) )\n",
    "        mod_layers += bn_drop_lin( 50, self.n_rat, p=0, actn=torch.nn.Softmax(dim=1) )\n",
    "#         mod_layers += bn_drop_lin( 1200, self.n_rat, p=0, actn=torch.nn.Softmax(dim=1) )\n",
    "        self.sentiment = nn.Sequential(*mod_layers)\n",
    "\n",
    "    def forward(self, input:Tuple[Tensor,Tensor,Tensor,Tensor])->Tuple[Tensor,Tensor,Tensor]:\n",
    "        raw_outputs,outputs,mask,p_index = input\n",
    "\n",
    "        output = outputs[-1] # [batch, seq_len, emb_size]\n",
    "\n",
    "        # print(\"number of sentences in docs:\")\n",
    "        n_sent = torch.sum( p_index , dim=1)\n",
    "\n",
    "        batch = sentence_extract_pool(outputs, mask, p_index)\n",
    "        doc_list = []\n",
    "        result = []\n",
    "        for doci in range(0,output.shape[0]):\n",
    "            sent_output = batch[doci]\n",
    "            doc_output = sent_output.mean(dim=0, keepdim=True)\n",
    "            doc_list.append(doc_output)\n",
    "\n",
    "        doc_list = torch.cat( doc_list, dim=0 )\n",
    "        aspect_dist = self.aspect(doc_list)         # [aspect]\n",
    "        sentiment_dist = self.sentiment(doc_list)   # [sentiment]\n",
    "        result = torch.bmm(aspect_dist.unsqueeze(2), sentiment_dist.unsqueeze(1))\n",
    "        \n",
    "        return result,raw_outputs,outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_classifier(arch:Callable, vocab_sz:int, vocab, n_class:int, bptt:int=70, max_len:int=20*70, config:dict=None,\n",
    "                        drop_mult:float=1., lin_ftrs:Collection[int]=None, ps:Collection[float]=None,\n",
    "                        pad_idx:int=1) -> nn.Module:\n",
    "    \"Create a text classifier from `arch` and its `config`, maybe `pretrained`.\"\n",
    "    print(\"CUSTOM DEFINED CLASSIFIER\")\n",
    "    meta = text.learner._model_meta[arch]\n",
    "    config = ifnone(config, meta['config_clas']).copy()\n",
    "    for k in config.keys():\n",
    "        if k.endswith('_p'): config[k] *= drop_mult\n",
    "    if lin_ftrs is None: lin_ftrs = [50]\n",
    "    if ps is None:  ps = [0.1]*len(lin_ftrs)\n",
    "    layers = [config[meta['hid_name']] * 3] + lin_ftrs + [n_class]\n",
    "    ps = [config.pop('output_p')] + ps\n",
    "    init = config.pop('init') if 'init' in config else None\n",
    "    encoder = SentenceEncoder(bptt, max_len, arch(vocab_sz, **config), vocab, pad_idx=pad_idx)\n",
    "    cls_layer = Base01Module(n_asp=hyper_params[\"num_aspect\"], n_rat=hyper_params[\"num_rating\"], layers=layers, drops=ps)\n",
    "    model = SequentialRNN(encoder, cls_layer)\n",
    "    return model if init is None else model.apply(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_classifier_learner(data:DataBunch, arch:Callable, bptt:int=70, max_len:int=20*70, config:dict=None,\n",
    "                            pretrained:bool=True, drop_mult:float=1., lin_ftrs:Collection[int]=None,\n",
    "                            ps:Collection[float]=None, **learn_kwargs) -> 'TextClassifierLearner':\n",
    "    \"Create a `Learner` with a text classifier from `data` and `arch`.\"\n",
    "    model = get_text_classifier(arch, len(data.vocab.itos), data.vocab, data.c, bptt=bptt, max_len=max_len,\n",
    "                                config=config, drop_mult=drop_mult, lin_ftrs=lin_ftrs, ps=ps)\n",
    "    meta = text.learner._model_meta[arch]\n",
    "    learn = RNNLearner(data, model, split_func=meta['split_clas'], **learn_kwargs)\n",
    "    if pretrained:\n",
    "        if 'url' not in meta:\n",
    "            warn(\"There are no pretrained weights for that architecture yet!\")\n",
    "            return learn\n",
    "        model_path = untar_data(meta['url'], data=False)\n",
    "        fnames = [list(model_path.glob(f'*.{ext}'))[0] for ext in ['pth', 'pkl']]\n",
    "        learn = learn.load_pretrained(*fnames, strict=False)\n",
    "        learn.freeze()\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification loss and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLabelCEL(nn.CrossEntropyLoss):\n",
    "    def forward(self, input, target, nasp=6):\n",
    "        target = target.long()\n",
    "        loss = 0\n",
    "        for i in range(nasp):\n",
    "            loss = loss + super(MultiLabelCEL, self).forward(input[:,i,:], target[:,i])\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_acc(preds, targs, nasp=6, nrat=5):\n",
    "    preds = preds[:,0:nasp,:]\n",
    "    preds = preds.contiguous().view(-1, nrat)\n",
    "    preds = torch.max(preds, dim=1)[1]\n",
    "    targs = targs.contiguous().view(-1).long()\n",
    "    return (preds==targs).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_clas_acc(asp_index):\n",
    "    def asp_acc(preds, targs):\n",
    "        preds = torch.max(preds, dim=2)[1]\n",
    "        targs = targs.contiguous().long()\n",
    "        return (preds[:,asp_index]==targs[:,asp_index]).float().mean()\n",
    "    return asp_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_0(preds, targs):\n",
    "    preds = torch.max(preds, dim=2)[1]\n",
    "    targs = targs.contiguous().long()\n",
    "    return (preds[:,0]==targs[:,0]).float().mean()\n",
    "def acc_1(preds, targs):\n",
    "    preds = torch.max(preds, dim=2)[1]\n",
    "    targs = targs.contiguous().long()\n",
    "    return (preds[:,1]==targs[:,1]).float().mean()\n",
    "def acc_2(preds, targs):\n",
    "    preds = torch.max(preds, dim=2)[1]\n",
    "    targs = targs.contiguous().long()\n",
    "    return (preds[:,2]==targs[:,2]).float().mean()\n",
    "def acc_3(preds, targs):\n",
    "    preds = torch.max(preds, dim=2)[1]\n",
    "    targs = targs.contiguous().long()\n",
    "    return (preds[:,3]==targs[:,3]).float().mean()\n",
    "def acc_4(preds, targs):\n",
    "    preds = torch.max(preds, dim=2)[1]\n",
    "    targs = targs.contiguous().long()\n",
    "    return (preds[:,4]==targs[:,4]).float().mean()\n",
    "def acc_5(preds, targs):\n",
    "    preds = torch.max(preds, dim=2)[1]\n",
    "    targs = targs.contiguous().long()\n",
    "    return (preds[:,5]==targs[:,5]).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clas_mse(asp_index):\n",
    "    def asp_mse(preds, targs):\n",
    "        preds = torch.max(preds, dim=2)[1].float()[:,asp_index]\n",
    "        targs = targs.contiguous().float()[:,asp_index]\n",
    "        return torch.nn.functional.mse_loss(preds, targs)\n",
    "    return asp_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clas_mse0(preds, targs):\n",
    "    preds = torch.max(preds, dim=2)[1].float()[:,0]\n",
    "    targs = targs.contiguous().float()[:,0]\n",
    "    return torch.nn.functional.mse_loss(preds, targs)\n",
    "def clas_mse1(preds, targs):\n",
    "    preds = torch.max(preds, dim=2)[1].float()[:,1]\n",
    "    targs = targs.contiguous().float()[:,1]\n",
    "    return torch.nn.functional.mse_loss(preds, targs)\n",
    "def clas_mse2(preds, targs):\n",
    "    preds = torch.max(preds, dim=2)[1].float()[:,2]\n",
    "    targs = targs.contiguous().float()[:,2]\n",
    "    return torch.nn.functional.mse_loss(preds, targs)\n",
    "def clas_mse3(preds, targs):\n",
    "    preds = torch.max(preds, dim=2)[1].float()[:,3]\n",
    "    targs = targs.contiguous().float()[:,3]\n",
    "    return torch.nn.functional.mse_loss(preds, targs)\n",
    "def clas_mse4(preds, targs):\n",
    "    preds = torch.max(preds, dim=2)[1].float()[:,4]\n",
    "    targs = targs.contiguous().float()[:,4]\n",
    "    return torch.nn.functional.mse_loss(preds, targs)\n",
    "def clas_mse5(preds, targs):\n",
    "    preds = torch.max(preds, dim=2)[1].float()[:,5]\n",
    "    targs = targs.contiguous().float()[:,5]\n",
    "    return torch.nn.functional.mse_loss(preds, targs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression loss and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLabelMSE(nn.MSELoss):\n",
    "    def forward(self, input, target, nasp=6):\n",
    "        target = target.float()\n",
    "        loss = 0\n",
    "        for i in range(nasp):\n",
    "            loss = loss + super(MultiLabelMSE, self).forward(input[:,i], target[:,i])\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_0(preds, targs):\n",
    "    preds = preds[:,0]\n",
    "    targs = targs.contiguous().float()[:,0]\n",
    "    return torch.nn.functional.mse_loss(preds, targs)\n",
    "def mse_1(preds, targs):\n",
    "    preds = preds[:,1]\n",
    "    targs = targs.contiguous().float()[:,1]\n",
    "    return torch.nn.functional.mse_loss(preds, targs)\n",
    "def mse_2(preds, targs):\n",
    "    preds = preds[:,2]\n",
    "    targs = targs.contiguous().float()[:,2]\n",
    "    return torch.nn.functional.mse_loss(preds, targs)\n",
    "def mse_3(preds, targs):\n",
    "    preds = preds[:,3]\n",
    "    targs = targs.contiguous().float()[:,3]\n",
    "    return torch.nn.functional.mse_loss(preds, targs)\n",
    "def mse_4(preds, targs):\n",
    "    preds = preds[:,4]\n",
    "    targs = targs.contiguous().float()[:,4]\n",
    "    return torch.nn.functional.mse_loss(preds, targs)\n",
    "def mse_5(preds, targs):\n",
    "    preds = preds[:,5]\n",
    "    targs = targs.contiguous().float()[:,5]\n",
    "    return torch.nn.functional.mse_loss(preds, targs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_regr_acc(preds, targs, nasp=6, nrat=5):\n",
    "    preds = preds[:,0:nasp]\n",
    "    preds = preds.contiguous().view(-1)\n",
    "    preds = preds.round()\n",
    "    targs = targs.contiguous().view(-1).long()\n",
    "    return (preds==targs).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regr_acc0(preds, targs):\n",
    "    return (preds[:,0].round()==targs[:,0].long()).float().mean()\n",
    "def regr_acc1(preds, targs):\n",
    "    return (preds[:,1].round()==targs[:,0].long()).float().mean()\n",
    "def regr_acc2(preds, targs):\n",
    "    return (preds[:,2].round()==targs[:,0].long()).float().mean()\n",
    "def regr_acc3(preds, targs):\n",
    "    return (preds[:,3].round()==targs[:,0].long()).float().mean()\n",
    "def regr_acc4(preds, targs):\n",
    "    return (preds[:,4].round()==targs[:,0].long()).float().mean()\n",
    "def regr_acc5(preds, targs):\n",
    "    return (preds[:,5].round()==targs[:,0].long()).float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create the objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUSTOM DEFINED CLASSIFIER\n",
      "Encoder init\n",
      "base01 init\n",
      "Num Aspect: 6\n",
      "Num Rating: 5\n",
      "FREEZING\n",
      "Sequential(\n",
      "  (0): Embedding(23008, 400, padding_idx=1)\n",
      "  (1): EmbeddingDropout(\n",
      "    (emb): Embedding(23008, 400, padding_idx=1)\n",
      "  )\n",
      ")\n",
      "FREEZING\n",
      "Sequential(\n",
      "  (0): WeightDropout(\n",
      "    (module): LSTM(400, 1152, batch_first=True)\n",
      "  )\n",
      "  (1): RNNDropout()\n",
      ")\n",
      "FREEZING\n",
      "Sequential(\n",
      "  (0): WeightDropout(\n",
      "    (module): LSTM(1152, 1152, batch_first=True)\n",
      "  )\n",
      "  (1): RNNDropout()\n",
      ")\n",
      "FREEZING\n",
      "Sequential(\n",
      "  (0): WeightDropout(\n",
      "    (module): LSTM(1152, 400, batch_first=True)\n",
      "  )\n",
      "  (1): RNNDropout()\n",
      ")\n",
      "UN-FREEZING\n",
      "Sequential(\n",
      "  (0): Base01Module(\n",
      "    (layers): Sequential(\n",
      "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): Dropout(p=0.5, inplace=False)\n",
      "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): Dropout(p=0.1, inplace=False)\n",
      "      (6): Linear(in_features=50, out_features=30, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "mloss = MultiLabelCEL()\n",
    "# mloss = MultiLabelMSE()\n",
    "experiment.add_tag(\"DROP1.1\")\n",
    "cls_learn = text_classifier_learner(cls_db, AWD_LSTM, \n",
    "                                    loss_func=mloss,\n",
    "                                    drop_mult=1.1,\n",
    "                                    metrics=[multi_acc,acc_0,acc_1,acc_2,acc_3,acc_4,acc_5,\n",
    "                                            clas_mse0,clas_mse1,clas_mse2,clas_mse3,clas_mse4,clas_mse5],\n",
    "#                                     metrics=[mse_0,mse_1,mse_2,mse_3,mse_4,mse_5,\n",
    "#                                              multi_regr_acc,regr_acc0,regr_acc1,regr_acc2,regr_acc3,regr_acc4,regr_acc5],\n",
    "                                    bptt=70,\n",
    "                                    max_len=hyper_params[\"max_sequence_length\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FREEZING\n",
      "Sequential(\n",
      "  (0): Embedding(23008, 400, padding_idx=1)\n",
      "  (1): EmbeddingDropout(\n",
      "    (emb): Embedding(23008, 400, padding_idx=1)\n",
      "  )\n",
      ")\n",
      "FREEZING\n",
      "Sequential(\n",
      "  (0): WeightDropout(\n",
      "    (module): LSTM(400, 1152, batch_first=True)\n",
      "  )\n",
      "  (1): RNNDropout()\n",
      ")\n",
      "FREEZING\n",
      "Sequential(\n",
      "  (0): WeightDropout(\n",
      "    (module): LSTM(1152, 1152, batch_first=True)\n",
      "  )\n",
      "  (1): RNNDropout()\n",
      ")\n",
      "FREEZING\n",
      "Sequential(\n",
      "  (0): WeightDropout(\n",
      "    (module): LSTM(1152, 400, batch_first=True)\n",
      "  )\n",
      "  (1): RNNDropout()\n",
      ")\n",
      "UN-FREEZING\n",
      "Sequential(\n",
      "  (0): Base01Module(\n",
      "    (layers): Sequential(\n",
      "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): Dropout(p=0.5, inplace=False)\n",
      "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): Dropout(p=0.1, inplace=False)\n",
      "      (6): Linear(in_features=50, out_features=30, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "_=cls_learn.load_encoder('lm_enc_hotel.1115')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BASE 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>multi_acc</th>\n",
       "      <th>acc_0</th>\n",
       "      <th>acc_1</th>\n",
       "      <th>acc_2</th>\n",
       "      <th>acc_3</th>\n",
       "      <th>acc_4</th>\n",
       "      <th>acc_5</th>\n",
       "      <th>clas_mse0</th>\n",
       "      <th>clas_mse1</th>\n",
       "      <th>clas_mse2</th>\n",
       "      <th>clas_mse3</th>\n",
       "      <th>clas_mse4</th>\n",
       "      <th>clas_mse5</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>8.179254</td>\n",
       "      <td>7.235473</td>\n",
       "      <td>0.482002</td>\n",
       "      <td>0.558984</td>\n",
       "      <td>0.518603</td>\n",
       "      <td>0.441470</td>\n",
       "      <td>0.408802</td>\n",
       "      <td>0.475045</td>\n",
       "      <td>0.489111</td>\n",
       "      <td>0.730036</td>\n",
       "      <td>0.926497</td>\n",
       "      <td>1.301724</td>\n",
       "      <td>1.838022</td>\n",
       "      <td>1.233212</td>\n",
       "      <td>1.430127</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>7.423484</td>\n",
       "      <td>6.737833</td>\n",
       "      <td>0.503403</td>\n",
       "      <td>0.594828</td>\n",
       "      <td>0.532214</td>\n",
       "      <td>0.460073</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.492287</td>\n",
       "      <td>0.493648</td>\n",
       "      <td>0.560799</td>\n",
       "      <td>0.783122</td>\n",
       "      <td>1.140653</td>\n",
       "      <td>1.442831</td>\n",
       "      <td>1.156987</td>\n",
       "      <td>1.160617</td>\n",
       "      <td>00:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>7.155400</td>\n",
       "      <td>6.635684</td>\n",
       "      <td>0.507638</td>\n",
       "      <td>0.593466</td>\n",
       "      <td>0.526770</td>\n",
       "      <td>0.465064</td>\n",
       "      <td>0.456897</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.503630</td>\n",
       "      <td>0.567151</td>\n",
       "      <td>0.870236</td>\n",
       "      <td>1.081216</td>\n",
       "      <td>1.323956</td>\n",
       "      <td>1.019056</td>\n",
       "      <td>1.213249</td>\n",
       "      <td>00:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>7.181266</td>\n",
       "      <td>6.708761</td>\n",
       "      <td>0.495311</td>\n",
       "      <td>0.565789</td>\n",
       "      <td>0.514973</td>\n",
       "      <td>0.451452</td>\n",
       "      <td>0.445554</td>\n",
       "      <td>0.488657</td>\n",
       "      <td>0.505445</td>\n",
       "      <td>0.715971</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.195100</td>\n",
       "      <td>1.436479</td>\n",
       "      <td>1.107532</td>\n",
       "      <td>1.359800</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7.107125</td>\n",
       "      <td>6.610183</td>\n",
       "      <td>0.505823</td>\n",
       "      <td>0.594374</td>\n",
       "      <td>0.521779</td>\n",
       "      <td>0.458711</td>\n",
       "      <td>0.458711</td>\n",
       "      <td>0.495917</td>\n",
       "      <td>0.505445</td>\n",
       "      <td>0.576679</td>\n",
       "      <td>0.843920</td>\n",
       "      <td>1.057169</td>\n",
       "      <td>1.262704</td>\n",
       "      <td>0.977314</td>\n",
       "      <td>1.250454</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>7.031645</td>\n",
       "      <td>6.543806</td>\n",
       "      <td>0.505369</td>\n",
       "      <td>0.598457</td>\n",
       "      <td>0.529492</td>\n",
       "      <td>0.463702</td>\n",
       "      <td>0.447822</td>\n",
       "      <td>0.493194</td>\n",
       "      <td>0.499546</td>\n",
       "      <td>0.565789</td>\n",
       "      <td>0.769510</td>\n",
       "      <td>0.996824</td>\n",
       "      <td>1.274047</td>\n",
       "      <td>0.925136</td>\n",
       "      <td>1.087114</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>7.007349</td>\n",
       "      <td>6.526912</td>\n",
       "      <td>0.509377</td>\n",
       "      <td>0.611615</td>\n",
       "      <td>0.531760</td>\n",
       "      <td>0.458258</td>\n",
       "      <td>0.455082</td>\n",
       "      <td>0.491833</td>\n",
       "      <td>0.507713</td>\n",
       "      <td>0.555354</td>\n",
       "      <td>0.776316</td>\n",
       "      <td>1.004084</td>\n",
       "      <td>1.250454</td>\n",
       "      <td>0.960526</td>\n",
       "      <td>1.189655</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>6.951386</td>\n",
       "      <td>6.494217</td>\n",
       "      <td>0.519510</td>\n",
       "      <td>0.614791</td>\n",
       "      <td>0.540835</td>\n",
       "      <td>0.484574</td>\n",
       "      <td>0.462341</td>\n",
       "      <td>0.502722</td>\n",
       "      <td>0.511797</td>\n",
       "      <td>0.560345</td>\n",
       "      <td>0.774501</td>\n",
       "      <td>1.027677</td>\n",
       "      <td>1.276316</td>\n",
       "      <td>0.958711</td>\n",
       "      <td>1.144737</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>6.982529</td>\n",
       "      <td>6.533786</td>\n",
       "      <td>0.513687</td>\n",
       "      <td>0.608893</td>\n",
       "      <td>0.521325</td>\n",
       "      <td>0.485027</td>\n",
       "      <td>0.457350</td>\n",
       "      <td>0.501361</td>\n",
       "      <td>0.508167</td>\n",
       "      <td>0.571234</td>\n",
       "      <td>0.788566</td>\n",
       "      <td>0.990472</td>\n",
       "      <td>1.259982</td>\n",
       "      <td>0.973230</td>\n",
       "      <td>1.169691</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>6.951486</td>\n",
       "      <td>6.437544</td>\n",
       "      <td>0.519661</td>\n",
       "      <td>0.616152</td>\n",
       "      <td>0.536751</td>\n",
       "      <td>0.480944</td>\n",
       "      <td>0.459165</td>\n",
       "      <td>0.507713</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.545372</td>\n",
       "      <td>0.772686</td>\n",
       "      <td>0.995463</td>\n",
       "      <td>1.205989</td>\n",
       "      <td>0.941016</td>\n",
       "      <td>1.140200</td>\n",
       "      <td>00:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>6.866036</td>\n",
       "      <td>6.460359</td>\n",
       "      <td>0.516410</td>\n",
       "      <td>0.615245</td>\n",
       "      <td>0.532214</td>\n",
       "      <td>0.484574</td>\n",
       "      <td>0.452359</td>\n",
       "      <td>0.497731</td>\n",
       "      <td>0.516334</td>\n",
       "      <td>0.545372</td>\n",
       "      <td>0.810345</td>\n",
       "      <td>0.996824</td>\n",
       "      <td>1.269056</td>\n",
       "      <td>0.967786</td>\n",
       "      <td>1.148367</td>\n",
       "      <td>00:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>6.867347</td>\n",
       "      <td>6.490115</td>\n",
       "      <td>0.514595</td>\n",
       "      <td>0.607532</td>\n",
       "      <td>0.525862</td>\n",
       "      <td>0.486842</td>\n",
       "      <td>0.454174</td>\n",
       "      <td>0.502269</td>\n",
       "      <td>0.510889</td>\n",
       "      <td>0.568058</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>1.001361</td>\n",
       "      <td>1.269056</td>\n",
       "      <td>0.969147</td>\n",
       "      <td>1.175590</td>\n",
       "      <td>00:44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with experiment.train():\n",
    "    cls_learn.fit_one_cycle(hyper_params[\"num_epochs1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'web': 'https://www.comet.ml/api/image/download?imageId=3d43646ed7494432a9bef1d4d9c6c2be&experimentKey=bb9a17fbe6c0409bae28f9e5da2f6d6e',\n",
       " 'api': 'https://www.comet.ml/api/rest/v1/image/get-image?imageId=3d43646ed7494432a9bef1d4d9c6c2be&experimentKey=bb9a17fbe6c0409bae28f9e5da2f6d6e',\n",
       " 'imageId': '3d43646ed7494432a9bef1d4d9c6c2be'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = cls_learn.recorder.plot_losses()\n",
    "experiment.log_figure(figure_name=\"train loss 01\", figure=fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_learn.save('hotel.clas.base01.1.learner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNLearner(data=TextClasDataBunch;\n",
       "\n",
       "Train: LabelList (8969 items)\n",
       "x: TextList\n",
       "xxbos we had the most wonderful time at the excellence xxperiod we opted for the excellence club and it was well worht it for the perks xxperiod roberto puello who was the club manager did an extra special job of making us feel welcomed xxperiod we took some great pictures that looked like postcards xxperiod the food was excellent the pizza was close to being our favorite xxperiod the shows were great especially the michael jackson and the 70 's 80 's night xxperiod the french resturant was probably our favorite xxperiod we will definately be back for an anniversary trip xxperiod we made some friends but had plenty of xxunk as well xxperiod the rooms were great and everytime we left and came back it was cleaned , towels restocked and the bar was as well xxperiod,xxbos too sick to enjoy the ride to and form the airport is not good xxperiod very bumpy road and you can really see the poor living conditions xxperiod when you get to the resort it is like another world xxperiod we were told not to drink the tap or shower water - keep your mouth shut in the shower etc xxperiod but we have since heard that not all properties in punta cana have a water problem xxperiod in some resorts they have a huge purification system and the tap water is safe xxperiod both my husband and i were sick with diarrhea while we were there and put it down to the unclean water used to prepare food xxperiod we will not go on any more holidays where we have to worry about our health xxperiod each night at about 10 pm when we were settling down to sleep the music started up and we like fresh air but we had to close our patio doors to mute the sound xxperiod we really wanted a quieter resort xxperiod it was disappointing xxperiod it was partially our fault for not doing our research properly xxperiod some people did not hear the bands play at night but we could nt change our swim up room for a quieter one xxperiod we will not be returning to dominican republic xxperiod,xxbos relaxing and fun , but xxperiod i rang in the new year at excellence punta cana xxperiod since new york was freezing at the time , i was just happy to be in the sun xxperiod my husband and i had a great time overall xxperiod however , i was a little surprised to see this hotel rating itself as a 5- star facility ( more like a 4 ) xxperiod all of the basics were covered , but some of the details that i would expect from a 5- star place were missing xxperiod the bed , although comfortable creaked loudly and i couldn ? ? tell whether or not the headboard was attached properly xxperiod the staff were friendly and helpful overall , but in keeping up with the island mentality , their sense of urgency was lacking ( we had to ask two different people for hand towels and our one small room service order took close to an hour to arrive ) xxperiod actually , as mentioned by another reviewer , the food was the worst part xxperiod the presentation was excellent ( clean buffet areas , nicely decorated theme restaurants ) , but the dinner food quality wasn ? ? the best xxperiod one night i didn ? ? even finish my meal ( at the ? ? xxunk ? xxperiod on - site ) xxperiod lunch ( indoor buffet or beach bbq ) was usually the best bet xxperiod actually , everything on the beach ? ? xxunk the wait xxunk great xxperiod considering all of this , the excellence was a great setting for relaxation xxperiod the grounds were beautiful , the weather was pleasant and there were many options for activities ( and spa treatments ) if you wanted them xxperiod i would definitely go back xxperiod one note - coordinate travel to and from the hotel beforehand if you can xxperiod the hotel is over an hour away from the airport , so you 'll want to skip the can i help you , sir xxperiod bidding wars between different transportation companies xxperiod one more note - the resort is on the atlantic side of the ocean xxperiod that means rough seas and cold ( er ) water xxperiod if you intend to spend your entire vacation in the ocean , you may want to skip this place xxperiod i went in a few times , but i quickly became content just relaxing by the water when i couldn ? ? go in it xxperiod,xxbos somewhat excellence we just returned from a one week stay at excellence punta cana from xxunk to xxunk xxperiod we are seasoned travelers and have stayed at a dozen all inclusives xxperiod we stayed at excellence punta cana in 2007 for two weeks , then excellence mayan riviera and then playa mujeres and now just returned from our second time to punta cana xxperiod we love excellence xxperiod so here goes the staff at excellence i rate 5 star all the way they are an amazing group of people friendly hard working and makes your stay wonderful xxperiod pool beach and grounds a solid five star ca not say more then wow xxperiod now for the rooms we traveled as three couples all oceanview excellence club seen all three rooms and they are all in need of work the rooms are showing there age all over the place a 4 rating is generous xxperiod food a 3 rating very incosistent cold most of the time under cooked over cooked , the new ala carte menus has less selection and was not impressed at all xxperiod deffinately a great decline since our last trip two years ago xxperiod excellence club we did it in 2007 and that is why we all choose to do it again i rate it a three the only thing good was the view and the ability for late check out as we had a late flight home xxperiod but for its service i rate it a 3 xxperiod excellence club was closed upon our late arrival so they gave us our keys and sent us on our way in pitch darkness we knew where we where going so we led the other two couples we traveled with too their rooms xxperiod their service was very inconsistent beach towels in all of our three club rooms only once xxperiod went to excellence club three times for a channel changer in the end tipped staff and they got one from an unoccupied room xxperiod turn down hit and miss had to ask for bathroom amenities , would not exchange any liquor bottles in room which they did the first time we where there xxperiod the club lounge it self which used to have plenty of food to choose from literally had nothing during the day and evening cheese some fruit and bread not at all like it was excellence club has xxunk there service big time xxperiod the staff tended better to you then excellence club staff xxperiod we requested top floor for all three rooms and after all our returns we thought that was not an unreasonable request and we did not get one top floor room xxperiod save your money and shame on you excellence club for your lack of service xxperiod all three rooms had very xxunk fridge stalking and was only resolved with a tip and even then once when givin a tip was not done xxperiod i will not be returning to excellence punta cana and it is sliding down the charts for a reason xxperiod in saying all this we traveled with two other couples and we all had a fabulous time we just feel we did not get what we xxunk for xxperiod anyone with questions please do not hesitate to contact me xxperiod,xxbos beautiful resort but be careful of a few things xxperiod my husband and i just got back from a one - week trip to this resort xxperiod our vacation did not start well xxperiod this hotel overbooks the nicest rooms xxperiod when we arrived they immediately downgraded us b / c they did not have the room we booked available xxperiod there was also an issue of miscommunication b / w our travel agent and the hotel and the hotel staff was totally unhelpful in resolving the issue xxperiod we had to do all of the xxunk ourselves xxperiod at one point the concierge told us they could not phone our travel agency b / c that phone call would cost $ xxperiod that 's customer service xxperiod once all was resolved and we were in our proper room , the trip was wonderful xxperiod the property is gorgeous and well maintained xxperiod there are lots of restaurants to choose from and the food was as good or better than anything we ' ve had in the carribean xxperiod apart from the front desk staff , all of the other employees are very friendly and helpful xxperiod booking the excellence club is worth it - just make sure the documents you get back from your travel agency clearly state that your booking includes the club xxperiod\n",
       "y: MultiCategoryList\n",
       ",0;2;3;5,,2,\n",
       "Path: data;\n",
       "\n",
       "Valid: LabelList (2204 items)\n",
       "x: TextList\n",
       "xxbos a truly fantastic place xmas we have just returned from a 2 week xmas new year break at the excellence punta cana xxperiod the hotel is magnificent and we have never experienced such incredible service before xxperiod the restaurants are great , with plenty of choice xxperiod the whole complex is so good that we only did one trip and that was for my wife to swim with the dolphins xxperiod great beaches and pools xxperiod the staff fall over each other to look after you xxperiod we stayed in a junior suite on ground level and it was spotlessly clean , great maid service and room service on tap 24 / 7 xxperiod overall i would say this is probably the best hotel we have ever stayed in on xxunk i am extremely fussy xxperiod the journey to the resort is a little uncomfortable , with the roads in a bad state xxperiod but once you are checked in the pace of life xxunk down and you forget about the outside world xxperiod worthy of special mention and our sincere thanks are : pedro from the cielo bar / pool an absolute gentleman xxperiod miguel the bell boy and also carlos from the xxunk bar xxperiod we will definately be booking again , probably for next christmas xxperiod jim eileen ( xxunk uk ) xxperiod,xxbos my husband and i stayed here for six days on our honeymoon xxperiod it was the most incredible resort xxperiod the rooms were comfortable and lovely , and the service was impeccable xxperiod we were so impressed we are looking into the other excellence resorts for our next vacation xxperiod we loved that it was all - inclusive xxperiod get hungry at 3 am xxperiod no problem , just call room service xxperiod the restaurants were impressive , and the bars were really nice xxperiod everything about the resort was visually appealing , clean , and luxurious xxperiod there were all sorts of things to do , also xxperiod we went horseback riding , spent a day in the spa ( amazing xxperiod ) , saw a circus and a magic show , and walked through the botanical garden , all within the resort xxperiod most other places ( marinarium , bavaro tours ) will pick you up right in front of the lobby if you want to do activities outside the resort xxperiod i definitely would not rent a car , though , unless you are comfortable driving amongst maniacs xxperiod seriously , though , if you are looking for a place to get away from everything , excellence at punta cana is the perfect choice xxperiod our honeymoon could not have been better xxperiod,xxbos best hotel in the dominican it was our 4th time to the domincan , this hotel was by far a superior class xxperiod resort : a very private resort where noise is kept to a minimum as it is chidren free and geared towards adults xxperiod plently of places to relax so it is not over - crowded xxperiod there were lots of different seating ranging from loungers to four poster beds both on the beach and around the pool , with plently of towels xxperiod the reception is large and spacious and very comfortable xxperiod the reception staff are very helpful , especially charismatic edwin xxperiod the unique design of the resort means that you do not get wet walking from the rooms to the restaurants during the tropical showers xxperiod rooms : there was a 4 poster bed , luxury furnishings and it was very comfortable xxperiod well maintained and clean xxperiod it was a spacious room with good seperate shower xxperiod dvd players in the room xxperiod the tv channels are limited and very geared towards the us market , no english footie or news xxperiod facilities : there is waiter service wherever you lay your hat xxperiod they will take drinks orders as well as deliver pizza on the beach xxperiod there are 8 restaurants for the evening dinners to satisfy most taste buds xxperiod if you have any special food requirements e xxperiod vegetarian , see ramon , manager of barcelona restaurant , he will make anything for you xxperiod ( thank you ramon , you made our holiday ) xxperiod the head chef , mr dettweitler is world xxunk and ensures that all of the food is of the highest quality , they are very lucky to have him there xxperiod the breakfast and lunch buffets are fantastic offering a large choice of food xxperiod felix the manager of the toscana is very polite and helpful xxperiod the gym is the most modern we have ever seen in a hotel with state of the art equipment and it is well maintained xxperiod general : they create a very comfortable atmosphere and nobody violates your space in any way , but they are always there if you need them xxperiod it is a very easy place to settle in to xxperiod go for it , you will not be disappointed xxperiod mr and mrs xxunk xxperiod,xxbos our trip our trip to the dominican republic was okay xxperiod we stayed at the excellence resort xxperiod it would have been excellent if we did not have so many problems getting the service that we paid for xxperiod when we called to get something fixed like the leaking ceiling or the toliet that stopped working , it took forever xxperiod numerous times there was not any towels for the next day or the mini bar was not restocked with the things that we liked xxperiod the thing that saved the trip was the entertainment staff xxperiod they were always smiling and asking if you were having a good time xxperiod they got you involved in the activities that were going on like dancing and spanish lessons xxperiod also , they had really good shows that were funny and entertaining xxperiod juan carlos , cesar and all the girls there were excellent xxperiod i think that it is very beautiful and relaxing there but i would definately let my friends know about the advantages and disadvantages of my trip and let them decide of they would want to go xxperiod,xxbos not the same the second time my wife and i just returned from excellence where we stayed from 11 / 21 - 11 / 26 xxperiod this was our second time staying at excellence and was far less enjoyable than our first visit in july 2007 xxperiod here are some of the issues we noticed this time : * the pool chair / towel insanity xxperiod as previous reviewers have mentioned , most pool chairs are reserved with towels and personal belongings by 9:00 am and all towels are gone from the towel shelves by this time as well xxperiod so if you have a massage in the morning or go horse back riding at 10 am or simply want to sleep in you literally will have no place to sit at the pool and no way to get a pool towel xxperiod there seems to be no recognition from the staff that this is a problem xxperiod * the food xxperiod while i appreciate the resort 's variety of food options , including asian , french , mexican , pizza , hamburgers / sandwiches , and italian , the result is that none of the food is particularly good xxperiod the best food is the simplest , like breakfast buffet items and food from the grill like hamburgers xxperiod asking chefs in a tropical resort to be experts in japanese or french food is going to lead to disappointment for most people xxperiod some of the food was okay , but we left dinner most night unsatisfied and sometimes still hungry xxperiod xxunk the problem is that the menus are written by workers with a limited command of english , describing food that they probably do not have a good idea about xxperiod as a result you sometimes literally have no idea what you are ordering xxperiod like others have mentioned , both my wife and i got sick during our time at excellence xxperiod since we never left the resort , we can only assume that some food or drink at the resort was the problem xxperiod we have traveled to various places in the caribbean and to xxunk in africa and have never gotten sick like we did at excellence xxperiod while we enjoyed aspects of our trip , we were disappointed that we would have to deal with these issues at a 5 star resort xxperiod\n",
       "y: MultiCategoryList\n",
       ",,,1;2;4;5,0;1\n",
       "Path: data;\n",
       "\n",
       "Test: LabelList (3739 items)\n",
       "x: TextList\n",
       "xxbos definitely not a 5 star resort i ' m dumbfounded that this hotel gets good reviews and is so highly rated xxperiod it 's decidedly a 3 star property , not 5 stars as indicated xxperiod the rooms are very dated and run down , old crappy beds and pillows , an old tv and overall poorly maintained xxperiod the whole property is pretty run down and old - looking xxperiod the food is subpar , not one meal i had would be called great xxperiod the service is uneven and the staff is poorly trained and uninformed xxperiod many do not comprehend english xxperiod the beach is great , it 's the only redeeming factor xxperiod however the resort is a 1- hour taxi trip from the airport xxperiod,xxbos facilities need work xxperiod we visited excellence for 5 nights in december xxperiod our first room , # xxunk , had a safe that did not work and so - so air conditioning xxperiod when we went to the front desk to complain , we were told to go to the room and someone would be there within 15 minutes xxperiod 45 minutes later , the safe guy showed up , but nobody for the a / c xxperiod the safe guy could not fix it xxperiod when he left , the electricity went out xxperiod it went out a second time before we finally went to the front desk to change rooms xxperiod we had dinner that night in the lobster house xxperiod do not waste your time on this one xxperiod the lobster tails had about 2 bites of food included xxperiod while we were in there , the electricity went out again xxperiod room xxunk served us pretty well , until night # 3 when my partner got up to go to the bathroom and stepped into an inch of water xxperiod a hose had broken on the back of the toilet and flooded our room xxperiod it would ' ve been ok , but when we went to the front desk we were told that we needed to wait until noon to see if perhaps they could move us to another room xxperiod the front desk clerks were not xxunk to just move us xxperiod my partner was infuriated that they wanted us to wait 4 hours for a new room xxperiod finally , matias at the front desk finally arranged to have us moved to another upgraded room - xxunk xxperiod we walked in and saw the leak coming from the ceiling and nearly flipped xxperiod we finally got into # xxunk , which was a gorgeous suite with a beautiful view xxperiod on the positive side , the food at the other restaurants was very good xxperiod i particularly liked the french restaurant , while my partner liked the asian restaurant xxperiod the breakfast buffet was like nothing i 'd ever seen before - lots of choices xxperiod the ocean was way too rough to enjoy , particularly if you 're not a strong swimmer xxperiod much of the beach was black flagged the entire time we were there , so if you 're a big ocean fan , i do not recommend this resort xxperiod my favorite part , by far , though , were the beds next to the pools and ocean xxperiod they were amazing xxperiod i guess you could particularly say so since the beds in the rooms were hard as rocks xxperiod all in all , a good trip - highly recommend the zip line tour xxperiod it was worth every penny xxperiod,xxbos excellence was exactly that xxperiod my family and i stayed at the excellence punta cana from december 22 to december 29 of this year xxperiod it was an amazing time had by all that attended xxperiod we arrived at the resort around 4 am because of a delay at the airport in vancouver , but even at 4 am , the service of the bellhops and the front desk was up to par xxperiod our bags were unloaded and immediately tagged and set to one side of the lobby while we were handed cold scented towels to cool off with xxperiod check in was fairly expedient and we were in our rooms within twenty minutes xxperiod i had never been to an all inclusive resort before , and wasted no time enjoying the pleasures of the mini bar in the room , as well as the ample storage space for our things xxperiod room service even at 4 am was great , the girl on the phone said it would be about 40 minutes for the food , which seemed a little long , but i think they only say that to cover there butts , because it took about 25 minutes at most xxperiod the activities during the day were well thought out , though , there was some delays and cancellations due to weather conditions ( beach volleyball cancelled to due strong winds xxperiod the entertainment staff was amazing and extremely friendly , a special thanks to all my friends , ines ( my fiance , ) altagracia ( who lovingly xxunk to me as xxunk loco , which translates into crazy skinny guy , ) xxunk and johanna ( my disco dance partners , ) sexy cesar ( who taught me all the sexy dance moves i xxperiod now know , ) julio cesar ( the mc for the games and parties xxperiod the restaurants i ca not offer too much help with , i did not eat at all of them , but of the few i did eat at , i recommend toscana for the huge buffet everyday , breakfast here is well prepared and quite delicious ( although i do not recommend the scrambled eggs xxperiod the omlettes are delicious and you have to try one xxperiod for lunch , you have to check out the grill on the beach , different food everyday , always good , and makes the beach smell amazing xxperiod for dinner , i liked spice ( asian cuisine , ) agave ( mexican , but do not eat the xxunk from here , very rubbery , ) the pizza that is delivered to the pool and the beach is awesome , make sure you try that xxperiod the bars were awesome , you get accustomed to speaking the language when ordering drinks , instead of drinking your usual bacardi and coke , try the brugal extra anejo , they call it the dominican xxunk , and it 's obvious why once you try it xxperiod the stuff tastes amazing and it does magic for someone trying to loosen up on the dance floor xxperiod the disco is great too , although sometimes a little empty , but still worth checking out xxperiod the worst part of my trip was the vendors , they do not let up , and i am a very well mannered person , which makes it hard to shut them down over and over again , make sure you do not tell them you like anything until you know you 're going to buy it , otherwise you 'll have to beat xxperiod them off with a stick to get away xxperiod try to make it to the theatre for the shows at 10 pm every night , they are worth it xxperiod the ice breaker shows are fun too , it gets people into the swing of things xxperiod all in all , i would highly recommend this resort for anyone going on a honeymoon or a romantic time with the better half , there is not a very big single crowd , so parents beware taking your single sons and daughters to this resort if they 're looking to party with other singles xxperiod hope this helps you xxperiod adios amigos and xxunk xxperiod,xxbos great service , nice hotel , mediocre food xxperiod my husband and i stayed at excellence for five nights mid - november xxperiod we booked our trip at the very last minute so we were not able to do a ton of research on the dominican but the hotel receives high ratings xxunk the web xxperiod after the one hour ride from the airport we arrived at the hotel and were greeted by everyone we met xxperiod i have to say that the staff at the hotel were very nice and made every effort to learn our names and greet us by name each time they saw us xxperiod we opted to upgrade to the excellence club and we are still trying to decide if we think it was worth it or not xxperiod as part of the excellence club , you are ushered to the club 's private lobby for check - in but , really , it almost just creates an xxunk step in the check - in process and adds another person or two you feel like you should tip xxperiod the biggest benefits of the excellence club for us were the unlimited internet access , beach towels in the room ( they were hard to get otherwise ) , and the beach bag in our room xxperiod we did eat breakfast each morning in the excellence club which was nice because it was a small buffet and you did not have to deal with a crowd xxperiod the hotel itself was clean , the staff was very friendly , and nothing ever felt crowded xxperiod however , the food was not great xxperiod it was not bad - but it was not great xxperiod i ' m not a big eater but i was prepared to indulge on my vacation and there just was not anything i was crazy about xxperiod the presentation of the food was nice but it was just bland xxperiod i think that is the best way to describe it xxperiod the pizzas that were delivered to the pool area were good but it was unpredictable because you never knew when they would arrive xxperiod we went on two excursions - swimming with the sting - rays / sharks and the zip - line tour xxperiod we loved the zip - line excursion xxperiod the staff was great and our bus driver and tour guide were great xxperiod it was interesting to visit the sting - rays and swim with the sharks but the reef where we snorkeled was disappointing xxperiod the fish were very small and there was not much to see xxperiod the electricity went out in our room a handful of times , especially when i used the hairdryer xxperiod also , our ac was terrible xxperiod they tried to repair it but it just never got cool xxperiod our room was big , though , and clean xxperiod we always got housekeeping service twice a day and they refilled our mini - bar daily xxperiod in many of the reviews , people said they got sick xxperiod our representative at the hotel ( through aaa ) warned us that many people think they get sick from the water or the food but they do not realize that having too many drinks with coconut in them will also do it xxperiod coconut is a natural laxative so you need to limit your consumption xxperiod i would still pack the immodium just to be sure xxperiod i could not decide if i wanted to give this hotel a 3 / 5 or a 4 / 5 but i decided to go up because of the friendly staff and the cleanliness of our room xxperiod i do not think i would go back because of the food but we had a nice time while we were there xxperiod we met a lot of great people at the swim up bar xxperiod,xxbos very relaxing experience just returned from my 40th birthday romantic getaway with my husband xxperiod this was our first time in the dominican republic , and we have literally been to every single island in the caribbean xxperiod so i can assure you that my review will be short , sweet , and comprehensive xxperiod in general , we liked the dr , and the excellence was very nice xxperiod the top reasons why we liked excellence were : 1 ) no kids ( ie xxperiod , if i want to get away from my own kids , i definitely do not want to vacation with other peoples ' kids ) xxperiod it was so quiet xxperiod 2 ) the staff and the people in the dr in general xxperiod so genuinely friendly , helpful , and wonderful xxperiod believe me , this is not true in most other areas of the caribbean xxperiod the all - inclusive feature xxperiod loved being served , served , served xxperiod i wanted to sit on my [ - - ] all day and just be a xxunk pig xxperiod and this is the perfect place to do it xxperiod 4 ) the best selection of beach and pool lounge chairs , beds , and hammocks i ' ve ever seen xxperiod there were palapas everywhere , so there was no shortage of shade xxperiod there were so many beds , you did not have to worry about not getting one xxperiod i 'd never had the chance to sleep on a beach bed , because usually hotels have only a few , so you end up looking xxunk at the lucky few who get them xxperiod ok , so here 's what i did not love about excellence :1 ) beach is not swimmable xxperiod way too rough most of the time xxperiod for this reason alone , i 'd not return here xxperiod i ' m a beach fan , and love to swim in the warm caribbean sea xxperiod i ' m no food snob , but some of the food was downright bad xxperiod and you end up eating in the same spot for breakfast and lunch xxperiod even though they have like 7 restaurants - the majority of them are only open for dinner xxperiod we only stayed 4 nights , and we were definitely getting very tired of the breakfast / lunch selection by the 3rd day xxperiod overall , if you just want to relax by the pool and you do not care about not going in the beach , this is a very beautiful resort xxperiod the staff is wonderful xxperiod if you are looking for a place to party and be loud and crazy , this is not your place xxperiod\n",
       "y: EmptyLabelList\n",
       ",,,,\n",
       "Path: data, model=SequentialRNN(\n",
       "  (0): SentenceEncoder(\n",
       "    (module): AWD_LSTM(\n",
       "      (encoder): Embedding(23008, 400, padding_idx=1)\n",
       "      (encoder_dp): EmbeddingDropout(\n",
       "        (emb): Embedding(23008, 400, padding_idx=1)\n",
       "      )\n",
       "      (rnns): ModuleList(\n",
       "        (0): WeightDropout(\n",
       "          (module): LSTM(400, 1152, batch_first=True)\n",
       "        )\n",
       "        (1): WeightDropout(\n",
       "          (module): LSTM(1152, 1152, batch_first=True)\n",
       "        )\n",
       "        (2): WeightDropout(\n",
       "          (module): LSTM(1152, 400, batch_first=True)\n",
       "        )\n",
       "      )\n",
       "      (input_dp): RNNDropout()\n",
       "      (hidden_dps): ModuleList(\n",
       "        (0): RNNDropout()\n",
       "        (1): RNNDropout()\n",
       "        (2): RNNDropout()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): Base01Module(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.5, inplace=False)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=50, out_features=30, bias=True)\n",
       "    )\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=MultiLabelCEL(), metrics=[<function multi_acc at 0x7fcfd552f170>, <function acc_0 at 0x7fd04af72320>, <function acc_1 at 0x7fcfd552f4d0>, <function acc_2 at 0x7fcfd552f5f0>, <function acc_3 at 0x7fcfd552f710>, <function acc_4 at 0x7fcfd552f830>, <function acc_5 at 0x7fcfd552f950>, <function clas_mse0 at 0x7fcfd552f050>, <function clas_mse1 at 0x7fcfd552f9e0>, <function clas_mse2 at 0x7fcfd552fc20>, <function clas_mse3 at 0x7fcfd552fd40>, <function clas_mse4 at 0x7fcfd552fe60>, <function clas_mse5 at 0x7fcfd552ff80>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('data'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
       "learn: ...\n",
       "alpha: 2.0\n",
       "beta: 1.0], layer_groups=[Sequential(\n",
       "  (0): Embedding(23008, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(23008, 400, padding_idx=1)\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): Base01Module(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.5, inplace=False)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=50, out_features=30, bias=True)\n",
       "    )\n",
       "  )\n",
       ")], add_time=True, silent=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_learn.load('hotel.clas.base01.1.learner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UN-FREEZING\n",
      "Sequential(\n",
      "  (0): Embedding(23008, 400, padding_idx=1)\n",
      "  (1): EmbeddingDropout(\n",
      "    (emb): Embedding(23008, 400, padding_idx=1)\n",
      "  )\n",
      ")\n",
      "UN-FREEZING\n",
      "Sequential(\n",
      "  (0): WeightDropout(\n",
      "    (module): LSTM(400, 1152, batch_first=True)\n",
      "  )\n",
      "  (1): RNNDropout()\n",
      ")\n",
      "UN-FREEZING\n",
      "Sequential(\n",
      "  (0): WeightDropout(\n",
      "    (module): LSTM(1152, 1152, batch_first=True)\n",
      "  )\n",
      "  (1): RNNDropout()\n",
      ")\n",
      "UN-FREEZING\n",
      "Sequential(\n",
      "  (0): WeightDropout(\n",
      "    (module): LSTM(1152, 400, batch_first=True)\n",
      "  )\n",
      "  (1): RNNDropout()\n",
      ")\n",
      "UN-FREEZING\n",
      "Sequential(\n",
      "  (0): Base01Module(\n",
      "    (layers): Sequential(\n",
      "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): Dropout(p=0.5, inplace=False)\n",
      "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): Dropout(p=0.1, inplace=False)\n",
      "      (6): Linear(in_features=50, out_features=30, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cls_learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>multi_acc</th>\n",
       "      <th>acc_0</th>\n",
       "      <th>acc_1</th>\n",
       "      <th>acc_2</th>\n",
       "      <th>acc_3</th>\n",
       "      <th>acc_4</th>\n",
       "      <th>acc_5</th>\n",
       "      <th>clas_mse0</th>\n",
       "      <th>clas_mse1</th>\n",
       "      <th>clas_mse2</th>\n",
       "      <th>clas_mse3</th>\n",
       "      <th>clas_mse4</th>\n",
       "      <th>clas_mse5</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6.939958</td>\n",
       "      <td>6.427804</td>\n",
       "      <td>0.519661</td>\n",
       "      <td>0.617514</td>\n",
       "      <td>0.535390</td>\n",
       "      <td>0.485935</td>\n",
       "      <td>0.454628</td>\n",
       "      <td>0.508167</td>\n",
       "      <td>0.516334</td>\n",
       "      <td>0.542650</td>\n",
       "      <td>0.794918</td>\n",
       "      <td>0.975953</td>\n",
       "      <td>1.228675</td>\n",
       "      <td>0.937387</td>\n",
       "      <td>1.151543</td>\n",
       "      <td>01:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6.914752</td>\n",
       "      <td>6.493486</td>\n",
       "      <td>0.517544</td>\n",
       "      <td>0.613430</td>\n",
       "      <td>0.531307</td>\n",
       "      <td>0.488203</td>\n",
       "      <td>0.451452</td>\n",
       "      <td>0.509528</td>\n",
       "      <td>0.511343</td>\n",
       "      <td>0.577132</td>\n",
       "      <td>0.817151</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.352541</td>\n",
       "      <td>0.966425</td>\n",
       "      <td>1.211434</td>\n",
       "      <td>01:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>6.875609</td>\n",
       "      <td>6.341587</td>\n",
       "      <td>0.526543</td>\n",
       "      <td>0.626134</td>\n",
       "      <td>0.543557</td>\n",
       "      <td>0.492287</td>\n",
       "      <td>0.466878</td>\n",
       "      <td>0.511797</td>\n",
       "      <td>0.518603</td>\n",
       "      <td>0.504537</td>\n",
       "      <td>0.729583</td>\n",
       "      <td>0.934664</td>\n",
       "      <td>1.197368</td>\n",
       "      <td>0.908802</td>\n",
       "      <td>1.131125</td>\n",
       "      <td>01:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6.849904</td>\n",
       "      <td>6.375635</td>\n",
       "      <td>0.524955</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.542196</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>0.466878</td>\n",
       "      <td>0.509074</td>\n",
       "      <td>0.528131</td>\n",
       "      <td>0.539020</td>\n",
       "      <td>0.852995</td>\n",
       "      <td>1.059891</td>\n",
       "      <td>1.194192</td>\n",
       "      <td>0.966878</td>\n",
       "      <td>1.113884</td>\n",
       "      <td>01:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>6.652443</td>\n",
       "      <td>6.295371</td>\n",
       "      <td>0.531307</td>\n",
       "      <td>0.633848</td>\n",
       "      <td>0.553539</td>\n",
       "      <td>0.498185</td>\n",
       "      <td>0.465064</td>\n",
       "      <td>0.511797</td>\n",
       "      <td>0.525408</td>\n",
       "      <td>0.495917</td>\n",
       "      <td>0.706443</td>\n",
       "      <td>0.925136</td>\n",
       "      <td>1.305354</td>\n",
       "      <td>0.943285</td>\n",
       "      <td>1.041742</td>\n",
       "      <td>01:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6.752784</td>\n",
       "      <td>6.369627</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.632486</td>\n",
       "      <td>0.544011</td>\n",
       "      <td>0.513158</td>\n",
       "      <td>0.453267</td>\n",
       "      <td>0.509528</td>\n",
       "      <td>0.505445</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.779492</td>\n",
       "      <td>0.926497</td>\n",
       "      <td>1.350726</td>\n",
       "      <td>0.918784</td>\n",
       "      <td>1.182849</td>\n",
       "      <td>01:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>6.570333</td>\n",
       "      <td>6.239287</td>\n",
       "      <td>0.539322</td>\n",
       "      <td>0.652904</td>\n",
       "      <td>0.563975</td>\n",
       "      <td>0.510436</td>\n",
       "      <td>0.470054</td>\n",
       "      <td>0.512704</td>\n",
       "      <td>0.525862</td>\n",
       "      <td>0.457350</td>\n",
       "      <td>0.675590</td>\n",
       "      <td>0.968240</td>\n",
       "      <td>1.207350</td>\n",
       "      <td>0.973230</td>\n",
       "      <td>1.100272</td>\n",
       "      <td>01:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>6.486907</td>\n",
       "      <td>6.259525</td>\n",
       "      <td>0.527979</td>\n",
       "      <td>0.628857</td>\n",
       "      <td>0.539927</td>\n",
       "      <td>0.501361</td>\n",
       "      <td>0.460980</td>\n",
       "      <td>0.520871</td>\n",
       "      <td>0.515880</td>\n",
       "      <td>0.502269</td>\n",
       "      <td>0.736388</td>\n",
       "      <td>0.838022</td>\n",
       "      <td>1.233666</td>\n",
       "      <td>0.846642</td>\n",
       "      <td>1.086661</td>\n",
       "      <td>01:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>6.489611</td>\n",
       "      <td>6.199972</td>\n",
       "      <td>0.540986</td>\n",
       "      <td>0.650635</td>\n",
       "      <td>0.561706</td>\n",
       "      <td>0.511343</td>\n",
       "      <td>0.470508</td>\n",
       "      <td>0.522686</td>\n",
       "      <td>0.529038</td>\n",
       "      <td>0.460073</td>\n",
       "      <td>0.672414</td>\n",
       "      <td>0.855717</td>\n",
       "      <td>1.193739</td>\n",
       "      <td>0.837568</td>\n",
       "      <td>1.022686</td>\n",
       "      <td>01:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>6.203860</td>\n",
       "      <td>6.153333</td>\n",
       "      <td>0.544087</td>\n",
       "      <td>0.651089</td>\n",
       "      <td>0.558530</td>\n",
       "      <td>0.524501</td>\n",
       "      <td>0.468693</td>\n",
       "      <td>0.538113</td>\n",
       "      <td>0.523593</td>\n",
       "      <td>0.450998</td>\n",
       "      <td>0.651996</td>\n",
       "      <td>0.805354</td>\n",
       "      <td>1.177858</td>\n",
       "      <td>0.807622</td>\n",
       "      <td>1.017695</td>\n",
       "      <td>01:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>6.304345</td>\n",
       "      <td>6.108984</td>\n",
       "      <td>0.547943</td>\n",
       "      <td>0.658802</td>\n",
       "      <td>0.567604</td>\n",
       "      <td>0.520871</td>\n",
       "      <td>0.465971</td>\n",
       "      <td>0.537205</td>\n",
       "      <td>0.537205</td>\n",
       "      <td>0.446915</td>\n",
       "      <td>0.661524</td>\n",
       "      <td>0.798548</td>\n",
       "      <td>1.153811</td>\n",
       "      <td>0.810799</td>\n",
       "      <td>1.019056</td>\n",
       "      <td>01:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>6.317392</td>\n",
       "      <td>6.053030</td>\n",
       "      <td>0.550892</td>\n",
       "      <td>0.661071</td>\n",
       "      <td>0.564882</td>\n",
       "      <td>0.525862</td>\n",
       "      <td>0.477768</td>\n",
       "      <td>0.542196</td>\n",
       "      <td>0.533575</td>\n",
       "      <td>0.433303</td>\n",
       "      <td>0.647913</td>\n",
       "      <td>0.809437</td>\n",
       "      <td>1.112523</td>\n",
       "      <td>0.783575</td>\n",
       "      <td>0.935572</td>\n",
       "      <td>01:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>6.251703</td>\n",
       "      <td>6.196865</td>\n",
       "      <td>0.548170</td>\n",
       "      <td>0.652450</td>\n",
       "      <td>0.566243</td>\n",
       "      <td>0.524047</td>\n",
       "      <td>0.463702</td>\n",
       "      <td>0.539020</td>\n",
       "      <td>0.543557</td>\n",
       "      <td>0.474592</td>\n",
       "      <td>0.670145</td>\n",
       "      <td>0.827132</td>\n",
       "      <td>1.203267</td>\n",
       "      <td>0.838022</td>\n",
       "      <td>1.003630</td>\n",
       "      <td>01:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>6.070129</td>\n",
       "      <td>6.045344</td>\n",
       "      <td>0.553993</td>\n",
       "      <td>0.663793</td>\n",
       "      <td>0.565789</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.477314</td>\n",
       "      <td>0.545372</td>\n",
       "      <td>0.545372</td>\n",
       "      <td>0.435118</td>\n",
       "      <td>0.646552</td>\n",
       "      <td>0.820780</td>\n",
       "      <td>1.156534</td>\n",
       "      <td>0.814428</td>\n",
       "      <td>0.911071</td>\n",
       "      <td>01:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>6.093341</td>\n",
       "      <td>6.146056</td>\n",
       "      <td>0.550892</td>\n",
       "      <td>0.651996</td>\n",
       "      <td>0.568058</td>\n",
       "      <td>0.529492</td>\n",
       "      <td>0.475953</td>\n",
       "      <td>0.540381</td>\n",
       "      <td>0.539474</td>\n",
       "      <td>0.465064</td>\n",
       "      <td>0.675590</td>\n",
       "      <td>0.847096</td>\n",
       "      <td>1.136116</td>\n",
       "      <td>0.848911</td>\n",
       "      <td>1.007259</td>\n",
       "      <td>01:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>6.002838</td>\n",
       "      <td>6.070854</td>\n",
       "      <td>0.557849</td>\n",
       "      <td>0.665608</td>\n",
       "      <td>0.575318</td>\n",
       "      <td>0.537659</td>\n",
       "      <td>0.478675</td>\n",
       "      <td>0.543103</td>\n",
       "      <td>0.546733</td>\n",
       "      <td>0.437387</td>\n",
       "      <td>0.627949</td>\n",
       "      <td>0.785844</td>\n",
       "      <td>1.134301</td>\n",
       "      <td>0.779492</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>01:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>5.994363</td>\n",
       "      <td>6.000923</td>\n",
       "      <td>0.557093</td>\n",
       "      <td>0.668330</td>\n",
       "      <td>0.570780</td>\n",
       "      <td>0.536751</td>\n",
       "      <td>0.475953</td>\n",
       "      <td>0.541289</td>\n",
       "      <td>0.549456</td>\n",
       "      <td>0.427405</td>\n",
       "      <td>0.628403</td>\n",
       "      <td>0.758167</td>\n",
       "      <td>1.099818</td>\n",
       "      <td>0.777677</td>\n",
       "      <td>0.905626</td>\n",
       "      <td>01:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>6.006251</td>\n",
       "      <td>6.120012</td>\n",
       "      <td>0.551573</td>\n",
       "      <td>0.654719</td>\n",
       "      <td>0.561706</td>\n",
       "      <td>0.535390</td>\n",
       "      <td>0.474592</td>\n",
       "      <td>0.538113</td>\n",
       "      <td>0.544918</td>\n",
       "      <td>0.465517</td>\n",
       "      <td>0.674229</td>\n",
       "      <td>0.811706</td>\n",
       "      <td>1.152450</td>\n",
       "      <td>0.803085</td>\n",
       "      <td>0.931942</td>\n",
       "      <td>01:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>5.998025</td>\n",
       "      <td>6.015248</td>\n",
       "      <td>0.557849</td>\n",
       "      <td>0.671053</td>\n",
       "      <td>0.572595</td>\n",
       "      <td>0.539927</td>\n",
       "      <td>0.474138</td>\n",
       "      <td>0.540381</td>\n",
       "      <td>0.549002</td>\n",
       "      <td>0.426951</td>\n",
       "      <td>0.622958</td>\n",
       "      <td>0.782214</td>\n",
       "      <td>1.132940</td>\n",
       "      <td>0.784483</td>\n",
       "      <td>0.923775</td>\n",
       "      <td>01:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>5.929208</td>\n",
       "      <td>6.062142</td>\n",
       "      <td>0.555808</td>\n",
       "      <td>0.661071</td>\n",
       "      <td>0.575771</td>\n",
       "      <td>0.539474</td>\n",
       "      <td>0.475045</td>\n",
       "      <td>0.532214</td>\n",
       "      <td>0.551270</td>\n",
       "      <td>0.446915</td>\n",
       "      <td>0.630672</td>\n",
       "      <td>0.779038</td>\n",
       "      <td>1.142922</td>\n",
       "      <td>0.792196</td>\n",
       "      <td>0.889292</td>\n",
       "      <td>01:25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with experiment.train():\n",
    "    cls_learn.fit_one_cycle(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'web': 'https://www.comet.ml/api/image/download?imageId=4dcb3b43b52a4910833cf921d8d70399&experimentKey=60a74bacee10483db556732eaf7d4362',\n",
       " 'api': 'https://www.comet.ml/api/rest/v1/image/get-image?imageId=4dcb3b43b52a4910833cf921d8d70399&experimentKey=60a74bacee10483db556732eaf7d4362',\n",
       " 'imageId': '4dcb3b43b52a4910833cf921d8d70399'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = cls_learn.recorder.plot_losses()\n",
    "experiment.log_figure(figure_name=\"train loss 02\", figure=fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_learn.save('hotel.clas.base01.2.learner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load test text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_num_file = [\"aspect_0.count\", \"test_aspect_0.count\"]\n",
    "rating_file = [\"aspect_0.rating\", \"test_aspect_0.rating\"]\n",
    "content_file = [\"aspect_0.txt\", \"test_aspect_0.txt\"]\n",
    "\n",
    "dataset_dir = \"./data/hotel_balance_LengthFix1_3000per/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN_DATA = 0\n",
    "TEST_DATA = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4  5\n",
       "0  1  0  0  3  1  1\n",
       "1  2  2  1  2  3  3\n",
       "2  4  4  4  3  4  4\n",
       "3  3  2  3  3  3  4\n",
       "4  3  4  3  4  4  4"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Ratings\n",
    "aspect_rating_test = list(open(dataset_dir + rating_file[TEST_DATA], \"r\").readlines())\n",
    "aspect_rating_test = [s for s in aspect_rating_test if (len(s) > 0 and s != \"\\n\")]\n",
    "\n",
    "aspect_rating_test = [s.split(\" \") for s in aspect_rating_test]\n",
    "aspect_rating_test = np.array(aspect_rating_test)[:, 0:-1]\n",
    "aspect_rating_test = aspect_rating_test.astype(np.int) - 1\n",
    "aspect_rating_test = pd.DataFrame(aspect_rating_test)\n",
    "aspect_rating_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0, 3, 1, 1],\n",
       "        [2, 2, 1, 2, 3, 3],\n",
       "        [4, 4, 4, 3, 4, 4],\n",
       "        ...,\n",
       "        [0, 0, 0, 3, 0, 2],\n",
       "        [0, 0, 0, 2, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 1]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = torch.tensor( aspect_rating_test.values )\n",
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3739, 6, 5])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = cls_learn.get_preds(ds_type=DatasetType.Test)\n",
    "preds[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#torch.argmax(asps[0],dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.0654)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mloss = MultiLabelCEL()\n",
    "mloss.forward( preds[0] , target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASP0</th>\n",
       "      <th>ASP1</th>\n",
       "      <th>ASP2</th>\n",
       "      <th>ASP3</th>\n",
       "      <th>ASP4</th>\n",
       "      <th>ASP5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.662744</td>\n",
       "      <td>0.584916</td>\n",
       "      <td>0.532763</td>\n",
       "      <td>0.479807</td>\n",
       "      <td>0.538914</td>\n",
       "      <td>0.54988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ASP0      ASP1      ASP2      ASP3      ASP4     ASP5\n",
       "0  0.662744  0.584916  0.532763  0.479807  0.538914  0.54988"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict( {\"ASP\"+str(ai):[get_clas_acc(ai)(preds[0], target).item()] for ai in range(6)} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASP0</th>\n",
       "      <th>ASP1</th>\n",
       "      <th>ASP2</th>\n",
       "      <th>ASP3</th>\n",
       "      <th>ASP4</th>\n",
       "      <th>ASP5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.43755</td>\n",
       "      <td>0.633324</td>\n",
       "      <td>0.739235</td>\n",
       "      <td>1.119016</td>\n",
       "      <td>0.789783</td>\n",
       "      <td>0.950789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ASP0      ASP1      ASP2      ASP3      ASP4      ASP5\n",
       "0  0.43755  0.633324  0.739235  1.119016  0.789783  0.950789"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict( {\"ASP\"+str(ai):[get_clas_mse(ai)(preds[0], target).item()] for ai in range(6)} )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINISH EXPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: ----------------------------\n",
      "COMET INFO: Comet.ml Experiment Summary:\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     url: https://www.comet.ml/aeryen/2019nn/60a74bacee10483db556732eaf7d4362\n",
      "COMET INFO:   Metrics [count] (min, max):\n",
      "COMET INFO:     sys.cpu.percent.01 [127]            : (0.8, 7.3)\n",
      "COMET INFO:     sys.cpu.percent.02 [127]            : (0.2, 15.3)\n",
      "COMET INFO:     sys.cpu.percent.03 [127]            : (0.2, 2.2)\n",
      "COMET INFO:     sys.cpu.percent.04 [127]            : (0.2, 1.4)\n",
      "COMET INFO:     sys.cpu.percent.05 [127]            : (0.2, 1.9)\n",
      "COMET INFO:     sys.cpu.percent.06 [127]            : (0.1, 1.3)\n",
      "COMET INFO:     sys.cpu.percent.07 [127]            : (0.2, 4.9)\n",
      "COMET INFO:     sys.cpu.percent.08 [127]            : (0.2, 29.5)\n",
      "COMET INFO:     sys.cpu.percent.09 [127]            : (0.2, 7.9)\n",
      "COMET INFO:     sys.cpu.percent.10 [127]            : (0.2, 10.0)\n",
      "COMET INFO:     sys.cpu.percent.11 [127]            : (0.6, 4.3)\n",
      "COMET INFO:     sys.cpu.percent.12 [127]            : (0.2, 1.4)\n",
      "COMET INFO:     sys.cpu.percent.avg [127]           : (0.39999999999999997, 5.750000000000001)\n",
      "COMET INFO:     sys.gpu.0.free_memory [144]         : (8409055232.0, 24858918912.0)\n",
      "COMET INFO:     sys.gpu.0.gpu_utilization [144]     : (0.0, 0.0)\n",
      "COMET INFO:     sys.gpu.0.total_memory              : (25373310976.0, 25373310976.0)\n",
      "COMET INFO:     sys.gpu.0.used_memory [144]         : (514392064.0, 16964255744.0)\n",
      "COMET INFO:     sys.load.avg [127]                  : (0.0, 0.72)\n",
      "COMET INFO:     sys.ram.total [127]                 : (16703758336.0, 16703758336.0)\n",
      "COMET INFO:     sys.ram.used [127]                  : (3812007936.0, 6157918208.0)\n",
      "COMET INFO:     train_acc_0 [20]                    : (0.6134301424026489, 0.6710526347160339)\n",
      "COMET INFO:     train_acc_1 [20]                    : (0.5313067436218262, 0.5757713317871094)\n",
      "COMET INFO:     train_acc_2 [20]                    : (0.48275861144065857, 0.5399274230003357)\n",
      "COMET INFO:     train_acc_3 [20]                    : (0.4514518976211548, 0.47867512702941895)\n",
      "COMET INFO:     train_acc_4 [20]                    : (0.5081669688224792, 0.5453720688819885)\n",
      "COMET INFO:     train_acc_5 [20]                    : (0.5054446458816528, 0.5512704253196716)\n",
      "COMET INFO:     train_clas_mse0 [20]                : (0.42695099115371704, 0.5771324634552002)\n",
      "COMET INFO:     train_clas_mse1 [20]                : (0.622958242893219, 0.8529945611953735)\n",
      "COMET INFO:     train_clas_mse2 [20]                : (0.7581669688224792, 1.0598911046981812)\n",
      "COMET INFO:     train_clas_mse3 [20]                : (1.099818468093872, 1.3525408506393433)\n",
      "COMET INFO:     train_clas_mse4 [20]                : (0.7776769399642944, 0.9732304811477661)\n",
      "COMET INFO:     train_clas_mse5 [20]                : (0.8892921805381775, 1.2114337682724)\n",
      "COMET INFO:     train_curr_epoch [20]               : 19\n",
      "COMET INFO:     train_loss [560]                    : (4.786417007446289, 8.880476951599121)\n",
      "COMET INFO:     train_multi_acc [20]                : (0.5175439119338989, 0.5578494668006897)\n",
      "COMET INFO:     train_sys.cpu.percent.01 [24]       : (3.5, 20.1)\n",
      "COMET INFO:     train_sys.cpu.percent.02 [24]       : (0.7, 30.0)\n",
      "COMET INFO:     train_sys.cpu.percent.03 [24]       : (0.7, 52.1)\n",
      "COMET INFO:     train_sys.cpu.percent.04 [24]       : (0.3, 20.4)\n",
      "COMET INFO:     train_sys.cpu.percent.05 [24]       : (0.6, 49.4)\n",
      "COMET INFO:     train_sys.cpu.percent.06 [24]       : (0.7, 50.4)\n",
      "COMET INFO:     train_sys.cpu.percent.07 [24]       : (0.5, 52.5)\n",
      "COMET INFO:     train_sys.cpu.percent.08 [24]       : (0.5, 50.9)\n",
      "COMET INFO:     train_sys.cpu.percent.09 [24]       : (0.7, 53.9)\n",
      "COMET INFO:     train_sys.cpu.percent.10 [24]       : (0.5, 18.6)\n",
      "COMET INFO:     train_sys.cpu.percent.11 [24]       : (0.9, 48.1)\n",
      "COMET INFO:     train_sys.cpu.percent.12 [24]       : (0.4, 52.3)\n",
      "COMET INFO:     train_sys.cpu.percent.avg [24]      : (4.616666666666667, 9.808333333333334)\n",
      "COMET INFO:     train_sys.gpu.0.free_memory [27]    : (8409055232.0, 9361293312.0)\n",
      "COMET INFO:     train_sys.gpu.0.gpu_utilization [27]: (20.0, 95.0)\n",
      "COMET INFO:     train_sys.gpu.0.used_memory [27]    : (16012017664.0, 16964255744.0)\n",
      "COMET INFO:     train_sys.load.avg [24]             : (0.39, 1.37)\n",
      "COMET INFO:     train_sys.ram.total [24]            : (16703758336.0, 16703758336.0)\n",
      "COMET INFO:     train_sys.ram.used [24]             : (5981745152.0, 6244745216.0)\n",
      "COMET INFO:     train_val_loss [20]                 : (6.000922679901123, 6.493485927581787)\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     figures  : 1\n",
      "COMET INFO:     git-patch: 1\n",
      "COMET INFO: ----------------------------\n",
      "COMET INFO: Uploading stats to Comet before program termination (may take several seconds)\n"
     ]
    }
   ],
   "source": [
    "experiment.end()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
